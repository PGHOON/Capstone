{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Flatten, Dense, LSTM\n",
    "from keras.layers import  BatchNormalization, Dropout\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load csv from Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "CLASSES = np.array(['Legitimate', 'Suspicious'])\n",
    "DATASET_DIR = \"dataset/\"\n",
    "VECTOR_LENGTH = 1 * 816\n",
    "\n",
    "def csvToVector(file_path):\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    vector = data.values.flatten()\n",
    "    return vector\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    subdirs = ['0', '1']\n",
    "\n",
    "    for class_idx, class_name in enumerate(subdirs):\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        for file_name in os.listdir(class_dir):\n",
    "            if file_name.endswith('.csv'):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                vector = csvToVector(file_path)\n",
    "                X.append(vector)\n",
    "                y.append(class_idx)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 816)\n",
      "(8,)\n",
      "[[6350    0    0 ...   29    0   48]\n",
      " [6350    0    0 ...   29    0   48]\n",
      " [6350    0    0 ...   29    0   48]\n",
      " ...\n",
      " [6350    0    0 ...   29    0   48]\n",
      " [6350    0    0 ...   29    0   48]\n",
      " [6350    0    0 ...   29    0   48]]\n",
      "[0 0 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Validation, Test Split and Nomalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "y_val = to_categorical(y_val, NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 816, 1)\n",
      "(3, 816, 1)\n",
      "(1, 816, 1)\n",
      "(4, 2)\n",
      "(3, 2)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(VECTOR_LENGTH, 1))\n",
    "\n",
    "x = LSTM(32, return_sequences=True)(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = LSTM(64, return_sequences=True)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = LSTM(128, return_sequences=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "output_layer = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 816, 1)]          0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 816, 32)           4352      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 816, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 816, 32)           0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 816, 64)           24832     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 816, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 816, 64)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 128)               98816     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,458\n",
      "Trainable params: 162,498\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = ModelCheckpoint(\n",
    "    filepath='cp/CMS_LSTM_CheckPoint.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lr(epoch, lr):\n",
    "    print(f\"Learning rate for epoch {epoch} is {lr}\")\n",
    "    return lr\n",
    "\n",
    "lr = LearningRateScheduler(print_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate for epoch 0 is 0.0010000000474974513\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 09:52:49.787962: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 2.3941 - accuracy: 0.2500\n",
      "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to cp/CMS_LSTM_CheckPoint.h5\n",
      "1/1 [==============================] - 6s 6s/step - loss: 2.3941 - accuracy: 0.2500 - val_loss: 2.3628 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 1 is 0.0010000000474974513\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3488 - accuracy: 0.7500\n",
      "Epoch 2: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 2.3488 - accuracy: 0.7500 - val_loss: 2.3328 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 2 is 0.0010000000474974513\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3056 - accuracy: 0.7500\n",
      "Epoch 3: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 2.3056 - accuracy: 0.7500 - val_loss: 2.3039 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 3 is 0.0010000000474974513\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2568 - accuracy: 0.7500\n",
      "Epoch 4: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 2.2568 - accuracy: 0.7500 - val_loss: 2.2760 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 4 is 0.0010000000474974513\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2165 - accuracy: 0.7500\n",
      "Epoch 5: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 2.2165 - accuracy: 0.7500 - val_loss: 2.2490 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 5 is 0.0010000000474974513\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1673 - accuracy: 0.7500\n",
      "Epoch 6: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 2.1673 - accuracy: 0.7500 - val_loss: 2.2229 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 6 is 0.0010000000474974513\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1323 - accuracy: 0.7500\n",
      "Epoch 7: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 2.1323 - accuracy: 0.7500 - val_loss: 2.1982 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 7 is 0.0010000000474974513\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0903 - accuracy: 0.7500\n",
      "Epoch 8: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 2.0903 - accuracy: 0.7500 - val_loss: 2.1745 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 8 is 0.0010000000474974513\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0485 - accuracy: 0.7500\n",
      "Epoch 9: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 2.0485 - accuracy: 0.7500 - val_loss: 2.1518 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 9 is 0.0010000000474974513\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0066 - accuracy: 0.7500\n",
      "Epoch 10: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 2.0066 - accuracy: 0.7500 - val_loss: 2.1299 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 10 is 0.0010000000474974513\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9825 - accuracy: 0.7500\n",
      "Epoch 11: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 1.9825 - accuracy: 0.7500 - val_loss: 2.1084 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 11 is 0.0010000000474974513\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9446 - accuracy: 0.7500\n",
      "Epoch 12: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1.9446 - accuracy: 0.7500 - val_loss: 2.0873 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 12 is 0.0010000000474974513\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8906 - accuracy: 0.7500\n",
      "Epoch 13: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.8906 - accuracy: 0.7500 - val_loss: 2.0672 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 13 is 0.0010000000474974513\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8522 - accuracy: 0.7500\n",
      "Epoch 14: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.8522 - accuracy: 0.7500 - val_loss: 2.0482 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 14 is 0.0010000000474974513\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8153 - accuracy: 0.7500\n",
      "Epoch 15: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 1.8153 - accuracy: 0.7500 - val_loss: 2.0301 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 15 is 0.0010000000474974513\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7722 - accuracy: 0.7500\n",
      "Epoch 16: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.7722 - accuracy: 0.7500 - val_loss: 2.0132 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 16 is 0.0010000000474974513\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7468 - accuracy: 0.7500\n",
      "Epoch 17: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.7468 - accuracy: 0.7500 - val_loss: 1.9971 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 17 is 0.0010000000474974513\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7333 - accuracy: 0.7500\n",
      "Epoch 18: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 1.7333 - accuracy: 0.7500 - val_loss: 1.9814 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 18 is 0.0010000000474974513\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7005 - accuracy: 0.7500\n",
      "Epoch 19: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 1.7005 - accuracy: 0.7500 - val_loss: 1.9660 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 19 is 0.0010000000474974513\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6678 - accuracy: 0.7500\n",
      "Epoch 20: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.6678 - accuracy: 0.7500 - val_loss: 1.9510 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 20 is 0.0010000000474974513\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6352 - accuracy: 0.7500\n",
      "Epoch 21: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.6352 - accuracy: 0.7500 - val_loss: 1.9363 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 21 is 0.0010000000474974513\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5862 - accuracy: 0.7500\n",
      "Epoch 22: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1.5862 - accuracy: 0.7500 - val_loss: 1.9225 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 22 is 0.0010000000474974513\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5472 - accuracy: 0.7500\n",
      "Epoch 23: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.5472 - accuracy: 0.7500 - val_loss: 1.9098 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 23 is 0.0010000000474974513\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5229 - accuracy: 0.7500\n",
      "Epoch 24: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 1.5229 - accuracy: 0.7500 - val_loss: 1.8980 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 24 is 0.0010000000474974513\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4897 - accuracy: 0.7500\n",
      "Epoch 25: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 1.4897 - accuracy: 0.7500 - val_loss: 1.8869 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 25 is 0.0010000000474974513\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4722 - accuracy: 0.7500\n",
      "Epoch 26: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 1.4722 - accuracy: 0.7500 - val_loss: 1.8765 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 26 is 0.0010000000474974513\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4451 - accuracy: 0.7500\n",
      "Epoch 27: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 1.4451 - accuracy: 0.7500 - val_loss: 1.8666 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 27 is 0.0010000000474974513\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4180 - accuracy: 0.7500\n",
      "Epoch 28: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 1.4180 - accuracy: 0.7500 - val_loss: 1.8571 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 28 is 0.0010000000474974513\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4077 - accuracy: 0.7500\n",
      "Epoch 29: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 1.4077 - accuracy: 0.7500 - val_loss: 1.8477 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 29 is 0.0010000000474974513\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3583 - accuracy: 0.7500\n",
      "Epoch 30: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.3583 - accuracy: 0.7500 - val_loss: 1.8390 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 30 is 0.0010000000474974513\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3590 - accuracy: 0.7500\n",
      "Epoch 31: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.3590 - accuracy: 0.7500 - val_loss: 1.8303 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 31 is 0.0010000000474974513\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3169 - accuracy: 0.7500\n",
      "Epoch 32: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1.3169 - accuracy: 0.7500 - val_loss: 1.8219 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 32 is 0.0010000000474974513\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2881 - accuracy: 0.7500\n",
      "Epoch 33: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 1.2881 - accuracy: 0.7500 - val_loss: 1.8141 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 33 is 0.0010000000474974513\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2705 - accuracy: 0.7500\n",
      "Epoch 34: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 1.2705 - accuracy: 0.7500 - val_loss: 1.8066 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 34 is 0.0010000000474974513\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2439 - accuracy: 0.7500\n",
      "Epoch 35: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 1.2439 - accuracy: 0.7500 - val_loss: 1.7994 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 35 is 0.0010000000474974513\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2220 - accuracy: 0.7500\n",
      "Epoch 36: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.2220 - accuracy: 0.7500 - val_loss: 1.7926 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 36 is 0.0010000000474974513\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2000 - accuracy: 0.7500\n",
      "Epoch 37: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1.2000 - accuracy: 0.7500 - val_loss: 1.7862 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 37 is 0.0010000000474974513\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2072 - accuracy: 0.7500\n",
      "Epoch 38: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 1.2072 - accuracy: 0.7500 - val_loss: 1.7797 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 38 is 0.0010000000474974513\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1894 - accuracy: 0.7500\n",
      "Epoch 39: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 1.1894 - accuracy: 0.7500 - val_loss: 1.7732 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 39 is 0.0010000000474974513\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1785 - accuracy: 0.7500\n",
      "Epoch 40: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.1785 - accuracy: 0.7500 - val_loss: 1.7662 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 40 is 0.0010000000474974513\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1315 - accuracy: 0.7500\n",
      "Epoch 41: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 1.1315 - accuracy: 0.7500 - val_loss: 1.7591 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 41 is 0.0010000000474974513\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1449 - accuracy: 0.7500\n",
      "Epoch 42: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 1.1449 - accuracy: 0.7500 - val_loss: 1.7515 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 42 is 0.0010000000474974513\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1215 - accuracy: 0.7500\n",
      "Epoch 43: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 1.1215 - accuracy: 0.7500 - val_loss: 1.7437 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 43 is 0.0010000000474974513\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1115 - accuracy: 0.7500\n",
      "Epoch 44: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 1.1115 - accuracy: 0.7500 - val_loss: 1.7353 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 44 is 0.0010000000474974513\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0946 - accuracy: 0.7500\n",
      "Epoch 45: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 1.0946 - accuracy: 0.7500 - val_loss: 1.7265 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 45 is 0.0010000000474974513\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0747 - accuracy: 0.7500\n",
      "Epoch 46: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 1.0747 - accuracy: 0.7500 - val_loss: 1.7175 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 46 is 0.0010000000474974513\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0606 - accuracy: 0.7500\n",
      "Epoch 47: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 1.0606 - accuracy: 0.7500 - val_loss: 1.7082 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 47 is 0.0010000000474974513\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0447 - accuracy: 0.7500\n",
      "Epoch 48: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 1.0447 - accuracy: 0.7500 - val_loss: 1.6989 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 48 is 0.0010000000474974513\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0295 - accuracy: 0.7500\n",
      "Epoch 49: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1.0295 - accuracy: 0.7500 - val_loss: 1.6896 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 49 is 0.0010000000474974513\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0124 - accuracy: 0.7500\n",
      "Epoch 50: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 1.0124 - accuracy: 0.7500 - val_loss: 1.6801 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 50 is 0.0010000000474974513\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9911 - accuracy: 0.7500\n",
      "Epoch 51: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.9911 - accuracy: 0.7500 - val_loss: 1.6704 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 51 is 0.0010000000474974513\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9851 - accuracy: 0.7500\n",
      "Epoch 52: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.9851 - accuracy: 0.7500 - val_loss: 1.6609 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 52 is 0.0010000000474974513\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9677 - accuracy: 0.7500\n",
      "Epoch 53: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.9677 - accuracy: 0.7500 - val_loss: 1.6512 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 53 is 0.0010000000474974513\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9551 - accuracy: 0.7500\n",
      "Epoch 54: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.9551 - accuracy: 0.7500 - val_loss: 1.6413 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 54 is 0.0010000000474974513\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9370 - accuracy: 0.7500\n",
      "Epoch 55: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.9370 - accuracy: 0.7500 - val_loss: 1.6316 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 55 is 0.0010000000474974513\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9322 - accuracy: 0.7500\n",
      "Epoch 56: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.9322 - accuracy: 0.7500 - val_loss: 1.6220 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 56 is 0.0010000000474974513\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9196 - accuracy: 0.7500\n",
      "Epoch 57: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.9196 - accuracy: 0.7500 - val_loss: 1.6127 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 57 is 0.0010000000474974513\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9054 - accuracy: 0.7500\n",
      "Epoch 58: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.9054 - accuracy: 0.7500 - val_loss: 1.6032 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 58 is 0.0010000000474974513\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9041 - accuracy: 0.7500\n",
      "Epoch 59: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.9041 - accuracy: 0.7500 - val_loss: 1.5936 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 59 is 0.0010000000474974513\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8941 - accuracy: 0.7500\n",
      "Epoch 60: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.8941 - accuracy: 0.7500 - val_loss: 1.5838 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 60 is 0.0010000000474974513\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8718 - accuracy: 0.7500\n",
      "Epoch 61: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.8718 - accuracy: 0.7500 - val_loss: 1.5740 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 61 is 0.0010000000474974513\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8619 - accuracy: 0.7500\n",
      "Epoch 62: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.8619 - accuracy: 0.7500 - val_loss: 1.5646 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 62 is 0.0010000000474974513\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8502 - accuracy: 0.7500\n",
      "Epoch 63: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.8502 - accuracy: 0.7500 - val_loss: 1.5552 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 63 is 0.0010000000474974513\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8620 - accuracy: 0.7500\n",
      "Epoch 64: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.8620 - accuracy: 0.7500 - val_loss: 1.5457 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 64 is 0.0010000000474974513\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8319 - accuracy: 0.7500\n",
      "Epoch 65: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.8319 - accuracy: 0.7500 - val_loss: 1.5367 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 65 is 0.0010000000474974513\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8471 - accuracy: 0.7500\n",
      "Epoch 66: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.8471 - accuracy: 0.7500 - val_loss: 1.5276 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 66 is 0.0010000000474974513\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8127 - accuracy: 0.7500\n",
      "Epoch 67: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.8127 - accuracy: 0.7500 - val_loss: 1.5189 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 67 is 0.0010000000474974513\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8028 - accuracy: 0.7500\n",
      "Epoch 68: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.8028 - accuracy: 0.7500 - val_loss: 1.5108 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 68 is 0.0010000000474974513\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8241 - accuracy: 0.7500\n",
      "Epoch 69: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.8241 - accuracy: 0.7500 - val_loss: 1.5025 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 69 is 0.0010000000474974513\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7877 - accuracy: 0.7500\n",
      "Epoch 70: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7877 - accuracy: 0.7500 - val_loss: 1.4943 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 70 is 0.0010000000474974513\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8062 - accuracy: 0.7500\n",
      "Epoch 71: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.8062 - accuracy: 0.7500 - val_loss: 1.4860 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 71 is 0.0010000000474974513\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7657 - accuracy: 0.7500\n",
      "Epoch 72: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7657 - accuracy: 0.7500 - val_loss: 1.4782 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 72 is 0.0010000000474974513\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7933 - accuracy: 0.7500\n",
      "Epoch 73: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.7933 - accuracy: 0.7500 - val_loss: 1.4703 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 73 is 0.0010000000474974513\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7891 - accuracy: 0.7500\n",
      "Epoch 74: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.7891 - accuracy: 0.7500 - val_loss: 1.4623 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 74 is 0.0010000000474974513\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7540 - accuracy: 0.7500\n",
      "Epoch 75: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7540 - accuracy: 0.7500 - val_loss: 1.4544 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 75 is 0.0010000000474974513\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7346 - accuracy: 0.7500\n",
      "Epoch 76: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7346 - accuracy: 0.7500 - val_loss: 1.4473 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 76 is 0.0010000000474974513\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7271 - accuracy: 0.7500\n",
      "Epoch 77: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.7271 - accuracy: 0.7500 - val_loss: 1.4408 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 77 is 0.0010000000474974513\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7190 - accuracy: 0.7500\n",
      "Epoch 78: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.7190 - accuracy: 0.7500 - val_loss: 1.4349 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 78 is 0.0010000000474974513\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7307 - accuracy: 0.7500\n",
      "Epoch 79: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7307 - accuracy: 0.7500 - val_loss: 1.4291 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 79 is 0.0010000000474974513\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7025 - accuracy: 0.7500\n",
      "Epoch 80: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7025 - accuracy: 0.7500 - val_loss: 1.4239 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 80 is 0.0010000000474974513\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.7500\n",
      "Epoch 81: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.6942 - accuracy: 0.7500 - val_loss: 1.4195 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 81 is 0.0010000000474974513\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7144 - accuracy: 0.7500\n",
      "Epoch 82: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7144 - accuracy: 0.7500 - val_loss: 1.4149 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 82 is 0.0010000000474974513\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7437 - accuracy: 0.7500\n",
      "Epoch 83: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.7437 - accuracy: 0.7500 - val_loss: 1.4102 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 83 is 0.0010000000474974513\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7392 - accuracy: 0.7500\n",
      "Epoch 84: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.7392 - accuracy: 0.7500 - val_loss: 1.4052 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 84 is 0.0010000000474974513\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6985 - accuracy: 0.7500\n",
      "Epoch 85: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.6985 - accuracy: 0.7500 - val_loss: 1.4002 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 85 is 0.0010000000474974513\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.7500\n",
      "Epoch 86: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.6929 - accuracy: 0.7500 - val_loss: 1.3952 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 86 is 0.0010000000474974513\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6864 - accuracy: 0.7500\n",
      "Epoch 87: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6864 - accuracy: 0.7500 - val_loss: 1.3903 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 87 is 0.0010000000474974513\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7299 - accuracy: 0.7500\n",
      "Epoch 88: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7299 - accuracy: 0.7500 - val_loss: 1.3849 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 88 is 0.0010000000474974513\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6727 - accuracy: 0.7500\n",
      "Epoch 89: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6727 - accuracy: 0.7500 - val_loss: 1.3797 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 89 is 0.0010000000474974513\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7140 - accuracy: 0.7500\n",
      "Epoch 90: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7140 - accuracy: 0.7500 - val_loss: 1.3744 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 90 is 0.0010000000474974513\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6379 - accuracy: 0.7500\n",
      "Epoch 91: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.6379 - accuracy: 0.7500 - val_loss: 1.3700 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 91 is 0.0010000000474974513\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6338 - accuracy: 0.7500\n",
      "Epoch 92: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.6338 - accuracy: 0.7500 - val_loss: 1.3665 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 92 is 0.0010000000474974513\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7169 - accuracy: 0.7500\n",
      "Epoch 93: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7169 - accuracy: 0.7500 - val_loss: 1.3622 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 93 is 0.0010000000474974513\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.7500\n",
      "Epoch 94: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.6249 - accuracy: 0.7500 - val_loss: 1.3588 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 94 is 0.0010000000474974513\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6971 - accuracy: 0.7500\n",
      "Epoch 95: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6971 - accuracy: 0.7500 - val_loss: 1.3551 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 95 is 0.0010000000474974513\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.7500\n",
      "Epoch 96: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6156 - accuracy: 0.7500 - val_loss: 1.3523 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 96 is 0.0010000000474974513\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6347 - accuracy: 0.7500\n",
      "Epoch 97: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.6347 - accuracy: 0.7500 - val_loss: 1.3495 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 97 is 0.0010000000474974513\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7044 - accuracy: 0.7500\n",
      "Epoch 98: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.7044 - accuracy: 0.7500 - val_loss: 1.3460 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 98 is 0.0010000000474974513\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6024 - accuracy: 0.7500\n",
      "Epoch 99: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6024 - accuracy: 0.7500 - val_loss: 1.3433 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 99 is 0.0010000000474974513\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6829 - accuracy: 0.7500\n",
      "Epoch 100: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.6829 - accuracy: 0.7500 - val_loss: 1.3403 - val_accuracy: 0.0000e+00 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c619b400>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=32, \n",
    "          epochs=100, \n",
    "          shuffle=True,\n",
    "          callbacks=[lr, cp]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 2.3567 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.356717586517334, 0.3333333432674408]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_model = load_model('cp/CMS_LSTM_CHeckPoint.h5')\n",
    "cp_model.evaluate(X_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 873ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = cp_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_single = CLASSES[np.argmax(y_pred, axis = -1)]\n",
    "actual_single = CLASSES[np.argmax(y_test, axis = -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(X_test)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    data = X_test[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i+1)\n",
    "    ax.plot(data)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.2, 'pred = ' + str(preds_single[idx]), fontsize=10, ha='center', transform=ax.transAxes) \n",
    "    ax.text(0.5, -0.4, 'act = ' + str(actual_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.17      0.50      0.25         3\n",
      "weighted avg       0.11      0.33      0.17         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gyeonghoon_park/miniforge3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/gyeonghoon_park/miniforge3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/gyeonghoon_park/miniforge3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "y_test_classes = tf.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion MatriX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "            Legitimate  Suspicious\n",
      "Legitimate           0           2\n",
      "Suspicious           0           1\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "class_labels = ['Legitimate', 'Suspicious']\n",
    "\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('ROC_Curve_cms_1d_cnn.pdf', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
