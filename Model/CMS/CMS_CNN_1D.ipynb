{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Flatten, Dense, Conv1D, MaxPooling1D\n",
    "from keras.layers import  BatchNormalization, LeakyReLU, Dropout, Activation\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load csv from Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "CLASSES = np.array(['Legitimate', 'Suspicious'])\n",
    "DATASET_DIR = \"dataset/\"\n",
    "VECTOR_LENGTH = 1 * 816\n",
    "\n",
    "def csvToVector(file_path):\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    vector = data.values.flatten()\n",
    "    return vector\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    classes = [class_name for class_name in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, class_name))]\n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        for file_name in os.listdir(class_dir):\n",
    "            if file_name.endswith('.csv'):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                vector = csvToVector(file_path)\n",
    "                X.append(vector)\n",
    "                y.append(class_idx)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 816)\n",
      "(8,)\n",
      "[[6350    0    0 ...   29    0   48]\n",
      " [6350    0    0 ...   29    0   48]\n",
      " [6350    0    0 ...   29    0   48]\n",
      " ...\n",
      " [6350    0    0 ...   29    0   48]\n",
      " [6350    0    0 ...   29    0   48]\n",
      " [6350    0    0 ...   29    0   48]]\n",
      "[0 0 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Validation, Test Split and Nomalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "y_val = to_categorical(y_val, NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 816)\n",
      "(3, 816)\n",
      "(1, 816)\n",
      "(4, 2)\n",
      "(3, 2)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(VECTOR_LENGTH, 1))\n",
    "\n",
    "x = Conv1D(filters=32, kernel_size=3, padding='same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Conv1D(filters=64, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Conv1D(filters=128, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(256)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 816, 1)]          0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 816, 32)           128       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 816, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 816, 32)           0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 408, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 408, 64)           6208      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 408, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 408, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 204, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 204, 128)          24704     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 204, 128)         512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 204, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 102, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 13056)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               3342592   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,376,066\n",
      "Trainable params: 3,375,106\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = ModelCheckpoint(\n",
    "    filepath='CMS_CNN_1D_CheckPoint.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lr(epoch, lr):\n",
    "    print(f\"Learning rate for epoch {epoch} is {lr}\")\n",
    "    return lr\n",
    "\n",
    "lr = LearningRateScheduler(print_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate for epoch 0 is 0.0010000000474974513\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.2500\n",
      "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to CMS_CNN_1D_CheckPoint.h5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6931 - accuracy: 0.2500 - val_loss: 0.6999 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 1 is 0.0010000000474974513\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.7500\n",
      "Epoch 2: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6893 - accuracy: 0.7500 - val_loss: 0.7071 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 2 is 0.0010000000474974513\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6858 - accuracy: 0.7500\n",
      "Epoch 3: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6858 - accuracy: 0.7500 - val_loss: 0.7148 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 3 is 0.0010000000474974513\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6822 - accuracy: 0.7500\n",
      "Epoch 4: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6822 - accuracy: 0.7500 - val_loss: 0.7235 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 4 is 0.0010000000474974513\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6816 - accuracy: 0.7500\n",
      "Epoch 5: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6816 - accuracy: 0.7500 - val_loss: 0.7314 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 5 is 0.0010000000474974513\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6725 - accuracy: 0.7500\n",
      "Epoch 6: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6725 - accuracy: 0.7500 - val_loss: 0.7392 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 6 is 0.0010000000474974513\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6695 - accuracy: 0.7500\n",
      "Epoch 7: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6695 - accuracy: 0.7500 - val_loss: 0.7476 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 7 is 0.0010000000474974513\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6716 - accuracy: 0.7500\n",
      "Epoch 8: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6716 - accuracy: 0.7500 - val_loss: 0.7559 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 8 is 0.0010000000474974513\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6612 - accuracy: 0.7500\n",
      "Epoch 9: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6612 - accuracy: 0.7500 - val_loss: 0.7639 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 9 is 0.0010000000474974513\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6563 - accuracy: 0.7500\n",
      "Epoch 10: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6563 - accuracy: 0.7500 - val_loss: 0.7725 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 10 is 0.0010000000474974513\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6562 - accuracy: 0.7500\n",
      "Epoch 11: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6562 - accuracy: 0.7500 - val_loss: 0.7816 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 11 is 0.0010000000474974513\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6485 - accuracy: 0.7500\n",
      "Epoch 12: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6485 - accuracy: 0.7500 - val_loss: 0.7915 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 12 is 0.0010000000474974513\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6486 - accuracy: 0.7500\n",
      "Epoch 13: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6486 - accuracy: 0.7500 - val_loss: 0.8014 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 13 is 0.0010000000474974513\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6445 - accuracy: 0.7500\n",
      "Epoch 14: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6445 - accuracy: 0.7500 - val_loss: 0.8110 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 14 is 0.0010000000474974513\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6401 - accuracy: 0.7500\n",
      "Epoch 15: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6401 - accuracy: 0.7500 - val_loss: 0.8207 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 15 is 0.0010000000474974513\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6325 - accuracy: 0.7500\n",
      "Epoch 16: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6325 - accuracy: 0.7500 - val_loss: 0.8312 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 16 is 0.0010000000474974513\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6444 - accuracy: 0.7500\n",
      "Epoch 17: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6444 - accuracy: 0.7500 - val_loss: 0.8407 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 17 is 0.0010000000474974513\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6245 - accuracy: 0.7500\n",
      "Epoch 18: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6245 - accuracy: 0.7500 - val_loss: 0.8507 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 18 is 0.0010000000474974513\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6232 - accuracy: 0.7500\n",
      "Epoch 19: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6232 - accuracy: 0.7500 - val_loss: 0.8603 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 19 is 0.0010000000474974513\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6190 - accuracy: 0.7500\n",
      "Epoch 20: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6190 - accuracy: 0.7500 - val_loss: 0.8699 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 20 is 0.0010000000474974513\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6335 - accuracy: 0.7500\n",
      "Epoch 21: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6335 - accuracy: 0.7500 - val_loss: 0.8786 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 21 is 0.0010000000474974513\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6106 - accuracy: 0.7500\n",
      "Epoch 22: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6106 - accuracy: 0.7500 - val_loss: 0.8873 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 22 is 0.0010000000474974513\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6059 - accuracy: 0.7500\n",
      "Epoch 23: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6059 - accuracy: 0.7500 - val_loss: 0.8964 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 23 is 0.0010000000474974513\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6022 - accuracy: 0.7500\n",
      "Epoch 24: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6022 - accuracy: 0.7500 - val_loss: 0.9058 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 24 is 0.0010000000474974513\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5987 - accuracy: 0.7500\n",
      "Epoch 25: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5987 - accuracy: 0.7500 - val_loss: 0.9152 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 25 is 0.0010000000474974513\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.7500\n",
      "Epoch 26: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6213 - accuracy: 0.7500 - val_loss: 0.9245 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 26 is 0.0010000000474974513\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5911 - accuracy: 0.7500\n",
      "Epoch 27: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5911 - accuracy: 0.7500 - val_loss: 0.9338 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 27 is 0.0010000000474974513\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.7500\n",
      "Epoch 28: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6165 - accuracy: 0.7500 - val_loss: 0.9425 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 28 is 0.0010000000474974513\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5851 - accuracy: 0.7500\n",
      "Epoch 29: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5851 - accuracy: 0.7500 - val_loss: 0.9518 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 29 is 0.0010000000474974513\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5819 - accuracy: 0.7500\n",
      "Epoch 30: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5819 - accuracy: 0.7500 - val_loss: 0.9613 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 30 is 0.0010000000474974513\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5783 - accuracy: 0.7500\n",
      "Epoch 31: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5783 - accuracy: 0.7500 - val_loss: 0.9711 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 31 is 0.0010000000474974513\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5752 - accuracy: 0.7500\n",
      "Epoch 32: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5752 - accuracy: 0.7500 - val_loss: 0.9812 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 32 is 0.0010000000474974513\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6058 - accuracy: 0.7500\n",
      "Epoch 33: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6058 - accuracy: 0.7500 - val_loss: 0.9911 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 33 is 0.0010000000474974513\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5699 - accuracy: 0.7500\n",
      "Epoch 34: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5699 - accuracy: 0.7500 - val_loss: 1.0004 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 34 is 0.0010000000474974513\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7500\n",
      "Epoch 35: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5662 - accuracy: 0.7500 - val_loss: 1.0096 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 35 is 0.0010000000474974513\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6005 - accuracy: 0.7500\n",
      "Epoch 36: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6005 - accuracy: 0.7500 - val_loss: 1.0184 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 36 is 0.0010000000474974513\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5624 - accuracy: 0.7500\n",
      "Epoch 37: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5624 - accuracy: 0.7500 - val_loss: 1.0281 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 37 is 0.0010000000474974513\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5871 - accuracy: 0.7500\n",
      "Epoch 38: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5871 - accuracy: 0.7500 - val_loss: 1.0384 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 38 is 0.0010000000474974513\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5578 - accuracy: 0.7500\n",
      "Epoch 39: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5578 - accuracy: 0.7500 - val_loss: 1.0487 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 39 is 0.0010000000474974513\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5552 - accuracy: 0.7500\n",
      "Epoch 40: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5552 - accuracy: 0.7500 - val_loss: 1.0587 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 40 is 0.0010000000474974513\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5941 - accuracy: 0.7500\n",
      "Epoch 41: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5941 - accuracy: 0.7500 - val_loss: 1.0687 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 41 is 0.0010000000474974513\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5858 - accuracy: 0.7500\n",
      "Epoch 42: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5858 - accuracy: 0.7500 - val_loss: 1.0773 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 42 is 0.0010000000474974513\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5919 - accuracy: 0.7500\n",
      "Epoch 43: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5919 - accuracy: 0.7500 - val_loss: 1.0851 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 43 is 0.0010000000474974513\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5903 - accuracy: 0.7500\n",
      "Epoch 44: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5903 - accuracy: 0.7500 - val_loss: 1.0924 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 44 is 0.0010000000474974513\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5881 - accuracy: 0.7500\n",
      "Epoch 45: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.5881 - accuracy: 0.7500 - val_loss: 1.0995 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 45 is 0.0010000000474974513\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5851 - accuracy: 0.7500\n",
      "Epoch 46: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5851 - accuracy: 0.7500 - val_loss: 1.1067 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 46 is 0.0010000000474974513\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5441 - accuracy: 0.7500\n",
      "Epoch 47: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5441 - accuracy: 0.7500 - val_loss: 1.1147 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 47 is 0.0010000000474974513\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5540 - accuracy: 0.7500\n",
      "Epoch 48: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5540 - accuracy: 0.7500 - val_loss: 1.1217 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 48 is 0.0010000000474974513\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5799 - accuracy: 0.7500\n",
      "Epoch 49: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5799 - accuracy: 0.7500 - val_loss: 1.1282 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 49 is 0.0010000000474974513\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5420 - accuracy: 0.7500\n",
      "Epoch 50: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5420 - accuracy: 0.7500 - val_loss: 1.1351 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 50 is 0.0010000000474974513\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5852 - accuracy: 0.7500\n",
      "Epoch 51: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5852 - accuracy: 0.7500 - val_loss: 1.1411 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 51 is 0.0010000000474974513\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5849 - accuracy: 0.7500\n",
      "Epoch 52: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5849 - accuracy: 0.7500 - val_loss: 1.1475 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 52 is 0.0010000000474974513\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5838 - accuracy: 0.7500\n",
      "Epoch 53: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5838 - accuracy: 0.7500 - val_loss: 1.1540 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 53 is 0.0010000000474974513\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5572 - accuracy: 0.7500\n",
      "Epoch 54: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5572 - accuracy: 0.7500 - val_loss: 1.1607 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 54 is 0.0010000000474974513\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5575 - accuracy: 0.7500\n",
      "Epoch 55: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5575 - accuracy: 0.7500 - val_loss: 1.1679 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 55 is 0.0010000000474974513\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5795 - accuracy: 0.7500\n",
      "Epoch 56: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5795 - accuracy: 0.7500 - val_loss: 1.1745 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 56 is 0.0010000000474974513\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.7500\n",
      "Epoch 57: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5417 - accuracy: 0.7500 - val_loss: 1.1809 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 57 is 0.0010000000474974513\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5570 - accuracy: 0.7500\n",
      "Epoch 58: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5570 - accuracy: 0.7500 - val_loss: 1.1870 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 58 is 0.0010000000474974513\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5564 - accuracy: 0.7500\n",
      "Epoch 59: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5564 - accuracy: 0.7500 - val_loss: 1.1938 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 59 is 0.0010000000474974513\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5785 - accuracy: 0.7500\n",
      "Epoch 60: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5785 - accuracy: 0.7500 - val_loss: 1.2007 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 60 is 0.0010000000474974513\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5787 - accuracy: 0.7500\n",
      "Epoch 61: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5787 - accuracy: 0.7500 - val_loss: 1.2072 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 61 is 0.0010000000474974513\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.7500\n",
      "Epoch 62: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5438 - accuracy: 0.7500 - val_loss: 1.2124 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 62 is 0.0010000000474974513\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5776 - accuracy: 0.7500\n",
      "Epoch 63: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5776 - accuracy: 0.7500 - val_loss: 1.2150 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 63 is 0.0010000000474974513\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5759 - accuracy: 0.7500\n",
      "Epoch 64: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5759 - accuracy: 0.7500 - val_loss: 1.2171 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 64 is 0.0010000000474974513\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.7500\n",
      "Epoch 65: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5448 - accuracy: 0.7500 - val_loss: 1.2183 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 65 is 0.0010000000474974513\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5757 - accuracy: 0.7500\n",
      "Epoch 66: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5757 - accuracy: 0.7500 - val_loss: 1.2194 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 66 is 0.0010000000474974513\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5749 - accuracy: 0.7500\n",
      "Epoch 67: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5749 - accuracy: 0.7500 - val_loss: 1.2204 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 67 is 0.0010000000474974513\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5754 - accuracy: 0.7500\n",
      "Epoch 68: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5754 - accuracy: 0.7500 - val_loss: 1.2205 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 68 is 0.0010000000474974513\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5575 - accuracy: 0.7500\n",
      "Epoch 69: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5575 - accuracy: 0.7500 - val_loss: 1.2198 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 69 is 0.0010000000474974513\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5715 - accuracy: 0.7500\n",
      "Epoch 70: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5715 - accuracy: 0.7500 - val_loss: 1.2199 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 70 is 0.0010000000474974513\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5744 - accuracy: 0.7500\n",
      "Epoch 71: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5744 - accuracy: 0.7500 - val_loss: 1.2199 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 71 is 0.0010000000474974513\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5690 - accuracy: 0.7500\n",
      "Epoch 72: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5690 - accuracy: 0.7500 - val_loss: 1.2215 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 72 is 0.0010000000474974513\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5672 - accuracy: 0.7500\n",
      "Epoch 73: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5672 - accuracy: 0.7500 - val_loss: 1.2247 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 73 is 0.0010000000474974513\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5605 - accuracy: 0.7500\n",
      "Epoch 74: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5605 - accuracy: 0.7500 - val_loss: 1.2275 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 74 is 0.0010000000474974513\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5607 - accuracy: 0.7500\n",
      "Epoch 75: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5607 - accuracy: 0.7500 - val_loss: 1.2303 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 75 is 0.0010000000474974513\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5614 - accuracy: 0.7500\n",
      "Epoch 76: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5614 - accuracy: 0.7500 - val_loss: 1.2335 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 76 is 0.0010000000474974513\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5740 - accuracy: 0.7500\n",
      "Epoch 77: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5740 - accuracy: 0.7500 - val_loss: 1.2354 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 77 is 0.0010000000474974513\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5599 - accuracy: 0.7500\n",
      "Epoch 78: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5599 - accuracy: 0.7500 - val_loss: 1.2376 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 78 is 0.0010000000474974513\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5564 - accuracy: 0.7500\n",
      "Epoch 79: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5564 - accuracy: 0.7500 - val_loss: 1.2414 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 79 is 0.0010000000474974513\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5740 - accuracy: 0.7500\n",
      "Epoch 80: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5740 - accuracy: 0.7500 - val_loss: 1.2427 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 80 is 0.0010000000474974513\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.7500\n",
      "Epoch 81: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5649 - accuracy: 0.7500 - val_loss: 1.2455 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 81 is 0.0010000000474974513\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5660 - accuracy: 0.7500\n",
      "Epoch 82: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5660 - accuracy: 0.7500 - val_loss: 1.2462 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 82 is 0.0010000000474974513\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7500\n",
      "Epoch 83: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5662 - accuracy: 0.7500 - val_loss: 1.2483 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 83 is 0.0010000000474974513\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.7500\n",
      "Epoch 84: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5656 - accuracy: 0.7500 - val_loss: 1.2514 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 84 is 0.0010000000474974513\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5739 - accuracy: 0.7500\n",
      "Epoch 85: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5739 - accuracy: 0.7500 - val_loss: 1.2547 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 85 is 0.0010000000474974513\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5612 - accuracy: 0.7500\n",
      "Epoch 86: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5612 - accuracy: 0.7500 - val_loss: 1.2577 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 86 is 0.0010000000474974513\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.7500\n",
      "Epoch 87: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5734 - accuracy: 0.7500 - val_loss: 1.2583 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 87 is 0.0010000000474974513\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.7500\n",
      "Epoch 88: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5616 - accuracy: 0.7500 - val_loss: 1.2597 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 88 is 0.0010000000474974513\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5718 - accuracy: 0.7500\n",
      "Epoch 89: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5718 - accuracy: 0.7500 - val_loss: 1.2607 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 89 is 0.0010000000474974513\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.7500\n",
      "Epoch 90: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5628 - accuracy: 0.7500 - val_loss: 1.2618 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 90 is 0.0010000000474974513\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5612 - accuracy: 0.7500\n",
      "Epoch 91: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5612 - accuracy: 0.7500 - val_loss: 1.2637 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 91 is 0.0010000000474974513\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5619 - accuracy: 0.7500\n",
      "Epoch 92: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5619 - accuracy: 0.7500 - val_loss: 1.2660 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 92 is 0.0010000000474974513\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.7500\n",
      "Epoch 93: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.5683 - accuracy: 0.7500 - val_loss: 1.2665 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 93 is 0.0010000000474974513\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.7500\n",
      "Epoch 94: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5616 - accuracy: 0.7500 - val_loss: 1.2666 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 94 is 0.0010000000474974513\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5605 - accuracy: 0.7500\n",
      "Epoch 95: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5605 - accuracy: 0.7500 - val_loss: 1.2622 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 95 is 0.0010000000474974513\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5660 - accuracy: 0.7500\n",
      "Epoch 96: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5660 - accuracy: 0.7500 - val_loss: 1.2531 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 96 is 0.0010000000474974513\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5644 - accuracy: 0.7500\n",
      "Epoch 97: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5644 - accuracy: 0.7500 - val_loss: 1.2430 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 97 is 0.0010000000474974513\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5647 - accuracy: 0.7500\n",
      "Epoch 98: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5647 - accuracy: 0.7500 - val_loss: 1.2324 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 98 is 0.0010000000474974513\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5614 - accuracy: 0.7500\n",
      "Epoch 99: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5614 - accuracy: 0.7500 - val_loss: 1.2225 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 99 is 0.0010000000474974513\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5613 - accuracy: 0.7500\n",
      "Epoch 100: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5613 - accuracy: 0.7500 - val_loss: 1.2130 - val_accuracy: 0.0000e+00 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16025e610>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=32, \n",
    "          epochs=100, \n",
    "          shuffle=True,\n",
    "          callbacks=[lr, cp]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 304ms/step - loss: 0.6954 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6954247355461121, 0.3333333432674408]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_model = load_model('CMS_CNN_1D_CHeckPoint.h5')\n",
    "cp_model.evaluate(X_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 257ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = cp_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_single = CLASSES[np.argmax(y_pred, axis = -1)]\n",
    "actual_single = CLASSES[np.argmax(y_test, axis = -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(X_test)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    data = X_test[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i+1)\n",
    "    ax.plot(data)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.2, 'pred = ' + str(preds_single[idx]), fontsize=10, ha='center', transform=ax.transAxes) \n",
    "    ax.text(0.5, -0.4, 'act = ' + str(actual_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.17      0.50      0.25         3\n",
      "weighted avg       0.11      0.33      0.17         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gyeonghoon_park/miniforge3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/gyeonghoon_park/miniforge3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/gyeonghoon_park/miniforge3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "y_test_classes = tf.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion MatriX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "            Legitimate  Suspicious\n",
      "Legitimate           0           2\n",
      "Suspicious           0           1\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "class_labels = ['Legitimate', 'Suspicious']\n",
    "\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('1D CNN')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('ROC_Curve_cms_1d_cnn.pdf', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
