{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Flatten, Dense, Conv1D, MaxPooling1D\n",
    "from keras.layers import  BatchNormalization, LeakyReLU, Dropout, Activation\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load csv from Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "CLASSES = np.array(['Legitimate', 'Suspicious'])\n",
    "DATASET_DIR = \"dataset/\"\n",
    "VECTOR_LENGTH = 1 * 816\n",
    "\n",
    "def csvToVector(file_path):\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    vector = data.values.flatten()\n",
    "    return vector\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    subdirs = ['0', '1']\n",
    "\n",
    "    for class_idx, class_name in enumerate(subdirs):\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        for file_name in os.listdir(class_dir):\n",
    "            if file_name.endswith('.csv'):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                vector = csvToVector(file_path)\n",
    "                X.append(vector)\n",
    "                y.append(class_idx)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 816)\n",
      "(8,)\n",
      "[[6350    0    0 ...   29    0   48]\n",
      " [6350    0    0 ...   29    0   48]\n",
      " [6350    0    0 ...   29    0   48]\n",
      " ...\n",
      " [6350    0    0 ...   29    0   48]\n",
      " [6350    0    0 ...   29    0   48]\n",
      " [6350    0    0 ...   29    0   48]]\n",
      "[0 0 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Validation, Test Split and Nomalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "y_val = to_categorical(y_val, NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 816)\n",
      "(3, 816)\n",
      "(1, 816)\n",
      "(4, 2)\n",
      "(3, 2)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(VECTOR_LENGTH, 1))\n",
    "\n",
    "x = Conv1D(filters=32, kernel_size=3, padding='same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Conv1D(filters=64, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Conv1D(filters=128, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(256)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 816, 1)]          0         \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 816, 32)           128       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 816, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 816, 32)           0         \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 408, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 408, 64)           6208      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 408, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 408, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 204, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 204, 128)          24704     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 204, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 204, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 102, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 13056)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               3342592   \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,376,066\n",
      "Trainable params: 3,375,106\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = ModelCheckpoint(\n",
    "    filepath='cp/CMS_CNN_1D_CheckPoint.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lr(epoch, lr):\n",
    "    print(f\"Learning rate for epoch {epoch} is {lr}\")\n",
    "    return lr\n",
    "\n",
    "lr = LearningRateScheduler(print_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate for epoch 0 is 0.0010000000474974513\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.2500\n",
      "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to cp/CMS_CNN_1D_CheckPoint.h5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6931 - accuracy: 0.2500 - val_loss: 0.6992 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 1 is 0.0010000000474974513\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.7500\n",
      "Epoch 2: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.6907 - accuracy: 0.7500 - val_loss: 0.7045 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 2 is 0.0010000000474974513\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.7500\n",
      "Epoch 3: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6871 - accuracy: 0.7500 - val_loss: 0.7117 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 3 is 0.0010000000474974513\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.7500\n",
      "Epoch 4: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6826 - accuracy: 0.7500 - val_loss: 0.7189 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 4 is 0.0010000000474974513\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.7500\n",
      "Epoch 5: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6794 - accuracy: 0.7500 - val_loss: 0.7272 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 5 is 0.0010000000474974513\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6817 - accuracy: 0.7500\n",
      "Epoch 6: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6817 - accuracy: 0.7500 - val_loss: 0.7358 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 6 is 0.0010000000474974513\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6787 - accuracy: 0.7500\n",
      "Epoch 7: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6787 - accuracy: 0.7500 - val_loss: 0.7436 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 7 is 0.0010000000474974513\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6683 - accuracy: 0.7500\n",
      "Epoch 8: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6683 - accuracy: 0.7500 - val_loss: 0.7518 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 8 is 0.0010000000474974513\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6635 - accuracy: 0.7500\n",
      "Epoch 9: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6635 - accuracy: 0.7500 - val_loss: 0.7602 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 9 is 0.0010000000474974513\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6592 - accuracy: 0.7500\n",
      "Epoch 10: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6592 - accuracy: 0.7500 - val_loss: 0.7688 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 10 is 0.0010000000474974513\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6657 - accuracy: 0.7500\n",
      "Epoch 11: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6657 - accuracy: 0.7500 - val_loss: 0.7774 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 11 is 0.0010000000474974513\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6623 - accuracy: 0.7500\n",
      "Epoch 12: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6623 - accuracy: 0.7500 - val_loss: 0.7858 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 12 is 0.0010000000474974513\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6586 - accuracy: 0.7500\n",
      "Epoch 13: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6586 - accuracy: 0.7500 - val_loss: 0.7939 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 13 is 0.0010000000474974513\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6546 - accuracy: 0.7500\n",
      "Epoch 14: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6546 - accuracy: 0.7500 - val_loss: 0.8024 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 14 is 0.0010000000474974513\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6467 - accuracy: 0.7500\n",
      "Epoch 15: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6467 - accuracy: 0.7500 - val_loss: 0.8109 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 15 is 0.0010000000474974513\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6464 - accuracy: 0.7500\n",
      "Epoch 16: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6464 - accuracy: 0.7500 - val_loss: 0.8198 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 16 is 0.0010000000474974513\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6406 - accuracy: 0.7500\n",
      "Epoch 17: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6406 - accuracy: 0.7500 - val_loss: 0.8287 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 17 is 0.0010000000474974513\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6373 - accuracy: 0.7500\n",
      "Epoch 18: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6373 - accuracy: 0.7500 - val_loss: 0.8382 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 18 is 0.0010000000474974513\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6335 - accuracy: 0.7500\n",
      "Epoch 19: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6335 - accuracy: 0.7500 - val_loss: 0.8478 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 19 is 0.0010000000474974513\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6295 - accuracy: 0.7500\n",
      "Epoch 20: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6295 - accuracy: 0.7500 - val_loss: 0.8579 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 20 is 0.0010000000474974513\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6252 - accuracy: 0.7500\n",
      "Epoch 21: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6252 - accuracy: 0.7500 - val_loss: 0.8682 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 21 is 0.0010000000474974513\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6154 - accuracy: 0.7500\n",
      "Epoch 22: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6154 - accuracy: 0.7500 - val_loss: 0.8792 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 22 is 0.0010000000474974513\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6120 - accuracy: 0.7500\n",
      "Epoch 23: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6120 - accuracy: 0.7500 - val_loss: 0.8904 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 23 is 0.0010000000474974513\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6126 - accuracy: 0.7500\n",
      "Epoch 24: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6126 - accuracy: 0.7500 - val_loss: 0.9016 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 24 is 0.0010000000474974513\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6084 - accuracy: 0.7500\n",
      "Epoch 25: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6084 - accuracy: 0.7500 - val_loss: 0.9128 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 25 is 0.0010000000474974513\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.7500\n",
      "Epoch 26: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6156 - accuracy: 0.7500 - val_loss: 0.9243 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 26 is 0.0010000000474974513\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5979 - accuracy: 0.7500\n",
      "Epoch 27: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5979 - accuracy: 0.7500 - val_loss: 0.9363 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 27 is 0.0010000000474974513\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5962 - accuracy: 0.7500\n",
      "Epoch 28: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5962 - accuracy: 0.7500 - val_loss: 0.9490 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 28 is 0.0010000000474974513\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5910 - accuracy: 0.7500\n",
      "Epoch 29: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5910 - accuracy: 0.7500 - val_loss: 0.9610 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 29 is 0.0010000000474974513\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6060 - accuracy: 0.7500\n",
      "Epoch 30: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6060 - accuracy: 0.7500 - val_loss: 0.9732 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 30 is 0.0010000000474974513\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6034 - accuracy: 0.7500\n",
      "Epoch 31: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6034 - accuracy: 0.7500 - val_loss: 0.9853 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 31 is 0.0010000000474974513\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6003 - accuracy: 0.7500\n",
      "Epoch 32: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6003 - accuracy: 0.7500 - val_loss: 0.9973 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 32 is 0.0010000000474974513\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5969 - accuracy: 0.7500\n",
      "Epoch 33: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5969 - accuracy: 0.7500 - val_loss: 1.0099 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 33 is 0.0010000000474974513\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5931 - accuracy: 0.7500\n",
      "Epoch 34: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5931 - accuracy: 0.7500 - val_loss: 1.0228 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 34 is 0.0010000000474974513\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.7500\n",
      "Epoch 35: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6042 - accuracy: 0.7500 - val_loss: 1.0346 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 35 is 0.0010000000474974513\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5737 - accuracy: 0.7500\n",
      "Epoch 36: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5737 - accuracy: 0.7500 - val_loss: 1.0468 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 36 is 0.0010000000474974513\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5715 - accuracy: 0.7500\n",
      "Epoch 37: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5715 - accuracy: 0.7500 - val_loss: 1.0586 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 37 is 0.0010000000474974513\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6021 - accuracy: 0.7500\n",
      "Epoch 38: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6021 - accuracy: 0.7500 - val_loss: 1.0695 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 38 is 0.0010000000474974513\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6009 - accuracy: 0.7500\n",
      "Epoch 39: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6009 - accuracy: 0.7500 - val_loss: 1.0799 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 39 is 0.0010000000474974513\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5758 - accuracy: 0.7500\n",
      "Epoch 40: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5758 - accuracy: 0.7500 - val_loss: 1.0914 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 40 is 0.0010000000474974513\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5735 - accuracy: 0.7500\n",
      "Epoch 41: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.5735 - accuracy: 0.7500 - val_loss: 1.1033 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 41 is 0.0010000000474974513\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5625 - accuracy: 0.7500\n",
      "Epoch 42: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 1.1160 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 42 is 0.0010000000474974513\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5608 - accuracy: 0.7500\n",
      "Epoch 43: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5608 - accuracy: 0.7500 - val_loss: 1.1289 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 43 is 0.0010000000474974513\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5664 - accuracy: 0.7500\n",
      "Epoch 44: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5664 - accuracy: 0.7500 - val_loss: 1.1418 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 44 is 0.0010000000474974513\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5953 - accuracy: 0.7500\n",
      "Epoch 45: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5953 - accuracy: 0.7500 - val_loss: 1.1533 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 45 is 0.0010000000474974513\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5556 - accuracy: 0.7500\n",
      "Epoch 46: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5556 - accuracy: 0.7500 - val_loss: 1.1644 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 46 is 0.0010000000474974513\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5604 - accuracy: 0.7500\n",
      "Epoch 47: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5604 - accuracy: 0.7500 - val_loss: 1.1760 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 47 is 0.0010000000474974513\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5522 - accuracy: 0.7500\n",
      "Epoch 48: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5522 - accuracy: 0.7500 - val_loss: 1.1872 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 48 is 0.0010000000474974513\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5566 - accuracy: 0.7500\n",
      "Epoch 49: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5566 - accuracy: 0.7500 - val_loss: 1.1972 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 49 is 0.0010000000474974513\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.7500\n",
      "Epoch 50: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5543 - accuracy: 0.7500 - val_loss: 1.2067 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 50 is 0.0010000000474974513\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5942 - accuracy: 0.7500\n",
      "Epoch 51: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5942 - accuracy: 0.7500 - val_loss: 1.2159 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 51 is 0.0010000000474974513\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5939 - accuracy: 0.7500\n",
      "Epoch 52: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5939 - accuracy: 0.7500 - val_loss: 1.2240 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 52 is 0.0010000000474974513\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5461 - accuracy: 0.7500\n",
      "Epoch 53: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5461 - accuracy: 0.7500 - val_loss: 1.2323 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 53 is 0.0010000000474974513\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5466 - accuracy: 0.7500\n",
      "Epoch 54: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5466 - accuracy: 0.7500 - val_loss: 1.2403 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 54 is 0.0010000000474974513\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.7500\n",
      "Epoch 55: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5448 - accuracy: 0.7500 - val_loss: 1.2484 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 55 is 0.0010000000474974513\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5799 - accuracy: 0.7500\n",
      "Epoch 56: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5799 - accuracy: 0.7500 - val_loss: 1.2552 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 56 is 0.0010000000474974513\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5406 - accuracy: 0.7500\n",
      "Epoch 57: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5406 - accuracy: 0.7500 - val_loss: 1.2615 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 57 is 0.0010000000474974513\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5437 - accuracy: 0.7500\n",
      "Epoch 58: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5437 - accuracy: 0.7500 - val_loss: 1.2680 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 58 is 0.0010000000474974513\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5931 - accuracy: 0.7500\n",
      "Epoch 59: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5931 - accuracy: 0.7500 - val_loss: 1.2730 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 59 is 0.0010000000474974513\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5349 - accuracy: 0.7500\n",
      "Epoch 60: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.5349 - accuracy: 0.7500 - val_loss: 1.2774 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 60 is 0.0010000000474974513\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.7500\n",
      "Epoch 61: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5330 - accuracy: 0.7500 - val_loss: 1.2819 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 61 is 0.0010000000474974513\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5876 - accuracy: 0.7500\n",
      "Epoch 62: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5876 - accuracy: 0.7500 - val_loss: 1.2877 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 62 is 0.0010000000474974513\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5882 - accuracy: 0.7500\n",
      "Epoch 63: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5882 - accuracy: 0.7500 - val_loss: 1.2918 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 63 is 0.0010000000474974513\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5445 - accuracy: 0.7500\n",
      "Epoch 64: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5445 - accuracy: 0.7500 - val_loss: 1.2952 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 64 is 0.0010000000474974513\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5964 - accuracy: 0.7500\n",
      "Epoch 65: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5964 - accuracy: 0.7500 - val_loss: 1.2959 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 65 is 0.0010000000474974513\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5254 - accuracy: 0.7500\n",
      "Epoch 66: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5254 - accuracy: 0.7500 - val_loss: 1.2964 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 66 is 0.0010000000474974513\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.7500\n",
      "Epoch 67: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5241 - accuracy: 0.7500 - val_loss: 1.2963 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 67 is 0.0010000000474974513\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5460 - accuracy: 0.7500\n",
      "Epoch 68: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5460 - accuracy: 0.7500 - val_loss: 1.2954 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 68 is 0.0010000000474974513\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5460 - accuracy: 0.7500\n",
      "Epoch 69: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5460 - accuracy: 0.7500 - val_loss: 1.2922 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 69 is 0.0010000000474974513\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5994 - accuracy: 0.7500\n",
      "Epoch 70: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5994 - accuracy: 0.7500 - val_loss: 1.2886 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 70 is 0.0010000000474974513\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5926 - accuracy: 0.7500\n",
      "Epoch 71: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5926 - accuracy: 0.7500 - val_loss: 1.2825 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 71 is 0.0010000000474974513\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5447 - accuracy: 0.7500\n",
      "Epoch 72: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5447 - accuracy: 0.7500 - val_loss: 1.2767 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 72 is 0.0010000000474974513\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6000 - accuracy: 0.7500\n",
      "Epoch 73: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6000 - accuracy: 0.7500 - val_loss: 1.2720 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 73 is 0.0010000000474974513\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5434 - accuracy: 0.7500\n",
      "Epoch 74: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5434 - accuracy: 0.7500 - val_loss: 1.2686 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 74 is 0.0010000000474974513\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5950 - accuracy: 0.7500\n",
      "Epoch 75: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5950 - accuracy: 0.7500 - val_loss: 1.2651 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 75 is 0.0010000000474974513\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.7500\n",
      "Epoch 76: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.5415 - accuracy: 0.7500 - val_loss: 1.2608 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 76 is 0.0010000000474974513\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5217 - accuracy: 0.7500\n",
      "Epoch 77: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5217 - accuracy: 0.7500 - val_loss: 1.2592 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 77 is 0.0010000000474974513\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5997 - accuracy: 0.7500\n",
      "Epoch 78: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5997 - accuracy: 0.7500 - val_loss: 1.2570 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 78 is 0.0010000000474974513\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.7500\n",
      "Epoch 79: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5386 - accuracy: 0.7500 - val_loss: 1.2550 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 79 is 0.0010000000474974513\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5374 - accuracy: 0.7500\n",
      "Epoch 80: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5374 - accuracy: 0.7500 - val_loss: 1.2531 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 80 is 0.0010000000474974513\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5982 - accuracy: 0.7500\n",
      "Epoch 81: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5982 - accuracy: 0.7500 - val_loss: 1.2520 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 81 is 0.0010000000474974513\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5993 - accuracy: 0.7500\n",
      "Epoch 82: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5993 - accuracy: 0.7500 - val_loss: 1.2517 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 82 is 0.0010000000474974513\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.7500\n",
      "Epoch 83: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5262 - accuracy: 0.7500 - val_loss: 1.2526 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 83 is 0.0010000000474974513\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5327 - accuracy: 0.7500\n",
      "Epoch 84: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5327 - accuracy: 0.7500 - val_loss: 1.2523 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 84 is 0.0010000000474974513\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5982 - accuracy: 0.7500\n",
      "Epoch 85: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5982 - accuracy: 0.7500 - val_loss: 1.2532 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 85 is 0.0010000000474974513\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6007 - accuracy: 0.7500\n",
      "Epoch 86: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6007 - accuracy: 0.7500 - val_loss: 1.2533 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 86 is 0.0010000000474974513\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6006 - accuracy: 0.7500\n",
      "Epoch 87: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6006 - accuracy: 0.7500 - val_loss: 1.2539 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 87 is 0.0010000000474974513\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5305 - accuracy: 0.7500\n",
      "Epoch 88: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5305 - accuracy: 0.7500 - val_loss: 1.2544 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 88 is 0.0010000000474974513\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5991 - accuracy: 0.7500\n",
      "Epoch 89: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5991 - accuracy: 0.7500 - val_loss: 1.2563 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 89 is 0.0010000000474974513\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5967 - accuracy: 0.7500\n",
      "Epoch 90: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5967 - accuracy: 0.7500 - val_loss: 1.2591 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 90 is 0.0010000000474974513\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5308 - accuracy: 0.7500\n",
      "Epoch 91: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.5308 - accuracy: 0.7500 - val_loss: 1.2630 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 91 is 0.0010000000474974513\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.7500\n",
      "Epoch 92: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5331 - accuracy: 0.7500 - val_loss: 1.2667 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 92 is 0.0010000000474974513\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5333 - accuracy: 0.7500\n",
      "Epoch 93: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5333 - accuracy: 0.7500 - val_loss: 1.2707 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 93 is 0.0010000000474974513\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.7500\n",
      "Epoch 94: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5328 - accuracy: 0.7500 - val_loss: 1.2739 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 94 is 0.0010000000474974513\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.7500\n",
      "Epoch 95: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5316 - accuracy: 0.7500 - val_loss: 1.2798 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 95 is 0.0010000000474974513\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5962 - accuracy: 0.7500\n",
      "Epoch 96: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5962 - accuracy: 0.7500 - val_loss: 1.2881 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 96 is 0.0010000000474974513\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5332 - accuracy: 0.7500\n",
      "Epoch 97: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5332 - accuracy: 0.7500 - val_loss: 1.2956 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 97 is 0.0010000000474974513\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.7500\n",
      "Epoch 98: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5334 - accuracy: 0.7500 - val_loss: 1.3034 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 98 is 0.0010000000474974513\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.7500\n",
      "Epoch 99: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5956 - accuracy: 0.7500 - val_loss: 1.3135 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Learning rate for epoch 99 is 0.0010000000474974513\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6023 - accuracy: 0.7500\n",
      "Epoch 100: val_accuracy did not improve from 0.00000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6023 - accuracy: 0.7500 - val_loss: 1.3182 - val_accuracy: 0.0000e+00 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ded2c400>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=32, \n",
    "          epochs=100, \n",
    "          shuffle=True,\n",
    "          callbacks=[lr, cp]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 346ms/step - loss: 0.6952 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6951704025268555, 0.3333333432674408]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_model = load_model('cp/CMS_CNN_1D_CHeckPoint.h5')\n",
    "cp_model.evaluate(X_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 232ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = cp_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_single = CLASSES[np.argmax(y_pred, axis = -1)]\n",
    "actual_single = CLASSES[np.argmax(y_test, axis = -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(X_test)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    data = X_test[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i+1)\n",
    "    ax.plot(data)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.2, 'pred = ' + str(preds_single[idx]), fontsize=10, ha='center', transform=ax.transAxes) \n",
    "    ax.text(0.5, -0.4, 'act = ' + str(actual_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.17      0.50      0.25         3\n",
      "weighted avg       0.11      0.33      0.17         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gyeonghoon_park/miniforge3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/gyeonghoon_park/miniforge3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/gyeonghoon_park/miniforge3/envs/TF/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "y_test_classes = tf.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion MatriX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "            Legitimate  Suspicious\n",
      "Legitimate           0           2\n",
      "Suspicious           0           1\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "class_labels = ['Legitimate', 'Suspicious']\n",
    "\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAHaCAYAAABM0zOsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB77klEQVR4nO3dd1xV9R/H8dcFWaKAyhAN997mQCsHppIz9145y1X5K3eunJlm5dYc5Z6ZIzeU2xyYhntrLlRUQOb9/v64evUGKOC9nAt8no8Hj8dZ95wPR+TN94zvV6eUUgghhBDC7Gy0LkAIIYRIryRkhRBCCAuRkBVCCCEsREJWCCGEsBAJWSGEEMJCJGSFEEIIC5GQFUIIISxEQlYIIYSwEAlZIYQQwkIkZIUQQggLkZAVwkqEhYUxcuRIPvjgA7Jnz45Op2PRokUJbluzZk10Oh06nQ4bGxtcXFwoWrQoHTt2ZMeOHck+dmBgIM2aNSNnzpzY29vj6elJo0aNWLdunXGbK1euGI+5du3aePsYNWoUOp2OkJAQ47IuXbqg0+koU6YMCfXgqtPp6Nu3b7LrFSKtkJAVwkqEhIQwZswYTp8+TdmyZV+7/VtvvcUvv/zCzz//zOTJk2ncuDH79++nbt26tG7dmpiYmCQdd+TIkfj5+XHq1Cl69erF7Nmz+fLLLwkLC6N58+YsW7Ys3mfGjBmTYGgm5uTJkyaBLURGkUnrAoQQBt7e3ty6dYucOXNy5MgRKlWq9MrtXV1d6dChg8myiRMn0r9/f2bOnEm+fPmYNGnSK/exZs0axowZQ4sWLVi2bBl2dnbGdV9++SXbtm2LF9blypUjKCiI9evX06xZs9d+X05OTvj4+DBmzBiaNWuGTqd77WeESC+kJSuElXBwcCBnzpxvtA9bW1t++OEHSpQowfTp03n06NErt//qq6/Inj07CxYsMAnY5/z9/WnYsKHJsjZt2lCkSJEkt2ZtbGwYPnw4f//9N+vXr0/eNyREGichK0Q6Y2trS9u2bYmIiGDv3r2Jbnf+/HnOnDlDkyZNyJo1a7L2P3z4cE6cOJHk0GzXrh2FCxdO9mVmIdI6CVkh0qFSpUoBcPHixUS3OX36NAClS5dO9v6TG5ovB/Ovv/6a7OMJkVZJyAqRDmXJkgWAJ0+eJLrN48ePAZLVin0uJaHZvn17ac2KDEdCVoh0KCwsDHh1gLq4uACvDuJXad++PYUKFUp2azYoKEhasyLDkJAVIh06deoUAIUKFUp0m2LFigGG12tS4uXQ3LBhQ5I+k9xgFiKtk5AVIp2Ji4tj2bJlZM6cmffeey/R7YoUKULRokXZsGGDseWbXB06dKBQoUKMHj062a3ZpAazEGmZhKwQ6UhcXBz9+/fn9OnT9O/f33hJODGjR4/m/v37dO/endjY2Hjrt2/fzqZNmxL9/Muh+dtvvyWpxpeDWYj0TjqjEMKKTJ8+ndDQUP79918ANm7cyI0bNwDo168frq6uxm0fPXrEkiVLAIiIiODChQusW7eOixcv0qZNG77++uvXHq9169acPHmScePGcfz4cdq2bUvevHm5f/8+W7duZdeuXQn2+PSy9u3b8/XXXxMUFJSk79HW1pZhw4bx0UcfJWl7IdI0JYSwGnnz5lVAgl+XL182blejRg2TdVmyZFGFCxdWHTp0UNu3b0/2cXft2qU+/PBD5enpqTJlyqQ8PDxUo0aN1IYNG4zbXL58WQFq8uTJ8T6/cOFCYy337t0zLu/cubNydnaOt31MTIwqWLCgAlSfPn2SXa8QaYVOKXn6QAghhLAEuScrhBBCWIiErBBCCGEhErJCCCGEhUjICiGEEBYiISuEEEJYiISsEEIIYSEZvjMKvV7Pv//+S9asWdHpdFqXI4QQQiNKKZ48eUKuXLmwsTFTG1Tj93RN/PHHH6phw4bK29tbAWr9+vWv/UxAQIAqX768sre3VwULFlQLFy5M1jGvX7+e6Mv/8iVf8iVf8pXxvq5fv56yEEuAVbVkw8PDKVu2LF27dqVZs2av3f7y5cs0aNCAjz/+mKVLl7Jr1y66d++Ot7c3/v7+STrm86HArl+//tp+XoUQQqRTSvH4+t/4lK6eojGWE2NVIVuvXj3q1auX5O1nz55N/vz5mTJlCgDFixdn7969fPfdd0kO2eeXiF1cXCRkhRAig1JXdsKGOgBmvXWYph98OnDgALVr1zZZ5u/vz4EDBxL9TFRUFI8fPzb5EkIIkXEd2L+fSrWa8K8F4iBNh+zt27fx8vIyWebl5cXjx495+vRpgp+ZMGECrq6uxi8fH5/UKFUIIYQV2r9/P/7+dTh6OZwG882//zQdsikxZMgQHj16ZPy6fv261iUJIYTQwL59+/D39+dJWAQAedzMf4w0HbI5c+bkzp07Jsvu3LmDi4sLTk5OCX7GwcHBeP9V7sMKIUTGtHfvXvz9/QkLCwOgThFY0b+w2Y+TpkO2atWq7Nq1y2TZjh07qFq1qkYVCSGEsHZ79uzhgw8+IDw8HIC6RWDDR+D03lCzH8uqQjYsLIygoCCCgoIAwys6QUFBXLt2DTBc6u3UqZNx+48//phLly4xcOBAzpw5w8yZM1m1ahWff/65FuULIYSwcn/88Qf16tUzBqx/0WcBm7MkFGpi9uNZVcgeOXKE8uXLU758eQAGDBhA+fLlGTFiBAC3bt0yBi5A/vz52bx5Mzt27KBs2bJMmTKF+fPnJ/n1HSGEEBlHYGAg9evXNwbsB2Vc+bULONoBVUeCzvyRqFNKKbPvNQ15/Pgxrq6uPHr0SO7PCiFEOvbll1/y7bffAlC/ZkXW+h8xBKx7aegUxOMnYWbPA6vqjEIIIYSwlG+++YaIiAiuXr3K2ua3cHjwbIWFWrEgISuEECKD0Ol0TJ8+nZizG7Df3NSw0KMMFG5qsWNa1T1ZIYQQwlx27tzJX3/9ZbJMB9gfGfdiQdVRFmvFgoSsEEKIdGj79u00atSIOnXqcOTIkRcrLm2CO8/mPcpZ5Inil0nICiGESFe2bdtG48aNiYyM5NGjR8yYMcOwQinYP+rFhlVHgoXHEZeQFUIIkW5s3bqVDz/8kKioKACaNm3K3LlzDSsv/gZ3jxmmPctDoQ8tXo+ErBBCiHTh999/NwnY5s2bs3LlSuzs7BJoxY6yeCsWJGSFEEKkA1u2bKFJkyZER0cD0KJFC5YvX24IWIALG+BekGHaqwIUbJQqdUnICiGESNM2bdpE06ZNjQHbsmVLli1b9iJglR4OjHrxgVRqxYKErBBCiDTs+vXrtGjRwhiwrVu3Ng1YgAu/wr0ThmmvilCgQarVJyErhBAizfLx8WHatGkAtGnThiVLlpAp00v9LCm96b3Yd0alWisWpMcnIYQQadzHH39MwYIF8fPzMw1YgPPrIOSkYTpnZchfP1Vrk5asEEKINOX27dvxltWpUyd+wCo9HBj9Yj6VW7EgISuEECINWbduHfnz52f16tWv3/jcWgg5ZZj29oV8H1i2uARIyAohhEgT1q5dS6tWrYiMjKRt27YcOnQo8Y3jtWJHp3orFiRkhRBCpAGrV6+mdevWxMXFAdCxY0cqVqyY+AfOrob7/ximvatC3rqpUGV8ErJCCCGs2qpVq2jbtq0xYD/66CN++uknbG1tE/6APk7ze7HPScgKIYSwWitXrqRdu3bGgO3WrRvz58/HxuYV8XV2FTw4bZjO9Q7krZMKlSZMQlYIIYRVWr58uUnAdu/enblz5746YPVxcHDMi3mN7sU+JyErhBDC6ixfvpwOHTqg1+sB6NGjB3PmzHl1wAKcXQkPzhimc78Hed63cKWvJiErhBDC6nh5eWFvbw9Ar169mD179usDVh8HB6ynFQvS45MQQggrVKtWLTZt2sTGjRuZOnXq6wMW4MxyeHjWMP1WdfDxs2yRSSAhK4QQwiq9//77vP9+Ei/36mNN78Wm4kg7ryKXi4UQQmhu8eLFjB49+vUbJub0Mnh43jD9Vg3Io30rFqQlK4QQQmMLFy6kW7duKKUAGDlyZPJ2oI+Fg1+/mH/nDcLazKQlK4QQQjMLFiwwCdgHDx4Yp5Ps9FIIvWCY9vEDnxpmrjLlJGSFEEJoYv78+SYB++mnnzJt2jR0ybmXasWtWJCQFUIIoYG5c+fSo0cP4/znn3/Od999l7yABQj+BUIvGqbzvA9vVTNjlW9OQlYIIUSqmjNnDr169TLO/+9//2PKlCnJD9i4GNNWbNVR5inQjCRkhRBCpJrZs2fz8ccfG+e//PJLJk+enPyABQj+GR5dNkznqQ1vvWemKs1HQlYIIUSqePLkCWPHjjXODxw4kEmTJqUsYONi4OCLfVnbvdjnJGSFEEKkiqxZs7J79268vb0ZPHgwEydOTFnAAvyzGB5fMUznrQu53zFbneYk78kKIYRINUWKFOHEiRO4u7unPGDjouGQ9bdiQVqyQgghLGjz5s3ExMSYLPPw8Eh5wAL8swgeXzVM5/sAclVJ+b4sTEJWCCGERXz33Xc0bNiQDh06EBsba56dxkXDwXEv5t8ZZZ79WoiErBBCCLObOnUqAwYMAGDVqlX8+uuv5tnxqQXw5JphOn898PY1z34tREJWCCGEWX377bf873//M86PGjWKFi1avPmOY6Pg0PgX81b4Xux/ScgKIYQwm8mTJ/Pll18a50ePHp38Dv8Tc2oBPLlumC7QALwrm2e/FiQhK4QQwiwmTZrEwIEDjfNff/01I0aMMM/O02ArFiRkhRBCmMGECRMYPHiwcX7s2LEMHz7cfAc4OR/CbhimCzSEnBXNt28LkvdkhRBCvJGFCxcydOhQ4/z48eMZMmSI+Q4QGwmHX2rFWvkTxS+TlqwQQog30qRJEypUqADAxIkTzRuw8KwV+69humBj8Kpg3v1bkLRkhRBCvJFs2bKxY8cONmzYQJcuXcy789hIODzhxXwauRf7nLRkhRBCJFtkZKTJfLZs2cwfsAB/z33Rii3UBLzKm/8YFiQhK4QQIllGjRpFtWrVCA0NteyBYp7+pxVrpleBUpGErBBCiCRRSjFy5EhGjx7NkSNHqFu3LtHR0ZY74N9zIPy2YbpQU/AsZ7ljWYjckxVCCPFaSilGjBhhMh5su3btsLe3t8wBYyLg8MQX82noieKXScgKIYR4JaUUw4cPZ/z4F6/RfP/99/Tv399yB/17DkTcMUwXbg4eZSx3LAuSkBVCCJEopRTDhg1jwoQX90Z//PFH+vbta7mDxkTA4Ukv5tPgvdjnJGSFEEIkSCnFkCFDmDTpReBNnz6dPn36WPbAJ2a9aMUWaQkepS17PAuSkBVCCBGPUopBgwYxefJk47IZM2bQu3dvyx44JvylVqwOqpqp72ONSMgKIYSIR6/Xc+XKFeP8rFmz+Pjjjy1/4KCZ8PSeYbpIS3AvZfljWpCErBBCiHhsbW1ZunQpALVr16Znz56WP2h0GPz1zbMZHbyTdu/FPichK4QQIkF2dnasXLkSnU6XOgcMmglPQwzTRVtDjhKpc1wLks4ohBBCoJRi9OjRnDt3zmR5qgVsdBgceX7/N+3fi31OQlYIITI4pRSfffYZo0aNws/Pj/Pnz6d+Ecenv2jFFmsLOYqnfg0WICErhBAZmFKK/v3788MPPwBw69Ytjhw5krpFRD950YrV2UCVr1L3+BYk92SFECKDUkrRt29fZs6cCRguDS9cuJC2bdumbiHHf4TIB4bpYm0hR7HUPb4FScgKIUQGpNfr6du3L7NmzQIMAbt48WI6duyYuoVEPYYj3xqmdTZQJX3ci31OQlYIITIYvV5Pnz59mD17NgA2NjYsXryYDh06pH4xx3+EyIeG6eLtIXuR1K/BgiRkhRAiA9Hr9XzyySfMnTsXMATszz//TPv27VO/mKhHcHSKYVpnm67uxT4nISuEEBnI5s2bTQJ2yZIlqX8P9rljP7xoxZboANkKa1OHBcnTxUIIkYE0atSIESNGYGtry7Jly7QL2MhQODrVMK2zBd/h2tRhYdKSFUKIDGbUqFG0bNmSUqU07Bf42PcQFWqYLtERshXSrhYLkpasEEKkY3FxcZw6dcpkmU6n0zZgI0Ph2HfPirGFKumzFQtWGLIzZswgX758ODo64uvry+HDh1+5/bRp0yhatChOTk74+Pjw+eefExkZmUrVCiGE9YqLi6Nbt25UrlyZgIAArct54dg0w0NPACU7g1tBTcuxJKsK2ZUrVzJgwABGjhzJsWPHKFu2LP7+/ty9ezfB7ZctW8bgwYMZOXIkp0+f5qeffmLlypUMHTo0lSsXQgjrEhcXx0cffcTixYt5+vQpTZs25eHDh1qXZXjQ6eizVqxNpnTdigUrC9mpU6fSo0cPPvroI0qUKMHs2bPJnDkzCxYsSHD7/fv38+6779KuXTvy5ctH3bp1adu27Wtbv0IIkZ7FxcXRpUsXfvnlFwAyZcrEwoULyZYtm8aVYQjY6MeG6ZJdwDW/puVYmtWEbHR0NEePHqV27drGZTY2NtSuXZsDBw4k+Jl33nmHo0ePGkP10qVLbNmyhfr16yd6nKioKB4/fmzyJYQQ6UVsbCydOnViyZIlgGG4ujVr1tC0aVONKwOePjBcKgZDK9Z3mKblpAarebo4JCSEuLg4vLy8TJZ7eXlx5syZBD/Trl07QkJCeO+991BKERsby8cff/zKy8UTJkxg9OjRZq1dCCGswfOAXb58OfAiYBs3bqxxZc8cnWoYDACg5Efgmk/TclKD1bRkUyIwMJDx48czc+ZMjh07xrp169i8eTNff/11op8ZMmQIjx49Mn5dv349FSsWQgjLiI2NpWPHjiYBu3btWusJ2Kf34bhhpB9s7KBK+m/FghW1ZN3d3bG1teXOnTsmy+/cuUPOnDkT/MxXX31Fx44d6d69OwClS5cmPDycnj17MmzYMGxs4v8N4eDggIODg/m/ASGE0FCXLl1YsWIFAPb29qxdu5aGDRtqXNVLXm7FluoKLnm1rSeVWE1L1t7engoVKrBr1y7jMr1ez65du6hatWqCn4mIiIgXpLa2toBhCCchhMgoGjdujK2tLfb29qxfv966AjYixNCFIhhasb4Z5w0Qq2nJAgwYMIDOnTtTsWJFKleuzLRp0wgPD+ejjz4CoFOnTuTOnZsJEyYAhu7Bpk6dSvny5fH19eXChQt89dVXNGrUyBi2QgiREbRq1QqlFFmzZn3lw5+aODoFYsIM06W7g0sebetJRVYVsq1bt+bevXuMGDGC27dvU65cObZu3Wp8GOratWsmLdfhw4ej0+kYPnw4N2/exMPDg0aNGjFu3DitvgUhhEgVSil0Op3JstatW2tUzStE3DMMZwdgaw+Vh2hbTyrTqQx+XfXx48e4urry6NEjXFxctC5HCCFeKzo6mrZt2+Lv70/Pnj21LufV/hwEf31jmC7bG2rP0LaeV7BEHlhVS1YIIcSrRUdH06pVKzZs2MC6deuwsbExPvxpdSLuwfHphmlbe/DNWK1YkJAVQog0IyoqipYtW7Jx40YAHB0dyZcvn7ZFvcpfkyE2wjBduidkfUvbejQgISuEEGlAVFQULVq0YNOmTQA4OTmxceNG3n//fY0rS0TEXQh6dmnY1iFDtmJBQlYIIaxeVFQUzZs3Z/PmzYAhYDdt2kStWrU0ruwVDn/zohVbphdkyaVtPRqRkBVCCCsWGRlJ8+bN2bJlC2AI2M2bN+Pn56dxZa8QfhtOzDRMZ3KEyoO1rUdDErJCCGGlIiMjadq0KVu3bgUgc+bMbN68mZo1a2pb2Ov89Q3EPjVMl+kFWby1rUdDErJCCGGlLl26ZByFzNnZmS1btlC9enWNq3qN8NtwYpZhOpMjVBqkbT0as5puFYUQQpgqUaIEO3bsIHfu3Pz+++/WH7AAhydBbKRhuuwnGboVC9KSFUIIq1apUiUuXLiAo6Oj1qW8Xtgt+Hu2YTqTU4ZvxYK0ZIUQwmpEREQwY8aMeAOcpImABTg88aVWbG9w9nr19hmAtGSFEMIKRERE0KhRI3bv3s3Zs2f5/vvv4/VNbNWe3IS/5ximMzlB5YHa1mMlpCUrhBAaCw8Pp2HDhuzevRuARYsWcfnyZY2rSqbDEyEuyjBdrg9k9tS2HishISuEEBp6HrABAQEAuLi4sH37dgoUKKBxZcnw5CacnGuYzpQZKn2pbT1WRC4XCyGERsLDw2nQoAF//PEH8CJgfX19Na4smQ5PgLhow3T5vtKKfYm0ZIUQQgNhYWHUr1/fGLCurq7s2LEj7QXs4+twcp5h2s4ZKkor9mXSkhVCiFT25MkT6tevz969e4EXAVupUiWNK0sBk1ZsP8jsrm09VkZaskIIkcr69u1rDFg3Nzd27tyZNgP28TU4Od8wbZcFKvxP23qskISsEEKksnHjxlGwYEGyZcvGrl27qFixotYlpcyh8aCPMUxLKzZBcrlYCCFS2VtvvUVgYCAhISGUK1dO63JS5vFVOLXAMG2fFSpKKzYhErJCCGFhjx8/xs7ODicnJ+Oyt956i7feekvDqt6QSSu2Pzjl0LYeKyWXi4UQwoIePXpE3bp1adKkCU+fPtW6HPN4dOWlVqwLVBigaTnWTEJWCCEsJDQ0lLp163Lo0CG2b99O9+7dtS7JPA6NA32sYfrtT8Epu7b1WDG5XCyEEBbwPGD/+usvANzd3Rk8eLDGVZnBo8vwzyLDtL0LVPhc03KsnbRkhRDCzB4+fEidOnWMAevh4UFAQAClS5fWuDIzOPhyK/YzcMymaTnWTlqyQghhRs8D9ujRowB4enqye/duSpYsqXFlZhB66UUr1sFVWrFJICErhBBm8uDBA+rUqcOxY8cAQ8AGBARQokQJjSszk4NjQcUZpt/+HBzdNC0nLZDLxUIIYQYPHjygdu3axoD18vJKXwH78AIE/2yYdnCDCp9pWU2aIS1ZIYQwA0dHR9zc3IAXAVu8eHFtizKnQy+1YisMMFwuFq8lLVkhhDCDzJkzs3HjRlq3bk1gYGD6CtiH5yH4F8O0YzZ4u7+29aQh0pIVQggzcXZ2ZsWKFVqXYX4Hx4LSG6alFZss0pIVQogUuHfvHi1atODWrVtal2JZD87B6SWGacfshi4URZJJyAohRDLdvXuXWrVqsXbtWmrVqsXt27e1LslyDn79ohVb8X/g4KJtPWmMXC4WQohkuHPnDrVq1SI4OBiAsLAwwsPDNa7KQh6chTPLDNOOOQzD2YlkeaOQjYqK4tixY9y9e5d3330Xd3cZS1AIkX7dvn2bWrVqcfr0aQB8fHwICAigYMGCGldmIQfGvNSK/cIwpJ1IlhRfLv7hhx/w9vbmvffeo1mzZvz9998AhISE4O7uzoIFC8xWpBBCaO327dv4+fmZBGxgYGD6Ddj7p+HMcsO0Yw4o31fbetKoFIXswoUL+eyzz/jggw/46aefUEoZ17m7u1OrVq30+YSdECJDunXrFn5+fpw5cwaAPHnyEBgYSIECBTSuzIIOfg08+91e6Uuwz6JpOWlVikJ2ypQpfPjhhyxbtoxGjRrFW1+hQgX++eefNy5OCCG09u+//1KzZk1jwObNmzf9B+z9YDjzrKHk5A7l+mhbTxqWopC9cOEC9erVS3R99uzZuX//foqLEkIIazF//nzOnTsHQL58+QgMDCR//vwaV2VhB8bwohU7UFqxbyBFDz65ubkREhKS6Prg4GBy5syZ4qKEEMJaDB8+nBs3brBjxw4CAwPJmzev1iVZVsg/cHaVYTqzJ5TrrW09aVyKWrL169dn7ty5hIaGxlv3zz//MG/ePBo3bvymtQkhhOZsbGyYPXs2hw4dSv8BC3BgNCatWDtnTctJ63Tq5aeWkujff//F19cXpRSNGjVi7ty5dOjQgbi4ONauXYu3tzeHDx9OE6/0PH78GFdXVx49eoSLi7xkLURGd/36de7fv0+5cuW0LiX13TsJP5cxTGf2hO6XwS6ztjWlIkvkQYpasrly5eLo0aN88MEHrFy5EqUUv/zyCxs3bqRt27YcPHgwTQSsEEK87Nq1a9SsWZP333+foKAgrctJfQfHvJiuNChDBaylpKgl+1/37t1Dr9fj4eGBjU3a6qlRWrJCCHgRsJcvXwagSpUq7N+/H51Op3FlqeTe3/BzWcN0Zi/ofinDhazVtGS7du3KoUOHjPMeHh54eXkZA/bw4cN07drVLAUKIYSlXb161SRgCxcuzJo1azJOwMKze7HPVB6c4QLWUlIUsosWLeLixYuJrr98+TKLFy9OcVFCCJFarly5YhKwRYoUISAggNy5c2tcWSq6GwTn1xmmnb2hTC9Ny0lPLDJAwL///ouTk5Mldi2EEGbzPGCvXr0KvAjYXLlyaVxZKovXipXf3+aS5JDdsGEDGzZsMM7PnTuXnTt3xtsuNDSUnTt3UqlSJfNUKIQQFnD58mVq1qzJtWvXAChatCgBAQF4e3trXFkqu3McLvxqmHb2hjI9NS0nvUlyyAYHB7N69WoAdDodhw4d4ujRoybb6HQ6nJ2dqV69OlOnTjVvpUIIYSZhYWH4+fkZA7ZYsWIEBARkzE50TFqxQyCTo3a1pEMperrYxsaGJUuW0K5dO0vUlKrk6WIhMqbp06fTr18/ihcvTkBAAF5eXlqXlPruHIMlFQzTWXJDtwsZOmQtkQcpuier1+vNcnAhhNBK3759cXV1pW7duhkzYAH2j3oxLa1Yi7DIg09CCGFtoqKicHBwMFnWsWNHjaqxArePwKWNhuksb0Hp7trWk06luOeI33//nTp16pAjRw4yZcqEra1tvC8hhLAG586do2jRoqxfv17rUqzHgVEvpn2HQiaHRDcVKZeikF27di0NGzbkzp07tGnTBr1eT9u2bWnTpg1OTk6UKVOGESNGmLtWIYRItrNnzxpf02nVqhXbt2/XuiTt3f4LLm02TGf1gVLSeZClpChkJ0yYQOXKlTl+/DijRxueTOvatStLly7l1KlT3Lp1K/2PtyiEsHpnzpzBz8+PW7duAVCiRAnefvttjauyAi/fi5VWrEWlKGSDg4Np06YNtra2ZMpkuK0bExMDGAY17t27N5MmTTJflUIIkUz/DdiyZcuya9cuGbzk1iG4vMUwnTWPtGItLEUhmzlzZuzt7QHDAO4ODg7GH2QALy8vYxdlQgiR2k6fPk3NmjW5ffs2AOXKlZOAfe7lVmyVYWBrr1kpGUGKQrZo0aIEBwcb58uVK8cvv/xCbGwskZGRLFu2jDx58pitSCGESKrg4GBq1qzJnTt3AChfvjy7du0iR44cGldmBf49AFe2GqZd8kLJLpqWkxGkKGSbNm3Khg0biIqKAmDYsGEEBgbi5uaGh4cHe/bsYfDgwWYtVAghXueff/6hZs2a3L17F4C3336bnTt3kj17do0rsxIm92KHSys2FZhlPFmAPXv2sG7dOmxtbWnQoAF+fn7m2K3FSY9PQqQfO3fupGHDhkRFRVGhQgV27NhBtmzZtC7LOtzcDyveNUy75IOu58DWTtOSrI0l8sBsIftfT548IWvWrJbYtVlJyAqRvmzbto2xY8eyceNG3NzctC7HeqypC1d3GKbrzofS3bStxwpZzaDtr3L37l2GDh0q92SFEJrw9/fnzz//lIB92c19LwLWtQCU6KRtPRlIsrpVvHv3Lj///DMXL14kW7ZsNG/enAoVDJ1L37x5k3HjxrFo0SIiIyOpWbOmJeoVQgijEydOsHv3bj7//HOT5TqdTqOKrNT+kS+mqwyXy8SpKMkhe+bMGapXr879+/d5foX5m2++YcmSJeh0Orp3705kZCTNmzfnyy+/NIavEEJYQlBQEO+//z4PHjwgMjKSIUOGaF2SdbqxB67tMky7FYQSGbi/Zg0k+XLxV199RVhYGDNnzuTUqVNs3LiRAgUK8Nlnn9GlSxfq1avH2bNnWbFihQSsEMKijh8/bgxYgI0bNxIdHa1xVVbKpBX7FdjIuDCpKcln+88//+STTz6hV69egKF7skyZMlGvXj06d+7MwoULLVakEEI8d+zYMWrXrs3Dhw8BeOedd/j999+NHeSIl1z/A64HGKbdCkHx9trWkwEluSV7//59ypQpY7KsbNmygOG9WXOZMWMG+fLlw9HREV9fXw4fPvzK7UNDQ+nTpw/e3t44ODhQpEgRtmzZYrZ6hBDW4+jRo7z//vvGgH333XfZunWrvBmQmJdH2pFWrCaSfMb1ej12dqY3y5/PZ8mSxSzFrFy5kgEDBjB79mx8fX2ZNm0a/v7+nD17Fk9Pz3jbR0dHU6dOHTw9PVmzZg25c+fm6tWr8lShEOnQkSNHqFOnDqGhoQC89957bNmyJU28KqiJ64GGL4BshaF4O+1qycCS9WfNkSNHcHR0NM4/efIEnU7H3r17jT/4L2vWrFmyipk6dSo9evTgo48+AmD27Nls3ryZBQsWJNiD1IIFC3jw4AH79+83Bn6+fPmSdUwhhPX766+/qFOnDo8ePQKgWrVqbNmyxWx/4Kc7Sv3nXuwIacVqJMmdUdjYJO+VWp1OR1xcXJK3j46OJnPmzKxZs4YmTZoYl3fu3JnQ0FA2bNgQ7zP169cne/bsZM6cmQ0bNuDh4UG7du0YNGhQooPGR0VFGbuDBMPLxz4+PtIZhRBWKi4ujpIlS3L27FkAatSowaZNmyRgX+Xablj9vmE6W1Ho8g/YJPw7Ubxgic4okvynTUBAgFkOmJiQkBDi4uLw8vIyWe7l5cWZM2cS/MylS5fYvXs37du3Z8uWLVy4cIHevXsTExPDyJEjE/zMhAkTjGPgCiGsn62tLevXr6dmzZqUKFGCTZs24ezsrHVZ1uu/rdiqIyRgNZTkkK1Ro4Yl60gRvV6Pp6cnc+fOxdbWlgoVKnDz5k0mT56caMgOGTKEAQMGGOeft2SFENarePHi7N27l1y5cknAvs613XBzr2E6ezEo2lrbejI4q7lI7+7ujq2trXF4qufu3LlDzpw5E/yMt7c3dnZ2JpeGixcvzu3bt4mOjk7wkX4HBwccHBzMW7wQwqxOnz5N4cKFyZTpxa+owoULa1hRGpHgvVhpxWrJ7H0Xp5S9vT0VKlRg165dxmV6vZ5du3ZRtWrVBD/z7rvvcuHCBfR6vXHZuXPn8Pb2lnfmhEij9u3bR+XKlencuXOynusQwNWd8O8+w3T24lC0lbb1COsJWYABAwYwb948Fi9ezOnTp/nkk08IDw83Pm3cqVMnk67TPvnkEx48eMCnn37KuXPn2Lx5M+PHj6dPnz5afQtCiDewd+9e/P39CQsLY9myZXz33Xdal5R2xLsXO1JasVbAai4XA7Ru3Zp79+4xYsQIbt++Tbly5di6davxYahr166ZPOXs4+PDtm3b+PzzzylTpgy5c+fm008/ZdCgQVp9C0KIFNqzZw/16tUjPDwcgLp168ofzMlxdTvcOmCYzlESirbUth4BWHA82bRCxpMVQnt//vkn9evXNwbsBx98wPr1603eyxevoBQsrwq3DhnmG66SkE2BNDGerBBCJMcff/xh0oKtV6+eBGxyXdn2ImDdS0GR5trWI4xSHLLXrl3j448/pmjRomTPnp0///wTMLzv2r9/f44fP262IoUQ6VNgYCD169cnIiICMHQws27dOgnY5EjoXqxO2k/WIkX3ZIODg6lWrRp6vR5fX18uXLhAbGwsYHgVZ+/evYSHh/PTTz+ZtVghRPqxf/9+6tevz9OnTwFo0KABa9eulVfskuvy73D72UAqHmWgcPK6sxWWlaI/dwYOHIibmxvnzp1jyZIl/Pe2boMGDdizZ49ZChRCpE9FixalaNGiADRq1EgCNiWkFWv1UvSv8XxsWQ8PD3Q6Xbz1efLk4ebNm29cnBAi/cqRIwc7d+7kiy++YPXq1RKwKXFpM9w5Ypj2KAuFmmhajogvRZeL9Xo9mTNnTnT9vXv35D+MECIepZTJH+Y5cuRg8uTJGlaUhillOl5s1VHSirVCKfoXefvtt9m8eXOC62JjY1mxYgVVqlR5o8KEEOnL9u3bqVWrlnG4OvGGLm2CO0cN0x7loNCHmpYjEpaikB0yZAhbt27lk08+4dSpU4Chj+GdO3dSt25dTp8+neD4r0KIjGnbtm00btyYwMBAPvjgA548eaJ1SWmbUrB/1Iv5d0ZBArfuhPZSdLm4Xr16LFq0iE8//ZS5c+cC0KFDB5RSuLi48PPPP1O9enWzFiqESJt+//13mjZtahzHOXfu3PKKzpu6+BvcPWaY9nwbCjbWth6RqDfq8Sk8PJwdO3Zw/vx59Ho9BQsWxN/fn6xZs5qzRouSHp+EsJwtW7bQtGlToqOjAWjRogXLli3Dzs5O48rSMKXgl7fhXpBhvslvULCRpiWlF5oO2v6y5w8vODs706RJE7MUIoRIXzZt2kTz5s2NAduqVSuWLFkiAfumLvz6ImC9KkKBhlpWI14jRfdkn3fEv2/fPnPXI4RIBzZu3EizZs2MAdu6dWuWLl0qAfumlB4OjH4xL/dirV6KQrZGjRosWLCA6tWrkydPHr744gsOHz5s7tqEEGnQb7/9RvPmzYmJiQGgTZs2LFmyxGQAdpFCF36FeycM0zkrQf76mpYjXi9FIbt8+XLu3r3LihUrqFy5MrNmzaJq1aoULFiQoUOHEhQUZOYyhRBpxbJly4wB265dO3755RcJWHNQetMniquOklZsGmCWoe7Cw8P57bffWLlyJdu2bSM6OprChQtz5swZc9RoUfLgkxDmFR0dTatWrciSJQuLFy/G1lYGDjeLc2tg47Ph67x9oe0BCVkzs0QemHU82bCwMBYtWsSwYcMICwsjLi7OXLu2GAlZIcwvOjoaW1tbCVhzUXr4uSyEGPoloNnvkP8DbWtKh6zm6eKXRURE8Ntvv7Fq1Sq2bt1KVFQUBQsWpH///uaoTwhh5X777TdKlixJwYIFjcvs7e01rCgdOrfmRcB6V4F8/trWI5IsRSEbGRnJ5s2bWblyJVu2bCEiIoJ8+fLRv39/WrduTfny5c1dpxDCCq1evZq2bduSK1cuAgMDKVCggNYlpT/xnigeLZeJ05AUhayHhwcRERHkypWLnj170rp1a3x9fc1dmxDCiq1atYp27doRFxfH9evXmTt3LhMnTtS6rPTn7Gq4H2yYzvUO5K2jbT0iWVIUsl26dKF169a899575q5HCJEGrFixgg4dOhifu+jatSvjx4/XuKp0SB9n2oqVJ4rTnBSF7I8//mjuOoQQacTy5cvp0KEDer0egO7duzNnzhxsbGSYNbM7uwoenDZM53oX8tbWth6RbEkK2T///BPA2On/8/nXkUEChEhfli1bRseOHY0B26NHD2bPni0Bawn6ODg45sW83ItNk5IUsjVr1kSn0/H06VPs7e2N84l53rdxWniFRwiRNEuWLKFz587GgO3VqxczZ86UgLWUsyvgwbO+BnJXgzy1tK1HpEiSQjYgIAB48Vj+83khRMZw/PhxOnXqxPPX6j/++GNmzJghAWsp+jg4IK3Y9CBJIVujRo1Xzgsh0rdy5coxaNAgJk6cSO/evZk+fforr2aJN3RmOTw8Z5h+qwbk8dO2HpFiKfoztFatWuzatSvR9QEBAdSqJZc2hEgvdDod48ePZ8OGDRKwlqaP/c+92FGalSLeXIpCNjAwkDt37iS6/u7du/zxxx8pLkoIob179+6ZzOt0Oho3biwBa2mnl8HD84Zpn5qGL5FmpfiGyqv+o124cIGsWbOmdNdCCI399NNPFCxYkD179mhdSsaij4WDX7+Yf2d04tuKNCHJ78kuXryYxYsXG+fHjh3LvHnz4m0XGhrK33//Tf36Ms6hEGnR/Pnz6dGjBwD16tXjxIkTJv0SCwsKXgKhFwzTeWrBW/IaZFqX5JCNiIgwuXz05MmTeE8W6nQ6nJ2d+fjjjxkxYoT5qhRCpIq5c+fSq1cv43yvXr2kP+LUoo+FQ2NfzFeVVmx6kKKh7vLnz8/3339P48aNLVFTqpKh7oQwmDNnDh9//LFx/osvvuCbb76Re7Cp5dRC2NbVMJ2nNrTcoW09GZDVDHV3+fJlsxxcCGEdZs2aRe/evY3zX375JZMmTZKATS1xMf+5FztKs1KEeSUpZK9duwZAnjx5TOZf5/n2QgjrNXPmTPr06WOcHzRoEBMmTJCATU3BP8OjZ42XvHUg97va1iPMJkkhmy9fPpNuFZ/Pv450qyiEdZsxYwZ9+/Y1zg8ZMoRx48ZJwKamuGg4+NK9WHmiOF1JUsguWLAAnU6HnZ2dybwQIm1zc3PDxsYGvV7P0KFDGTt2rPzfTm3//AyPrxim8/lDrqqaliPMK0UPPqUn8uCTyOiWLFnCuXPnGD16tARsaouLhgVF4PFVw3y7g+Dtq21NGZjVPPiUmOjoaGJiYnB2djbnboUQFtShQwetS8i4/ln0ImDz15OATYdS1OPTihUr+Pzzz02WjR49mixZsuDm5kbTpk0JCwszS4FCCPP57rvvWLBggdZlCHh2L3bci/mqozQrRVhOikJ2ypQphIeHG+f379/P6NGj8ff35/PPP2fr1q2MGzfuFXsQQqS2KVOmMGDAALp3787ChQu1LkecWgBPnr2pkb8+eFfWth5hESm6XHzx4kU6d+5snF+2bBk5c+Zk/fr1ZMqUCb1ez9q1a5kwYYLZChVCpNzkyZMZOHAgAEopbty4oXFFGVxslGkrVt6LTbdS1JKNiorC0dHROL99+3bq1atHpkyGzC5RooT8JxbCSkyaNMkYsABff/01X331lYYVCU4tgLBnvyMLNISclbStR1hMikI2f/787Ny5E4AjR45w4cIFPvjgA+P6O3fukCVLFvNUKIRIsQkTJjB48GDj/Lhx4xg+fLiGFQlio+DQ+Bfz0opN11J0ubhXr158+umnBAcHc+PGDd566y0aNmxoXL9v3z5KlixptiKFEMk3fvx4hg0bZjI/ZMgQDSsSAJyc/6IVW7AxeFXQth5hUSkK2X79+uHo6MiWLVuoUKECgwYNwsnJCYAHDx5w+/Ztk47GhRCpa+zYsSaXhCdOnMigQYM0rEgAEBsJh19qxVYdqV0tIlVIZxTSGYVIZ27evEnx4sV58uQJAN988w1ffvmlxlUJAI79CAH9DdMFP4Qmv2pajjBllZ1RBAcHc/Wq4WXqvHnzUqJEiTcuSgiRcrlz52bbtm34+/szYsQIvvjiC61LEgAxT+HwS29cyL3YDCHFIbthwwYGDBjAlStXTJbnz5+fqVOnpouxZoVIq6pWrcrZs2fx9vbWuhTx3Ml5EH7LMF2oKXiW07QckTpS9HTxli1baN68OWB4mGL9+vWsX7+e8ePHo5SiWbNmbN261ayFCiESppRi69at/PfOjwSsFZFWbIaVonuyVatWJSoqij179sTrpzg8PJz33nsPR0dHDhw4YLZCLUXuyYq0TCnFiBEjGDt2LAMGDODbb7+VTv6t0dFpEPisK9rCzaHxGk3LEQmzRB6kqCX7999/07lz5wQHAnB2dqZLly78/fffb1ycECJxSimGDx/O2LGGsUinTp3Kvn37NK5KxBMTAYcnvpivOkK7WkSqS9E9WUdHRx48eJDo+gcPHpj0CCWEMC+lFMOGDTPpuvTHH3/kvffe07AqkaATsyHijmG6SAvwKKNtPSJVpaglW6tWLb7//vsELwcfOnSIH374gdq1a79xcUKI+JRSDBkyxCRgp0+fTt++fTWsSiQoJhz+mvRsRifvxWZAKWrJfvPNN1StWpX33nuPypUrU7RoUQDOnj3L4cOH8fT0ZNKkSa/ZixAiuZRSDB48mG+++ca4bObMmXzyyScaViUSdWI2RNw1TBdpCe6ltK1HpLoU9138999/079/fx4+fMjKlStZuXIlDx8+5NNPP+XEiRPky5fPzKUKkbEppRg4cKBJwM6aNUsC1lrFhMPhl1qx70grNiNK9tPFcXFx3Lt3Dzc3t3Rx31WeLhZpxaRJk0w6+58zZw49e/bUsCLxSn9Nhj+fjX5UtA00XK5tPeK1NH26WCnF0KFDyZYtG7lz58bFxYWmTZu+8gEoIYT5tG3blvz58wMwd+5cCVhrFh0Gfz2/4qCDqjK0YEaV5HuyixYtYuLEibz11lt88MEHXLx4kQ0bNqDX69mwYYMlaxRCAHny5CEgIIB9+/bRrl07rcsRrxI0A56GGKaLtYEc0t1sRpXky8WVK1cmLi6OvXv3Gkfc+fTTT5kxYwa3b9/G3d3dooVailwuFtZKKUVMTAz29vZalyKSI/oJzMsPkfdBZwOd/4EcxbSuSiSBppeLL168SKdOnYwBC9C7d2/0ej3nz583SzFCCAOlFP3796dp06ZERUVpXY5IjuMzDAELUKytBGwGl+SQffjwIR4eHibLnrdeIyMjzVuVEBmYUoq+ffsyffp0tmzZQqtWreL1SyysVPQTODLZMK2zgSrSu1NGl6xXeKRPVCEsS6/X06dPH2bOnAkY/s81b95c/u+lFcd/hMhnD4MWbw/Zi2hbj9Bcku/J2tjY4OPjg6urq3FZXFwcp0+fJn/+/PH6MdbpdJw4ccK81VqA3JMV1kKv19O7d2/mzJkDGP7PLV68mA4dOmhcmUiSqMcwPx9EPjS0YruclpBNYzQdtL169eoJ/jXt6elplkKEyMj0ej2ffPIJc+fOBQwB+/PPP9O+fXuNKxNJdvwHQ8ACFO8gASuAZIRsYGCgBcsQIuPS6/X06tWL+fPnA4aA/eWXX+Q1nbQk6hEcnWqY1tlCFXkvVhikqO9iIYR56PV6evbsyU8//QQYAnbp0qW0adNG48pEshx7qRVboiNkK6RtPcJqpKjvYkubMWMG+fLlw9HREV9fXw4fPpykz61YsQKdTkeTJk0sW6AQZhIZGcm5c+cAsLW1ZdmyZRKwaU1k6H9ascM1LUdYF6sL2ZUrVzJgwABGjhzJsWPHKFu2LP7+/ty9e/eVn7ty5QpffPEF1apVS6VKhXhzmTNnZsuWLdSsWZPly5fTunVrrUsSyXXse4gKNUyX7AxuBTUtR1iXZA8QYGm+vr5UqlSJ6dOnA4bLaT4+PvTr18+kc/SXxcXFUb16dbp27cqePXsIDQ3l119/TdLx5OliYQ2UUvKaTloUGWp4ojjqEdhkgo/OglsBrasSKaRpj0+pITo6mqNHj5oM+G5jY0Pt2rUTHCD+uTFjxuDp6Um3bt1ee4yoqCgeP35s8iVEaomLi+Orr76Kd2VGAjaNOvqdIWABSnSWgBXxWFXIhoSEEBcXh5eXl8lyLy8vbt++neBn9u7dy08//cS8efOSdIwJEybg6upq/PLx8XnjuoVIiri4OLp06cLYsWOpVasW9+7d07ok8SYiH8KxaYZpm0xyL1Yk6I1C9ubNmyxfvpzvv/+eGzduAIZfJA8ePCAuLs4sBb7KkydP6NixI/PmzUvyAAVDhgzh0aNHxq/r169buEohIDY2lk6dOrFkyRIAzp49y7FjxzSuSryRo99B9LMrYSU/Atd8mpYjrFOKXuFRSvG///2P6dOnExsbi06no3Tp0rz11luEhYWRL18+xowZw2effZas/bq7u2Nra8udO3dMlt+5c4ecOXPG2/7ixYtcuXKFRo0aGZfp9XoAMmXKxNmzZylY0PQhBAcHBxwcHJJVlxBv4nnALl9uGLTbzs6O1atX4+/vr3FlIsWePnipFWsHVYZpWo6wXilqyU6ePJnvv/+eL774gh07dph0Xu7q6kqzZs1Yu3Ztsvdrb29PhQoV2LVrl3GZXq9n165dVK1aNd72xYoV4+TJkwQFBRm/GjdujJ+fH0FBQXIpWGguNjaWjh07mgTsmjVr+PDDDzWuTLyRo1MNgwEAlOoKLnm1rUdYrRS1ZOfNm0enTp0YP3489+/fj7e+TJky/P777ykqaMCAAXTu3JmKFStSuXJlpk2bRnh4OB999BEAnTp1Infu3EyYMAFHR0dKlSpl8nk3NzeAeMuFSG2xsbG0b9+eVatWAYY/IteuXUvDhg01rky8kaf3Da/tgKEV6ztU23qEVUtRyF6/fp133nkn0fXOzs4pfmq3devW3Lt3jxEjRnD79m3KlSvH1q1bjQ9DXbt2DRsbq3peS4h4YmJiaN++PatXrwYMAbtu3ToaNGigcWXijR2ZAjFhhunS3cAlj7b1CKuWopD19PR85QNDR48eJU+elP/g9e3bl759+ya47nV9KC9atCjFxxXCXH766SeTgF2/fj3169fXuCrxxiJCDMPZAdjaQ2VpxYpXS1GTsFmzZsyePZtLly4Zlz1/z2/79u0sWrSIli1bmqdCIdKgnj170qVLFxwcHNiwYYMEbHpx9KVWbKnu4CLPfYhXS1GPT48ePaJ69epcvnyZatWqsXXrVurUqUNYWBgHDhygfPny/Pnnn2TOnNkSNZuV9PgkLCUuLo5Tp05RtmxZrUsR5hBxD+bnh5hwQyu220XI+pbWVQkzspoen1xdXTl48CADBw7k5s2bODo68scffxAaGsrIkSPZs2dPmghYIcwlOjqaCxcumCyztbWVgE1PjnxrCFiA0j0lYEWSWF3fxalNWrLiTUVFRdGyZUsOHDjA7t27KV26tNYlCXOLuAvz8kNsBNg6PGvF5ta6KmFmVtOSFUIYREVF0aJFCzZu3EhISAiNGjUiOjpa67KEuf012RCwAGV6SsCKJEvR08Vdu3Z97TY6nc44ELUQ6VFUVBTNmzdn8+bNADg5ObFgwQLs7e01rkyYVcRdCJphmM7kCJUTHg1MiISkKGR3794db9SQuLg4bt26RVxcHB4eHjg7O5ulQCGsUWRkJM2bN2fLli2AYVzYzZs3U7NmTW0LE+Z3+BuIfWqYLtMLsuTSth6RpqQoZK9cuZLg8piYGObMmcO0adPYsWPHm9QlhNWKjIykWbNmxl7Nng+8XqNGDY0rE2YXfhtOzDRMZ3KESoO0rUekOWa9J2tnZ0ffvn2pW7duop1JCJGWRUZG0rRpU2PAOjs78/vvv0vApld/vdSKLfsJZPHWth6R5ljkwaeyZcvy559/WmLXQmgmLi6OJk2asHXrVuBFwFavXl3jyoRFhN2CE7MM05mcoNJAbesRaZJFQnbHjh3ynqxId2xtbalbty4AWbJkYevWrVSrVk3jqoTF/DUJYiMN02U/Aef4w20K8Topuic7ZsyYBJeHhoby559/cuzYMQYPlifwRPozYMAAbG1tqVixIu+++67W5QhLCbsFf88xTEsrVryBFHVGkdgoONmyZaNgwYJ0796dHj16xHsC2RpJZxTiVZRSaeLnWJjZ7k/h+A+G6YpfQI3J2tYjUoUl8iBFLVm9Xm+WgwthzSIiImjevDm9e/emUaNGWpcjUsuTmy+1YjNDpS+1rUekacm+J/v06VMGDBjAxo0bLVGPEFYhPDychg0bsnXrVpMOJ0QGcHgixEUZpsv3hcye2tYj0rRkh6yTkxNz5szhzp07lqhHCM2Fh4fToEEDAgICAMPPvLu7u8ZViVTx5AacnGuYtnM2XCoW4g2k6OniChUqcOrUKXPXIoTmwsLCqF+/Pn/88QdgGHFqx44d+Pr6alyZSBWHJ0Lcs76ny/WFzB7a1iPSvBSF7LRp01ixYgXz588nNjbW3DUJoYknT55Qr1494zvebm5u7Ny5k8qVK2tcmUgV/x6Ek/MM03ZZpBUrzCLJTxf/+eefFC9eHA8PD0qXLs39+/e5c+cODg4O5M6dGycnJ9Md63ScOHHCIkWbkzxdLOBFwO7btw94EbAVKlTQuDJhcbcOw4HRcHnLi2WVh0C18drVJDSh6dPFfn5+LFmyhLZt25IjRw7c3d0pWrSoWYoQQkuPHz+mXr167N+/HzC8irZz507efvttjSsTFvXvQUO4Xtlquty9lDxRLMwmySGrlOJ5ozcwMNBS9QiR6oKCgjhy5AgA2bNnZ+fOnZQvX17jqoTF3NxvCNer202XZ80DvkOhZBfI5KBJaSL9SdF7skKkJ9WrV2ft2rX07NmTLVu2UK5cOa1LEpZwc9+zcP3PCGEuecF3GJTsDLYyFrAwr2SFrPR8I9Krhg0bcuHCBelzOz26sccQrtd2mS53yfcsXDtJuAqLSfKDTzY2NskKWZ1OlyaePJYHnzKe0NBQNm7cSMeOHbUuRVjS9T8M4Xo9wHS5awFDuJboCLZ22tQmrJLm3SrWrl2bIkWKmOXAQmghNDSUunXr8tdff3H37l3+97//aV2SMLfrgc/CNdB0uVtB8B0OxdtLuIpUk6yW7JIlS2jXrp2la0pV0pLNOB4+fEjdunWNDzl5eHhw5swZsmfPrnFl4o0p9SxcR8GN/4xl7VYIqjwLVxt5DEUkTvOWrBBp1YMHD6hTpw7Hjh0DDAG7e/duCdi0Tim4ttvQcr25x3RdtiKGcC3WVsJVaEZ+8kS69+DBA2rXrs3x48cB8PT0ZPfu3ZQsWVLjykSKKQVXdxrC9d99puuyFYWqX0HRNmBjq019QjwjISvStfv371O7dm2CgoIA8PLyYvfu3ZQoUULbwkTKKGV4BWf/KLh1wHRd9mJQ5Sso2lrCVViNJIesjCEr0pqQkBBq165t7N7Ty8uLgIAAihcvrnFlItmUgivbDC3XWwdN1+UoYQjXIi0lXIXVkZasSLfatWtnDNicOXMSEBBAsWLFNK5KJItScPl3Q7jePmy6LkdJqDoCirQAXYrGOhHC4iRkRbo1depU/Pz8sLOzIyAgQPraTkuUMnTYf2A03P7LdJ17KagyAoo0l3AVVk9CVqRbpUqVYvfu3Tg4OMj73WmFUnBpExwYA3eOmK7zKGMI18JNJVxFmiEhK9KNhw8f4uLigq3ti/typUuX1rAikWRKwcXfDOF695jpOo+yUHUkFPpQwlWkORKyIl24c+cOtWrVonLlysyfP98kaIUVUwoubDBcFr4XZLrOs7yh5VqosYSrSLMkZEWa9zxgg4ODCQ4OxtPTk0mTJmldlngVpYcLvxparvdOmK7zfNvQci3YCGRQEpHGSciKNO327dvUqlWL06dPA+Dj40PPnj01rkokSunh/Do4+DXc+9t0nVcFqDoKCjSQcBXphoSsSLNu3bpFrVq1OHPmDAB58uQhICCAAgUKaFyZiEfp4dxaODgGQk6ZrstZydByzV9fwlWkOxKyIk26desWfn5+nD17FoC8efMSEBBA/vz5Na5MmNDHwbk1hpbr/X9M13n7GsI13wcSriLdkpAVac6///6Ln58f586dAwwBGxgYSL58+bQtTLygj4Ozqwzh+uC06TrvKvDOKMhbV8JVpHsSsiJNuXnzJn5+fpw/fx6AfPnyERgYSN68eTWuTADPwnXls3A9Y7ou1zuGlmveOhKuIsOQkBVpir29PQ4ODgDkz5+fwMBA8uTJo3FVAn0snFkBB8fCw7Om63K/ZwjXPO9LuIoMR0JWpCkeHh7s2rWLHj16MH36dHx8fLQuKWPTx8LpZXBoLDw8b7oudzXDZWEfPwlXkWFJyIo0x9PTkw0bNmhdRsamj4XTSw0t19ALpuveqmFoufrUlHAVGZ50oyKs2rVr1+jQoQNPnjzRuhQBEBcDpxbCwmKwtYtpwPr4QatAaB0IeaT1KgRIS1ZYsatXr+Ln58fly5e5evUqW7ZsIWvWrFqXlTHFxUDwz3BoPDy6ZLouTy1Dy/Wt6trUJoQVk5AVVunKlSv4+flx5coVAO7evUtYWJiEbGqLi4Z/foZD4+DxFdN1eWo/C9f3NClNiLRAQlZYnStXrlCzZk2uXr0KQNGiRdm9ezfe3t4aV5aBxEXDP4sMLdfHV03X5a1rCNfc72hSmhBpiYSssCqXL1+mZs2aXLt2DYBixYpJwKam2Cj4ZyEcmgBPrpmuy+dvCNdcVbWpTYg0SEJWWI1Lly5Rs2ZNrl+/DhgCNiAggJw5c2pcWQYQGwWnFsDhCfDkuum6/PUMQ87lqqJNbUKkYRKywipcvHiRmjVrcuPGDQBKlCjB7t278fLy0riydC42Ek7+BIcnQtgN03UFGhjC1buyNrUJkQ5IyAqrMGnSJAnY1BQbCX/Pg78mQdhN03UFGkLVEYbRcYQQb0RCVliFH3/8kZs3b3L16lV2796Np6en1iWlTzFP4eTzcP3XdF3BxoZw9aqgTW1CpEMSssIqODg4sHbtWsLCwnB3d9e6nPQn5in8PccQruG3TdcV/PBZuL6tTW1CpGMSskIT586dw97e3mR4OkdHRxwdHbUrKj2KiYATs+GvbyDijum6Qk0N4epZTpPShMgIJGRFqjtz5gy1atXCwcGBP/74Q0bRsYSY8JfC9a7pusLNocpX4FlWm9qEyEAkZEWqOnPmDH5+fty+bbhk+emnn7J+/XqNq0pHYsIhaCb8NRme3jNdV6SFIVw9ymhTmxAZkISsSDWnT5/Gz8+PO3cMly3LlSvH/PnzNa4qnYgOM4TrkW//E646KNISqn4F7qU0K0+IjEpCVqSK4OBg/Pz8uHvXcOmyfPny7Ny5k+zZs2tcWRoX/QSOz4CjU+BpyEsrdFC0NVQZDu4lNStPiIxOQlZY3D///EOtWrWMAfv222+zY8cOCdg3EfUYgqbDkSkQ+eClFToo1sYQrjlKaFaeEMJAQlZY1KlTp6hVqxb37hkuYVaoUIEdO3aQLVs2jStLo6Iew/Ef4ehU03DV2UCxtuA7HHIU064+IYQJCVlhMbdu3TIJ2EqVKrF9+3bc3Ny0LSwtinoEx36AY99B5MMXy3U2ULw9+A6D7EW1q08IkSAbrQsQ6VfOnDnp1KkTAJUrV5aATYnIUNg/Gublg/0jXgSszhZKdIIup6HezxKwQlgpackKi9HpdEyePJm8efPSqVMnXF1dtS4p7YgMhWPTDF9Rj14s19lCiY6Glmu2QhoVJ4RIKglZYVbR0dHY29sb53U6Hf369dOwojTm6YNn4fo9RD9+sVxnCyU7g+9QcCuoWXlCiOSRy8XCbI4fP07RokU5cOCA1qWkPU8fwN7hMD8fHPz6RcDaZIJS3aDrOfD/SQJWiDTGKkN2xowZ5MuXD0dHR3x9fTl8+HCi286bN49q1aqRLVs2smXLRu3atV+5vbCMY8eO8f7773PlyhX8/f05fvy41iWlDU/vw95hhnA9NM7w3isYwrV0D+h6Hvzng1sBTcsUQqSM1YXsypUrGTBgACNHjuTYsWOULVsWf39/4zuW/xUYGEjbtm0JCAjgwIED+Pj4ULduXW7evJng9sL8jh49yvvvv8/Dh4aHcsqUKUOhQnK/8JUiQmDPEMMDTYfGvxSudlCmF3S7AHXngms+LasUQrwhnVJKaV3Ey3x9falUqRLTp08HQK/X4+PjQ79+/Rg8ePBrPx8XF0e2bNmYPn268cnWl0VFRREVFWWcf/z4MT4+Pjx69AgXFxfzfSMZxJEjR6hTpw6hoaEAvPfee2zZsoWsWbNqW5i1irhn6PowaIahn+HnbOygdDeoPARcZMAEIbTw+PFjXF1dzZoHVtWSjY6O5ujRo9SuXdu4zMbGhtq1ayf5Pl9ERAQxMTGJ9iY0YcIEXF1djV8+Pj5mqT0j+uuvv6hdu7YxYKtVq8bvv/8uAZuQiLvwx0BDy/Wvb14ErK09lO0N3S5C7VkSsEKkM1b1dHFISAhxcXF4eXmZLPfy8uLMmTNJ2segQYPIlSuXSVC/bMiQIQwYMMA4/7wlK5Ln0KFD1K1bl8ePDQ/oVK9enc2bN5MlSxaNK7My4XcMI+KcmAWxES+W29ob7rlWHgxZ39KuPiGERVlVyL6piRMnsmLFCgIDAxMd/NvBwQEHB4dUrix9OXjwIP7+/saArVmzJps2bcLZ2VnjyqxI+G1Di/XEbIh9+mK5rQOU6QmVBkHW3NrVJ4RIFVYVsu7u7tja2hqHQnvuzp075MyZ85Wf/fbbb5k4cSI7d+6kTBkZL9OSzp8/z5Mnhgd1/Pz82LhxowTsc2G3DOH692yIjXyxPJOj4YGmSgMhSy7t6hNCpCqrCll7e3sqVKjArl27aNKkCWB48GnXrl307ds30c998803jBs3jm3btlGxYsVUqjbj6tixI7GxsSxbtowNGzaQOXNmrUvSXti/cHgSnJybQLh+/CxcvbWrTwihCat7unjlypV07tyZOXPmULlyZaZNm8aqVas4c+YMXl5edOrUidy5czNhwgQAJk2axIgRI1i2bBnvvvuucT9ZsmRJ0v1BSzxNllHo9XpsbKzq2bnU9+QmHJ4IJ+dB3Iun1snkBGU/gUpfgvOrr8IIIayDJfLAqlqyAK1bt+bevXuMGDGC27dvU65cObZu3Wp8GOratWsmv9hnzZpFdHQ0LVq0MNnPyJEjGTVqVGqWnm7t3buXq1ev0r59e5PlGTpgn9x4KVyjXyzPlBnK9YaKX4CzV+KfF0JkCFbXkk1t0pJ9tT179lCvXj0iIiL4+eef6dChg9YlaevxdTg8AU79lEC49oFKX0BmT+3qE0KkWIZoyQrr8eeff1K/fn3Cww3vdK5YsYL27duj0+k0rkwDj68ZwvXkT6CPebHczhnK9YWK/4PMHtrVJ4SwShKyIkF//PEH9evXJyLC8G5nvXr1WLNmTcYL2MdXDd0enlr4n3DNAuX7QYUBkNldu/qEEFZNQlbEExAQQMOGDY0BW79+fdauXZvou8fp0qMrhnD9ZyHoY18st8/6IlydcmhWnhAibZCQFSZ2795Nw4YNefrU0IFCgwYNWLt2bcbpwCP0kiFcgxf/J1xd4O3+8Pbn4JRwl51CCPFfErLCaOfOnTRq1IjISMN7ng0bNmTNmjUZI2BDL8LBcRD8M6i4F8vtXeDtz6DCZ+CYTavqhBBplISsACA8PJx27doZA7ZRo0asXr06/QfswwuGcVyDfzENVwdXQ7i+/amEqxAixSRkBQDOzs6sXbuWevXqUbt2bVatWoW9vb3WZVnOw/NwcCycXvqfcHWDCp9D+f7g6KZVdUKIdEJCVhhVq1aNffv2Ubx48fQbsA/OGsL1zDJQ+hfLHbMZ7re+3d/QihVCCDOQkM3Azpw5Q9GiRU1eyylbtqyGFVnQ/TNwaCycWf6fcM1ueFK4fD9wkM5IhBDmlYH7xcvYtmzZQtmyZRkyZAjputOv+6dhcztYVOLZpeFnAeuYA94bDz2uQJVhErBCCIuQlmwGtHnzZpo1a0Z0dDSTJk2ibNmytG3bVuuyzCvkHzj4NZxdBbz0R4RjDkO/wuX7GN55FUIIC5KQzWA2bdpE8+bNiY429LvbqlWreIMrpGkhp+DA13BuNSbh6uQOFb80dN5v//rRmYQQwhwkZDOQjRs30rx5c2JiDN0DtmnThl9++YVMmdLBj8G9k3BwDJxbY7o8s+ezcP3E0M+wEEKkonTw21UkxW+//UaLFi2MAdu2bVt+/vnntB+wd08YwvX8OtPlmT0NA6WX/VjCVQihmTT+G1YkxYYNG2jZsqUxYNu1a8fixYvTdsDeDYIDY+DCetPlzjkN4VqmF9hl1qQ0IYR4Lg3/lhVJsXnzZlq0aEFsrKEf3vbt27N48WJsbW01riyF7hwzhOvFDabLnb2h8iAo3RPsnLSpTQgh/kNCNp0rUaIEuXLl4tq1a3Ts2JGFCxemzYC9cxT2j4ZLG02XZ8kFlQZB6R4SrkIIqyMhm87lz5+fgIAAZs+ezYQJE9JewN4+AgdGw6VNpsuz5IbKg6F0d8iUgYbgE0KkKTqVrnsieL3Hjx/j6urKo0ePcHFJHx0SKKXS/uDqtw4bwvXyFtPlWd4C3yFQqquEqxDCrCyRB9LjUzqzatUqWrZsaXwPNs359yCsrQfLfE0DNqsPvD8Tul0wvOsqASuESAPkcnE6snLlStq3b09cXBytWrVi9erV2NnZaV1W0vx7wNByvbLNdHnWPOA7FEp2gUzpfNg9IUS6IyGbTixfvpwOHTqg1xv65vXw8Egb919v7jOE69Udpstd8oLvMCjZGWzT6YhAQoh0T0I2HVi2bBkdO3Y0BmyPHj2YPXs2NjZWfDfgxh5DuF7bZbrcJd+zcO0k4SqESPMkZNO4JUuW0LlzZ2PA9urVi5kzZ1pvwN7481m47jZd7lrAEK4lOoJtGrnELYQQryEhm4b98ssvdOnSxRiwn3zyCdOnT7fOgL0eaAjX64Gmy90Kgu9wKN5ewlUIke5IyKZRixcv5qOPPjKOBdu7d2+mT59uXa/uKPUiXG/8YbrOrRBUeRauNvJjKIRIn+S3WxoUFxfHvHnzjAHbt29ffvjhB+sJWKUMl4MPjIabe0zXZStiCNdibSVchRDpnvyWS4NsbW3ZsmUL/v7+VKpUie+//946AlYpw4NM+0fBv/tM12UrClW/gqJtwCYNPPUshBBmICGbRrm4uLBr1y6cnJy0D1ilDK/gHBgN/+43XZe9GFT5Coq2lnAVQmQ4ErJpxOrVq/Hz88Pd3d24LHNmjYdyU8rQecSB0XDroOm6HCUM4VqkpYSrECLDkpBNA+bOnUuvXr0oW7Ysu3btIkeOHNoWpBRc2fosXA+ZrstREqqOgCItQGeFTzkLIUQqkt+CVm7OnDn06tULgBMnTvDLL79oV4xScGmzoV/hdfVNA9a9FDRcBZ3/hqKtJGCFEAJpyVq1WbNm0bt3b+P8l19+yaeffpr6hShlGGruwBi4c8R0nUcZqDICCjeVYBVCiP+QkLVSM2fOpE+fPsb5gQMHMnHixNR9yEkpuLjRcFn47jHTdR5loepIKPShhKsQQiRCQtYKzZgxg759+xrnBw8ezPjx41MvYJWCCxvg4Bi4e9x0nWd5Q8u1UGMJVyGEeA0JWSvz448/0r9/f+P80KFDGTt2bOoErNLDhV8Nl4XvnTBd5/m2oeVasBFo/cqQEEKkERKyVmT79u0mATts2DC+/vprywes0sP59YaW672/Tdd5VYCqo6BAAwlXC1JKERsbS1xcnNalCJFu2drakilTplS97SYha0Xef/992rdvz9KlS/nqq68YPXq0ZX8YlB7OrTWEa8gp03U5KxlarvnrS7haWHR0NLdu3SIiIkLrUoRI9zJnzoy3tzf29qkzlKZOPe8AN4N6/Pgxrq6uPHr0CBcXF63LIS4ujl9//ZVmzZpZLmD1cXBuDRz8Gu7/Y7rO29cQrvk+kHBNBXq9nvPnz2Nra4uHhwf29vba9+AlRDqklCI6Opp79+4RFxdH4cKF441YZok8kJasxh48eED27NmN87a2tjRv3twyB9PHwbnVhnuuD06brvOuAu+Mgrx1JVxTUXR0NHq9Hh8fH+178BIinXNycsLOzo6rV68SHR2No6OjxY8pj4dq6JtvvqF48eIEBwdb9kD6ODi9DBaXgs1tTQM21zvQfBu03Q/5/CVgNWKVYwALkQ6l9v81aclqZNKkSQwePBiAWrVqcerUKZN+ic1CHwtnVsDBsfDwrOm63O8ZLgvneV+CVQghLERCVgMTJkxg6NChxvl+/fqZN2D1sXBmueGe68PzputyVzNcFvbxk3AVQggLk2tUqWz8+PEmATt+/HiGDRtmnp3rY+GfxbCwOPzeyTRg36oBLXdD6z8gTy0JWCE0cvbsWXLmzMmTJ0+0LiVdCQkJwdPTkxs3bmhdigkJ2VQ0duxYk0CdOHEiQ4YMefMdx8XAqYWwsBhs7QKhF16s86kJrQKgdSDkkdarMI8uXbqg0+nQ6XTY2dmRP39+Bg4cSGRkZLxtN23aRI0aNciaNSuZM2emUqVKLFq0KMH9rl27lpo1a+Lq6kqWLFkoU6YMY8aM4cGDBxb+jlLPkCFD6NevH1mzZtW6FIuZMWMG+fLlw9HREV9fXw4fPvzK7detW0fFihVxc3PD2dmZcuXKxRsMZdSoURQrVgxnZ2eyZctG7dq1OXToxSAl7u7udOrUiZEjR1rke0oxlcE9evRIAerRo0cWPc6YMWMUYPyaNGnSm+80Nlqpv39Sal4Bpb7F9GtVLaWu//HmxxAW9fTpUxUcHKyePn2qdSnJ0rlzZ/XBBx+oW7duqWvXrqn169crFxcXNXDgQJPtfvjhB2VjY6OGDBmi/vnnH3X+/Hn17bffKgcHB/W///3PZNuhQ4cqW1tb9cUXX6h9+/apy5cvq+3bt6tmzZqpadOmpdr3FhUVZbF9X716VdnZ2akbN2680X4sWeObWrFihbK3t1cLFixQ//zzj+rRo4dyc3NTd+7cSfQzAQEBat26dSo4OFhduHBBTZs2Tdna2qqtW7cat1m6dKnasWOHunjxojp16pTq1q2bcnFxUXfv3jVuc+rUKeXg4KDu37+f6LFe9X/OEnkgIZsKITt69GiTgJ08efKb7TA2WqkT85Salz+BcK2t1PU95ilcWFxaDtkPP/zQZFmzZs1U+fLljfPXrl1TdnZ2asCAAfE+/8MPPyhAHTx4UCml1KFDhxSQaJg+fPgw0VquX7+u2rRpo7Jly6YyZ86sKlSoYNxvQnV++umnqkaNGsb5GjVqqD59+qhPP/1U5ciRQ9WsWVO1bdtWtWrVyuRz0dHRKkeOHGrx4sVKKaXi4uLU+PHjVb58+ZSjo6MqU6aMWr16daJ1KqXU5MmTVcWKFU2WhYSEqDZt2qhcuXIpJycnVapUKbVs2TKTbRKqUSmlTp48qT744APl7OysPD09VYcOHdS9e/eMn/v999/Vu+++q1xdXVX27NlVgwYN1IULF15Z45uqXLmy6tOnj3E+Li5O5cqVS02YMCFZ+ylfvrwaPnx4ouuf/+7euXOnyfL8+fOr+fPnJ/q51A5ZefApFbzcs8iUKVMYMGBAynYUFw3/LIJD4+HxVdN1eesYnhbO/W7KCxXWYUlFCL+d+sd1zgkdjrx+uwScOnWK/fv3kzdvXuOyNWvWEBMTwxdffBFv+169ejF06FCWL1+Or68vS5cuJUuWLCZDO77Mzc0tweVhYWHUqFGD3Llz89tvv5EzZ06OHTuGXq9PVv2LFy/mk08+Yd++fQBcuHCBli1bEhYWRpYsWQDYtm0bERERNG3aFDA8wLhkyRJmz55N4cKF+fPPP+nQoQMeHh7UqFEjwePs2bOHihUrmiyLjIykQoUKDBo0CBcXFzZv3kzHjh0pWLAglStXTrTG0NBQatWqRffu3fnuu+94+vQpgwYNolWrVuzevRuA8PBwBgwYQJkyZQgLC2PEiBE0bdqUoKCgRF9lGT9+POPHj3/l+QoODiZPnjzxlkdHR3P06FGT22A2NjbUrl2bAwcOvHKfzyml2L17N2fPnmXSpEkJbhMdHc3cuXNxdXWlbNmyJusqV67Mnj176NatW5KOZ2kSsqlg8ODBKKVwdHTk888/T/4O4qIN91wPjYcn10zX5fM3hGuuquYpVmgv/DaE3dS6itfatGkTWbJkITY2lqioKGxsbJg+fbpx/blz53B1dcXb2zveZ+3t7SlQoADnzp0D4Pz58xQoUAA7O7tk1bBs2TLu3bvHX3/9ZezUpVChQsn+XgoXLsw333xjnC9YsCDOzs6sX7+ejh07Go/VuHFjsmbNSlRUFOPHj2fnzp1UrWr4v1egQAH27t3LnDlzEg3Zq1evxgvZ3Llzm/wh0q9fP7Zt28aqVatMQva/NY4dO5by5cubBOKCBQvw8fHh3LlzFClSJF7HNgsWLMDDw4Pg4GBKlSqVYI0ff/wxrVq1euX5ypUrV4LLQ0JCiIuLw8vLy2S5l5cXZ86ceeU+Hz16RO7cuYmKisLW1paZM2dSp04dk202bdpEmzZtiIiIwNvbmx07dsR7MyNXrlwcP/6f0cM0JCGbSlL0gFNsFJxaAIcnwJPrpuvy1zMMOZerinkKFNbDOWeaOK6fnx+zZs0iPDyc7777jkyZMqW4tzKVwt5dg4KCKF++vEmvaSlRoUIFk/lMmTLRqlUrli5dSseOHQkPD2fDhg2sWLECMLR0IyIi4oVAdHQ05cuXT/Q4T58+jdfLUFxcHOPHj2fVqlXcvHmT6OhooqKi4vUA9t8aT5w4QUBAgLGl/bKLFy9SpEgRzp8/z4gRIzh06BAhISHGFv61a9cSDdns2bO/8flMiaxZsxIUFERYWBi7du1iwIABFChQgJo1axq38fPzIygoiJCQEObNm0erVq04dOgQnp6exm2cnJysqh9wCVkzU0oxevRoqlSpwgcffJCyncRGwsmf4PBECPvP4+j56xtart6VE/6sSPtSeMk2tTk7OxtbjQsWLKBs2bL89NNPxst0RYoU4dGjR/z777/xWj7R0dFcvHgRPz8/47Z79+4lJiYmWa1ZJyenV663sbGJF+AxMTEJfi//1b59e2rUqMHdu3fZsWMHTk5Oxv/TYWFhAGzevJncuXObfM7BwSHRetzd3Xn48KHJssmTJ/P9998zbdo0SpcujbOzM5999hnR0dGvrDEsLIxGjRoleEn1+dWDRo0akTdvXubNm0euXLnQ6/WUKlUq3r5f9iaXi93d3bG1teXOnTsmy+/cuUPOnK/+I87Gxsb481SuXDlOnz7NhAkTTEL2+c9coUKFqFKlCoULF+ann34yacQ8ePAADw+PVx4rNckrPGaklGLYsGGMHj2aJk2asG3btuTtIDYSjk+HnwrB7r6mAVugIbQ/DM02S8AKq2NjY8PQoUMZPnw4T58+BaB58+bY2dkxZcqUeNvPnj2b8PBw2rZtC0C7du0ICwtj5syZCe4/NDQ0weVlypQhKCgo0Vd8PDw8uHXrlsmyoKCgJH1P77zzDj4+PqxcuZKlS5fSsmVL4x8AJUqUwMHBgWvXrhl/6T//8vHxSXSf5cuXj9eN6r59+/jwww/p0KEDZcuWNbmM/ipvv/02//zzD/ny5YtXg7OzM/fv3+fs2bMMHz6c999/n+LFi8cL+IR8/PHHBAUFvfIrscvF9vb2VKhQgV27dhmX6fV6du3aZbysnlR6vZ6oqKhkb3Pq1KlXXk1IdWZ7hCqNMtfTZHq9Xg0aNMjkKeKZM2cm7cPREUod/V6p2bniPy28vrFSt4+8UW3CeqWnp4tjYmJU7ty5TZ6e/+6775SNjY0aOnSoOn36tLpw4YKaMmVKgq/wDBw4UNna2qovv/xS7d+/X125ckXt3LlTtWjRItGnjqOiolSRIkVUtWrV1N69e9XFixfVmjVr1P79+5VSSm3dulXpdDq1ePFide7cOTVixAjl4uIS7+niTz/9NMH9Dxs2TJUoUUJlypRJ7dmzJ966HDlyqEWLFqkLFy6oo0ePqh9++EEtWrQo0fP222+/KU9PTxUbG2tc9vnnnysfHx+1b98+FRwcrLp3765cXFxMzm9CNd68eVN5eHioFi1aqMOHD6sLFy6orVu3qi5duqjY2FgVFxencuTIoTp06KDOnz+vdu3apSpVqqQAtX79+kRrfFMrVqxQDg4OatGiRSo4OFj17NlTubm5qdu3bxu36dixoxo8eLBxfvz48Wr79u3q4sWLKjg4WH377bcqU6ZMat68eUoppcLCwtSQIUPUgQMH1JUrV9SRI0fURx99pBwcHNSpU6eM+wkPD1dOTk7qzz//TLQ+eYUnlZnjpOr1evXll18mP2CjI5Q68p1Ss7wTCNcPlbp9NMU1ibQhPYWsUkpNmDBBeXh4qLCwMOOyDRs2qGrVqilnZ2fl6OioKlSooBYsWJDgfleuXKmqV6+usmbNqpydnVWZMmXUmDFjXvkKz5UrV1Tz5s2Vi4uLypw5s6pYsaI6dOiQcf2IESOUl5eXcnV1VZ9//rnq27dvkkM2ODhYASpv3rxKr9ebrNPr9WratGmqaNGiys7OTnl4eCh/f3/1xx+Jv58eExOjcuXKZfL+5/3799WHH36osmTJojw9PdXw4cNVp06dXhuySil17tw51bRpU+Xm5qacnJxUsWLF1GeffWasdceOHap48eLKwcFBlSlTRgUGBlo8ZJVS6scff1R58uRR9vb2qnLlysZXql7+fjp37mycHzZsmCpUqJBydHRU2bJlU1WrVlUrVqwwrn/69Klq2rSpypUrl7K3t1fe3t6qcePG6vDhwyb7XbZsmSpatOgra0vtkJXxZN9w/EClFAMHDuTbb781Lps1axYff/xx4h+KiYC/58Bf38R/VaNQU6g6AjzLJbsWkfZERkZy+fJl8ufPnyrDbgntzZgxg99++y35t5PEa1WpUoX+/fvTrl27RLd51f85GU/Wyiil+OKLL5g6dapx2Zw5c+jZs2fCH4gJhxOz4a/JEGH6YACFm0OVr8CzbMKfFUKkC7169SI0NJQnT56k664VU1tISAjNmjUz3ue3FhKyKaSUYsCAAUybNs24bO7cufTo0SP+xjHhEDQTjnwLEXdN1xVpYQhXjzKWLVgIYRUyZcpkvkFBhJG7uzsDBw7Uuox4JGRT6OTJk8yYMcM4P2/ePLp37266UXTYi3B9eu+lFToo0hKqfgXuCb+rJoQQIu2TkE2hMmXKsGrVKlq3bs2sWbPo2rXri5XRT+D4DDg6BZ6GvPQpHRRtDVWGg3vJVK9ZCCFE6pKQfQNNmjThwoULL96Li3oMQdPhyFSIvP/Sljoo1sYQrjlKaFKrsG4Z/PlDIVJNav9fk5BNIqUUgYGBxh5qnvPx8TGE6/Ef4ehUiHzppXidDRRrC77DIUexVK5YpAXPOzeIiIh4be9FQog397zLxeT2k51SErJJoNfr6du3L7NmzeKHH36gX79+hhVRj+DYD3DsO4h8qScVnQ0Ubw++wyB7UW2KFmmCra0tbm5u3L1reCAuc+bM6HQ6jasSIv1RShEREcHdu3dxc3PD1tY2VY4r78m+5r0ovV5P7969mTNnDmDoPu500CGKPNkMx6ZBVOiLjXW2L4VrkdT5BkSap5Ti9u3biXYdKIQwHzc3N3LmzJngH7Pynmwq0+v1fPLJJ8ydOxcwBOzPwz+kyB+1Da3Y53S2UKKjIVyzJX+YLZGx6XQ6vL298fT0TLDzeiGEedjZ2aVaC/Y5CdlE6PV6evXqxfz58wGwsdGxpKMDbV3Ww/P+qHW2ULIz+A4Ft4LaFSvSBVtb21T/BSCEsCyrHIVnxowZ5MuXD0dHR3x9fTl8+PArt1+9ejXFihXD0dGR0qVLs2XLljc6vl6vp2fPni8CVgdL2yraljaMLoJNJijVDbqeA/+fJGCFEEIkyOpCduXKlQwYMICRI0dy7NgxypYti7+/v/HBkP/av38/bdu2pVu3bhw/fpwmTZrQpEkTTp06laLj6/V6enzUiZ9++gkAWxtY1h7alMcQrqV7QNfz4D8f3Aqk9NsUQgiRAVjdg0++vr5UqlSJ6dOnA4bQ8/HxoV+/fgwePDje9q1btyY8PJxNmzYZl1WpUoVy5coxe/bs1x7P5EZ3pmg+71KPaasNg2bb2sDy9tCyvB2U6gq+Q8Alr5m+UyGEENYk3T/4FB0dzdGjR01GubexsaF27docOHAgwc8cOHCAAQMGmCzz9/fn119/TXD7qKgok0F+Hz0yPMD0+PFjOPktLTyPsNgJHkXCgtY2+DfvwuMKA8DlWYcTjx+/wXcohBDCWj1+9vvdnG1PqwrZkJAQ4uLi8PLyMlnu5eXFmTNnEvzM7du3E9z+9u3bCW4/YcIERo8eHW+5sdeml3ReroflC4AFSfwOhBBCpHX379/H1dXVLPuyqpBNDUOGDDFp+er1eh48eECOHDnQ6XQ8fvwYHx8frl+/brbLBemdnLPkk3OWPHK+kk/OWfI9evSIPHnykD17drPt06pC1t3dHVtbW+7cMR1r9c6dO+TMmTPBz+TMmTNZ2zs4OODg4GCyzM3NLd52Li4u8oOZTHLOkk/OWfLI+Uo+OWfJZ2NjvmeCrerpYnt7eypUqMCuXbuMy/R6Pbt27aJq1aoJfqZq1aom2wPs2LEj0e2FEEKI1GJVLVmAAQMG0LlzZypWrEjlypWZNm0a4eHhfPTRRwB06tSJ3LlzM2HCBAA+/fRTatSowZQpU2jQoAErVqzgyJEjxl6ahBBCCK1YXci2bt2ae/fuMWLECG7fvk25cuXYunWr8eGma9eumTTl33nnHZYtW8bw4cMZOnQohQsX5tdff6VUqZQNhu7g4MDIkSPjXVIWiZNzlnxyzpJHzlfyyTlLPkucM6t7T1YIIYRIL6zqnqwQQgiRnkjICiGEEBYiISuEEEJYiISsEEIIYSEZMmS1HkovLUrOOZs3bx7VqlUjW7ZsZMuWjdq1a7/2HKdHyf05e27FihXodDqaNGli2QKtTHLPV2hoKH369MHb2xsHBweKFCmS4f5vJvecTZs2jaJFi+Lk5ISPjw+ff/45kZGRqVSttv78808aNWpErly50Ol0ifZv/7LAwEDefvttHBwcKFSoEIsWLUr+gVUGs2LFCmVvb68WLFig/vnnH9WjRw/l5uam7ty5k+D2+/btU7a2tuqbb75RwcHBavjw4crOzk6dPHkylSvXTnLPWbt27dSMGTPU8ePH1enTp1WXLl2Uq6urunHjRipXrp3knrPnLl++rHLnzq2qVaumPvzww9Qp1gok93xFRUWpihUrqvr166u9e/eqy5cvq8DAQBUUFJTKlWsnueds6dKlysHBQS1dulRdvnxZbdu2TXl7e6vPP/88lSvXxpYtW9SwYcPUunXrFKDWr1//yu0vXbqkMmfOrAYMGKCCg4PVjz/+qGxtbdXWrVuTddwMF7KVK1dWffr0Mc7HxcWpXLlyqQkTJiS4fatWrVSDBg1Mlvn6+qpevXpZtE5rktxz9l+xsbEqa9asavHixZYq0eqk5JzFxsaqd955R82fP1917tw5Q4Vscs/XrFmzVIECBVR0dHRqlWh1knvO+vTpo2rVqmWybMCAAerdd9+1aJ3WKCkhO3DgQFWyZEmTZa1bt1b+/v7JOlaGulz8fCi92rVrG5clZSi9l7cHw1B6iW2f3qTknP1XREQEMTExZu1025ql9JyNGTMGT09PunXrlhplWo2UnK/ffvuNqlWr0qdPH7y8vChVqhTjx48nLi4utcrWVErO2TvvvMPRo0eNl5QvXbrEli1bqF+/fqrUnNaY63e/1fX4ZEmpMZReepOSc/ZfgwYNIleuXPF+YNOrlJyzvXv38tNPPxEUFJQKFVqXlJyvS5cusXv3btq3b8+WLVu4cOECvXv3JiYmhpEjR6ZG2ZpKyTlr164dISEhvPfeeyiliI2N5eOPP2bo0KGpUXKak9jv/sePH/P06VOcnJyStJ8M1ZIVqW/ixImsWLGC9evX4+joqHU5VunJkyd07NiRefPm4e7urnU5aYJer8fT05O5c+dSoUIFWrduzbBhw5g9e7bWpVmtwMBAxo8fz8yZMzl27Bjr1q1j8+bNfP3111qXlq5lqJZsagyll96k5Jw99+233zJx4kR27txJmTJlLFmmVUnuObt48SJXrlyhUaNGxmV6vR6ATJkycfbsWQoWLGjZojWUkp8xb29v7OzssLW1NS4rXrw4t2/fJjo6Gnt7e4vWrLWUnLOvvvqKjh070r17dwBKly5NeHg4PXv2ZNiwYWYd3i09SOx3v4uLS5JbsZDBWrIylF7ypeScAXzzzTd8/fXXbN26lYoVK6ZGqVYjueesWLFinDx5kqCgIONX48aN8fPzIygoCB8fn9QsP9Wl5Gfs3Xff5cKFC8Y/RgDOnTuHt7d3ug9YSNk5i4iIiBekz/9IUdKFfTxm+92fvGey0r4VK1YoBwcHtWjRIhUcHKx69uyp3Nzc1O3bt5VSSnXs2FENHjzYuP2+fftUpkyZ1LfffqtOnz6tRo4cmSFf4UnOOZs4caKyt7dXa9asUbdu3TJ+PXnyRKtvIdUl95z9V0Z7uji55+vatWsqa9asqm/fvurs2bNq06ZNytPTU40dO1arbyHVJfecjRw5UmXNmlUtX75cXbp0SW3fvl0VLFhQtWrVSqtvIVU9efJEHT9+XB0/flwBaurUqer48ePq6tWrSimlBg8erDp27Gjc/vkrPF9++aU6ffq0mjFjhrzCk1Q//vijypMnj7K3t1eVK1dWBw8eNK6rUaOG6ty5s8n2q1atUkWKFFH29vaqZMmSavPmzalcsfaSc87y5s2rgHhfI0eOTP3CNZTcn7OXZbSQVSr552v//v3K19dXOTg4qAIFCqhx48ap2NjYVK5aW8k5ZzExMWrUqFGqYMGCytHRUfn4+KjevXurhw8fpn7hGggICEjw99Lzc9S5c2dVo0aNeJ8pV66csre3VwUKFFALFy5M9nFlqDshhBDCQjLUPVkhhBAiNUnICiGEEBYiISuEEEJYiISsEEIIYSESskIIIYSFSMgKIYQQFiIhK4QQQliIhKwQQghhIRKyQrxGYGAgOp2OwMBArUuxKJ1Ox6hRo5K0bb58+ejSpYtF6xEiPZCQFenWokWL0Ol0CX4NHjxY6/Je6b+1Ozo6UqRIEfr27RtvZBBL2b9/P6NGjSI0NDRVjpcU+fLlMzkvzs7OVK5cmZ9//jnF+9yyZUuS/7gQIrky1FB3ImMaM2YM+fPnN1lWqlQpjapJnue1R0ZGsnfvXmbNmsWWLVs4deoUmTNnNuuxnj59SqZML34l7N+/n9GjR9OlSxfc3NxMtj179qxmQ6OVK1eO//3vfwDcunWL+fPn07lzZ6KioujRo0ey97dlyxZmzJghQSssQkJWpHv16tVLs8PtvVx79+7dyZEjB1OnTmXDhg20bdvWrMdydHRM8rYODg5mPXZy5M6dmw4dOhjnu3TpQoECBfjuu+9SFLJCWJJcLhYZ1tWrV+nduzdFixbFycmJHDly0LJlS65cufLaz54/f57mzZuTM2dOHB0deeutt2jTpg2PHj0y2W7JkiVUqFABJycnsmfPTps2bbh+/XqKa65VqxYAly9fBiA2Npavv/6aggUL4uDgQL58+Rg6dChRUVEmnzty5Aj+/v64u7vj5ORE/vz56dq1q8k2L9+THTVqFF9++SUA+fPnN16efX5uXr4ne+TIEXQ6HYsXL45X77Zt29DpdGzatMm47ObNm3Tt2hUvLy8cHBwoWbIkCxYsSPE58fDwoFixYly8eNFk+Z49e2jZsiV58uTBwcEBHx8fPv/8c54+fWrcpkuXLsyYMcP4/T//ek6v1zNt2jRKliyJo6MjXl5e9OrVi4cPH6a4XpGxSEtWpHuPHj0iJCTEZJm7uzt//fUX+/fvp02bNrz11ltcuXKFWbNmUbNmTYKDgxO9HBsdHY2/vz9RUVH069ePnDlzcvPmTTZt2kRoaCiurq4AjBs3jq+++opWrVrRvXt37t27x48//kj16tU5fvx4vEuwSfE8SHLkyAEYWreLFy+mRYsW/O9//+PQoUNMmDCB06dPs379egDu3r1L3bp18fDwYPDgwbi5uXHlyhXWrVuX6HGaNWvGuXPnWL58Od999x3u7u6AIdD+q2LFihQoUIBVq1bRuXNnk3UrV64kW7Zs+Pv7A3Dnzh2qVKmCTqejb9++eHh48Pvvv9OtWzceP37MZ599luxzEhsby40bN8iWLZvJ8tWrVxMREcEnn3xCjhw5OHz4MD/++CM3btxg9erVAPTq1Yt///2XHTt28Msvv8Tbd69evVi0aBEfffQR/fv35/Lly0yfPp3jx4+zb98+7Ozskl2vyGDedIw+IazVwoULExw/8vmPfURERLzPHDhwQAHq559/Ni57Pg5lQECAUkoZB31evXp1ose+cuWKsrW1VePGjTNZfvLkSZUpU6Z4yxOrfefOnerevXvq+vXrasWKFSpHjhzKyclJ3bhxQwUFBSlAde/e3eSzX3zxhQLU7t27lVJKrV+/XgHqr7/+euUx+c+Yv5MnT1aAunz5crxt8+bNazJW6ZAhQ5SdnZ168OCBcVlUVJRyc3NTXbt2NS7r1q2b8vb2ViEhISb7a9OmjXJ1dU3w3+S/x61bt666d++eunfvnjp58qTq2LGjAlSfPn1Mtk1oXxMmTFA6nc44ULdSSvXp00cl9Ktwz549ClBLly41Wb5169YElwuRELlcLNK9GTNmsGPHDpMvACcnJ+M2MTEx3L9/n0KFCuHm5saxY8cS3d/zluq2bduIiIhIcJt169ah1+tp1aoVISEhxq+cOXNSuHBhAgICklR77dq18fDwwMfHhzZt2pAlSxbWr19P7ty52bJlCwADBgww+czzh4I2b94MYGwxb9q0iZiYmCQdN7lat25NTEyMSet4+/bthIaG0rp1awCUUqxdu5ZGjRqhlDI5L/7+/jx69OiV5/3l/Xp4eODh4UHp0qX55Zdf+Oijj5g8ebLJdi//+4aHhxMSEsI777yDUorjx4+/9jirV6/G1dWVOnXqmNRaoUIFsmTJkuR/Q5GxyeVike5Vrlw5wQefnj59yoQJE1i4cCE3b95EKWVc9997qy/Lnz8/AwYMYOrUqSxdupRq1arRuHFjOnToYAzg8+fPo5SicOHCCe4jqZcZZ8yYQZEiRciUKRNeXl4ULVrU+FTv1atXsbGxoVChQiafyZkzJ25ubly9ehWAGjVq0Lx5c0aPHs13331HzZo1adKkCe3atTPbA0xly5alWLFirFy5km7dugGGS8Xu7u7G+8j37t0jNDSUuXPnMnfu3AT3c/fu3dcey9fXl7FjxxIXF8epU6cYO3YsDx8+xN7e3mS7a9euMWLECH777bd491Bf9e/73Pnz53n06BGenp4prlUICVmRYfXr14+FCxfy2WefUbVqVVxdXdHpdLRp0wa9Xv/Kz06ZMoUuXbqwYcMGtm/fTv/+/ZkwYQIHDx7krbfeQq/Xo9Pp+P3337G1tY33+SxZsiSpxsT+QHjZyw/qJLZ+zZo1HDx4kI0bN7Jt2za6du3KlClTOHjwYJJreZ3WrVszbtw4QkJCyJo1K7/99htt27Y1vhb0/Jx26NAh3r3b58qUKfPa47i7u1O7dm0A/P39KVasGA0bNuT77783turj4uKoU6cODx48YNCgQRQrVgxnZ2du3rxJly5dXvvv+7xeT09Pli5dmuD6hO5PC/FfErIiw1qzZg2dO3dmypQpxmWRkZFJ7nyhdOnSlC5dmuHDh7N//37effddZs+ezdixYylYsCBKKfLnz0+RIkUsUn/evHnR6/WcP3+e4sWLG5ffuXOH0NBQ8ubNa7J9lSpVqFKlCuPGjWPZsmW0b9+eFStW0L179wT3/7rw/q/WrVszevRo1q5di5eXF48fP6ZNmzbG9R4eHmTNmpW4uDhjSJpDgwYNqFGjBuPHj6dXr144Oztz8uRJzp07x+LFi+nUqZNx2+e3Cl6W2PdZsGBBdu7cybvvvmty6VmI5JB7siLDsrW1NblEDPDjjz8SFxf3ys89fvyY2NhYk2WlS5fGxsbG+OpMs2bNsLW1ZfTo0fGOoZTi/v37b1x//fr1AZg2bZrJ8qlTpwKG8AF4+PBhvBrKlSsHEO9Vn5c5OzsDJPmPjuLFi1O6dGlWrlzJypUr8fb2pnr16sb1tra2NG/enLVr13Lq1Kl4n793716SjpOQQYMGcf/+febNm2c8FmDyfSul+P777+N9NrHvs1WrVsTFxfH111/H+0xsbKxV9YQlrJe0ZEWG1bBhQ3755RdcXV0pUaIEBw4cYOfOncbXYxKze/du+vbtS8uWLSlSpAixsbH88ssvxhABQyto7NixDBkyhCtXrtCkSROyZs3K5cuXWb9+PT179uSLL754o/rLli1L586dmTt3LqGhodSoUYPDhw+zePFimjRpgp+fHwCLFy9m5syZNG3alIIFC/LkyRPmzZuHi4uLMagTUqFCBQCGDRtGmzZtsLOzo1GjRsZQSkjr1q0ZMWIEjo6OdOvWLV6vUBMnTiQgIABfX1969OhBiRIlePDgAceOHWPnzp08ePAgReeiXr16lCpViqlTp9KnTx+KFStGwYIF+eKLL7h58yYuLi6sXbs2wfdbn3+f/fv3x9/fH1tbW9q0aUONGjXo1asXEyZMICgoiLp162JnZ8f58+dZvXo133//PS1atEhRvSID0eahZiEs7/lrMIm9uvLw4UP10UcfKXd3d5UlSxbl7++vzpw5E+/1lP++wnPp0iXVtWtXVbBgQeXo6KiyZ8+u/Pz81M6dO+MdY+3ateq9995Tzs7OytnZWRUrVkz16dNHnT179o1qfy4mJkaNHj1a5c+fX9nZ2SkfHx81ZMgQFRkZadzm2LFjqm3btipPnjzKwcFBeXp6qoYNG6ojR46Y7Iv/vMKjlFJff/21yp07t7KxsTF5nee/5+i58+fPG1+T2rt3b4I137lzR/Xp00f5+PgoOzs7lTNnTvX++++ruXPnvvJ7fX7cBg0aJLhu0aJFClALFy5USikVHBysateurbJkyaLc3d1Vjx491IkTJ0y2UUqp2NhY1a9fP+Xh4aF0Ol2813nmzp2rKlSooJycnFTWrFlV6dKl1cCBA9W///772nqF0Cn1n+tIQgghhDALuScrhBBCWIiErBBCCGEhErJCCCGEhUjICiGEEBYiISuEEEJYiISsEEIIYSESskIIIYSFSMgKIYQQFiIhK4QQQliIhKwQQghhIRKyQgghhIVIyAohhBAW8n+BxbAVlKQrjwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('1D CNN')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('ROC_Curve_cms_1d_cnn.pdf', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
