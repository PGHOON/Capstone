{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 16:27:48.080235: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-29 16:27:48.131624: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9360] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-29 16:27:48.131658: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-29 16:27:48.131690: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1537] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-29 16:27:48.140621: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Input, Flatten, Conv2D, BatchNormalization, LeakyReLU, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, Activation, Add\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Calls List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "syscalls = [\n",
    "\"sys_enter_llistxattr\",\n",
    "\"sys_enter_setgroups\",\n",
    "\"sys_enter_lremovexattr\",\n",
    "\"sys_enter_sethostname\",\n",
    "\"sys_enter_accept\",\n",
    "\"sys_enter_lseek\",\n",
    "\"sys_enter_setitimer\",\n",
    "\"sys_enter_accept4\",\n",
    "\"sys_enter_lsetxattr\",\n",
    "\"sys_enter_setns\",\n",
    "\"sys_enter_acct\",\n",
    "\"sys_enter_madvise\",\n",
    "\"sys_enter_setpgid\",\n",
    "\"sys_enter_add_key\",\n",
    "\"sys_enter_mbind\",\n",
    "\"sys_enter_setpriority\",\n",
    "\"sys_enter_adjtimex\",\n",
    "\"sys_enter_membarrier\",\n",
    "\"sys_enter_setregid\",\n",
    "\"sys_enter_personality\",\n",
    "\"sys_enter_memfd_create\",\n",
    "\"sys_enter_setresgid\",\n",
    "\"sys_enter_bind\",\n",
    "\"sys_enter_memfd_secret\",\n",
    "\"sys_enter_setresuid\",\n",
    "\"sys_enter_bpf\",\n",
    "\"sys_enter_migrate_pages\",\n",
    "\"sys_enter_setreuid\",\n",
    "\"sys_enter_brk\",\n",
    "\"sys_enter_mincore\",\n",
    "\"sys_enter_setrlimit\",\n",
    "\"sys_enter_capget\",\n",
    "\"sys_enter_mkdirat\",\n",
    "\"sys_enter_setsid\",\n",
    "\"sys_enter_capset\",\n",
    "\"sys_enter_mknodat\",\n",
    "\"sys_enter_setsockopt\",\n",
    "\"sys_enter_chdir\",\n",
    "\"sys_enter_mlock\",\n",
    "\"sys_enter_settimeofday\",\n",
    "\"sys_enter_chroot\",\n",
    "\"sys_enter_mlock2\",\n",
    "\"sys_enter_setuid\",\n",
    "\"sys_enter_clock_adjtime\",\n",
    "\"sys_enter_mlockall\",\n",
    "\"sys_enter_setxattr\",\n",
    "\"sys_enter_clock_getres\",\n",
    "\"sys_enter_mmap\",\n",
    "\"sys_enter_shmat\",\n",
    "\"sys_enter_clock_gettime\",\n",
    "\"sys_enter_mount\",\n",
    "\"sys_enter_shmctl\",\n",
    "\"sys_enter_clock_nanosleep\",\n",
    "\"sys_enter_mount_setattr\",\n",
    "\"sys_enter_shmdt\",\n",
    "\"sys_enter_clock_settime\",\n",
    "\"sys_enter_move_mount\",\n",
    "\"sys_enter_shmget\",\n",
    "\"sys_enter_clone\",\n",
    "\"sys_enter_move_pages\",\n",
    "\"sys_enter_shutdown\",\n",
    "\"sys_enter_clone3\",\n",
    "\"sys_enter_mprotect\",\n",
    "\"sys_enter_sigaltstack\",\n",
    "\"sys_enter_close\",\n",
    "\"sys_enter_mq_getsetattr\",\n",
    "\"sys_enter_signalfd4\",\n",
    "\"sys_enter_close_range\",\n",
    "\"sys_enter_mq_notify\",\n",
    "\"sys_enter_socket\",\n",
    "\"sys_enter_connect\",\n",
    "\"sys_enter_mq_open\",\n",
    "\"sys_enter_socketpair\",\n",
    "\"sys_enter_copy_file_range\",\n",
    "\"sys_enter_mq_timedreceive\",\n",
    "\"sys_enter_splice\",\n",
    "\"sys_enter_delete_module\",\n",
    "\"sys_enter_mq_timedsend\",\n",
    "\"sys_enter_statfs\",\n",
    "\"sys_enter_dup\",\n",
    "\"sys_enter_mq_unlink\",\n",
    "\"sys_enter_statx\",\n",
    "\"sys_enter_dup3\",\n",
    "\"sys_enter_mremap\",\n",
    "\"sys_enter_swapoff\",\n",
    "\"sys_enter_epoll_create1\",\n",
    "\"sys_enter_msgctl\",\n",
    "\"sys_enter_swapon\",\n",
    "\"sys_enter_epoll_ctl\",\n",
    "\"sys_enter_msgget\",\n",
    "\"sys_enter_symlinkat\",\n",
    "\"sys_enter_epoll_pwait\",\n",
    "\"sys_enter_msgrcv\",\n",
    "\"sys_enter_sync\",\n",
    "\"sys_enter_epoll_pwait2\",\n",
    "\"sys_enter_msgsnd\",\n",
    "\"sys_enter_sync_file_range\",\n",
    "\"sys_enter_eventfd2\",\n",
    "\"sys_enter_msync\",\n",
    "\"sys_enter_syncfs\",\n",
    "\"sys_enter_execve\",\n",
    "\"sys_enter_munlock\",\n",
    "\"sys_enter_sysinfo\",\n",
    "\"sys_enter_execveat\",\n",
    "\"sys_enter_munlockall\",\n",
    "\"sys_enter_syslog\",\n",
    "\"sys_enter_exit\",\n",
    "\"sys_enter_munmap\",\n",
    "\"sys_enter_tee\",\n",
    "\"sys_enter_exit_group\",\n",
    "\"sys_enter_name_to_handle_at\",\n",
    "\"sys_enter_tgkill\",\n",
    "\"sys_enter_faccessat\",\n",
    "\"sys_enter_nanosleep\",\n",
    "\"sys_enter_timer_create\",\n",
    "\"sys_enter_faccessat2\",\n",
    "\"sys_enter_newfstat\",\n",
    "\"sys_enter_timer_delete\",\n",
    "\"sys_enter_fadvise64\",\n",
    "\"sys_enter_newfstatat\",\n",
    "\"sys_enter_timer_getoverrun\",\n",
    "\"sys_enter_fallocate\",\n",
    "\"sys_enter_newuname\",\n",
    "\"sys_enter_timer_gettime\",\n",
    "\"sys_enter_fanotify_init\",\n",
    "\"sys_enter_open_by_handle_at\",\n",
    "\"sys_enter_timer_settime\",\n",
    "\"sys_enter_fanotify_mark\",\n",
    "\"sys_enter_open_tree\",\n",
    "\"sys_enter_timerfd_create\",\n",
    "\"sys_enter_fchdir\",\n",
    "\"sys_enter_openat\",\n",
    "\"sys_enter_timerfd_gettime\",\n",
    "\"sys_enter_fchmod\",\n",
    "\"sys_enter_openat2\",\n",
    "\"sys_enter_timerfd_settime\",\n",
    "\"sys_enter_fchmodat\",\n",
    "\"sys_enter_perf_event_open\",\n",
    "\"sys_enter_times\",\n",
    "\"sys_enter_fchown\",\n",
    "\"sys_enter_pidfd_getfd\",\n",
    "\"sys_enter_tkill\",\n",
    "\"sys_enter_fchownat\",\n",
    "\"sys_enter_pidfd_open\",\n",
    "\"sys_enter_truncate\",\n",
    "\"sys_enter_fcntl\",\n",
    "\"sys_enter_pidfd_send_signal\",\n",
    "\"sys_enter_umask\",\n",
    "\"sys_enter_fdatasync\",\n",
    "\"sys_enter_pipe2\",\n",
    "\"sys_enter_umount\",\n",
    "\"sys_enter_fgetxattr\",\n",
    "\"sys_enter_pivot_root\",\n",
    "\"sys_enter_unlinkat\",\n",
    "\"sys_enter_finit_module\",\n",
    "\"sys_enter_ppoll\",\n",
    "\"sys_enter_unshare\",\n",
    "\"sys_enter_flistxattr\",\n",
    "\"sys_enter_prctl\",\n",
    "\"sys_enter_userfaultfd\",\n",
    "\"sys_enter_flock\",\n",
    "\"sys_enter_pread64\",\n",
    "\"sys_enter_utimensat\",\n",
    "\"sys_enter_fremovexattr\",\n",
    "\"sys_enter_preadv\",\n",
    "\"sys_enter_vhangup\",\n",
    "\"sys_enter_fsconfig\",\n",
    "\"sys_enter_preadv2\",\n",
    "\"sys_enter_vmsplice\",\n",
    "\"sys_enter_fsetxattr\",\n",
    "\"sys_enter_prlimit64\",\n",
    "\"sys_enter_wait4\",\n",
    "\"sys_enter_fsmount\",\n",
    "\"sys_enter_process_madvise\",\n",
    "\"sys_enter_waitid\",\n",
    "\"sys_enter_fsopen\",\n",
    "\"sys_enter_process_mrelease\",\n",
    "\"sys_enter_write\",\n",
    "\"sys_enter_fspick\",\n",
    "\"sys_enter_process_vm_readv\",\n",
    "\"sys_enter_writev\",\n",
    "\"sys_enter_fstatfs\",\n",
    "\"sys_enter_process_vm_writev\",\n",
    "\"sys_enter_fsync\",\n",
    "\"sys_enter_pselect6\",\n",
    "\"sys_enter_ftruncate\",\n",
    "\"sys_enter_ptrace\",\n",
    "\"sys_enter_futex\",\n",
    "\"sys_enter_pwrite64\",\n",
    "\"sys_enter_get_mempolicy\",\n",
    "\"sys_enter_pwritev\",\n",
    "\"sys_enter_get_robust_list\",\n",
    "\"sys_enter_pwritev2\",\n",
    "\"sys_enter_getcpu\",\n",
    "\"sys_enter_quotactl\",\n",
    "\"sys_enter_getcwd\",\n",
    "\"sys_enter_quotactl_fd\",\n",
    "\"sys_enter_getdents64\",\n",
    "\"sys_enter_read\",\n",
    "\"sys_enter_getegid\",\n",
    "\"sys_enter_readahead\",\n",
    "\"sys_enter_geteuid\",\n",
    "\"sys_enter_readlinkat\",\n",
    "\"sys_enter_getgid\",\n",
    "\"sys_enter_readv\",\n",
    "\"sys_enter_getgroups\",\n",
    "\"sys_enter_reboot\",\n",
    "\"sys_enter_getitimer\",\n",
    "\"sys_enter_recvfrom\",\n",
    "\"sys_enter_getpeername\",\n",
    "\"sys_enter_recvmmsg\",\n",
    "\"sys_enter_getpgid\",\n",
    "\"sys_enter_recvmsg\",\n",
    "\"sys_enter_getpid\",\n",
    "\"sys_enter_remap_file_pages\",\n",
    "\"sys_enter_getppid\",\n",
    "\"sys_enter_removexattr\",\n",
    "\"sys_enter_getpriority\",\n",
    "\"sys_enter_renameat\",\n",
    "\"sys_enter_getrandom\",\n",
    "\"sys_enter_renameat2\",\n",
    "\"sys_enter_getresgid\",\n",
    "\"sys_enter_request_key\",\n",
    "\"sys_enter_getresuid\",\n",
    "\"sys_enter_restart_syscall\",\n",
    "\"sys_enter_getrlimit\",\n",
    "\"sys_enter_rseq\",\n",
    "\"sys_enter_getrusage\",\n",
    "\"sys_enter_rt_sigaction\",\n",
    "\"sys_enter_getsid\",\n",
    "\"sys_enter_rt_sigpending\",\n",
    "\"sys_enter_getsockname\",\n",
    "\"sys_enter_rt_sigprocmask\",\n",
    "\"sys_enter_getsockopt\",\n",
    "\"sys_enter_rt_sigqueueinfo\",\n",
    "\"sys_enter_gettid\",\n",
    "\"sys_enter_rt_sigreturn\",\n",
    "\"sys_enter_gettimeofday\",\n",
    "\"sys_enter_rt_sigsuspend\",\n",
    "\"sys_enter_getuid\",\n",
    "\"sys_enter_rt_sigtimedwait\",\n",
    "\"sys_enter_getxattr\",\n",
    "\"sys_enter_rt_tgsigqueueinfo\",\n",
    "\"sys_enter_init_module\",\n",
    "\"sys_enter_sched_get_priority_max\",\n",
    "\"sys_enter_inotify_add_watch\",\n",
    "\"sys_enter_sched_get_priority_min\",\n",
    "\"sys_enter_inotify_init1\",\n",
    "\"sys_enter_sched_getaffinity\",\n",
    "\"sys_enter_inotify_rm_watch\",\n",
    "\"sys_enter_sched_getattr\",\n",
    "\"sys_enter_io_cancel\",\n",
    "\"sys_enter_sched_getparam\",\n",
    "\"sys_enter_io_destroy\",\n",
    "\"sys_enter_sched_getscheduler\",\n",
    "\"sys_enter_io_getevents\",\n",
    "\"sys_enter_sched_rr_get_interval\",\n",
    "\"sys_enter_io_pgetevents\",\n",
    "\"sys_enter_sched_setaffinity\",\n",
    "\"sys_enter_io_setup\",\n",
    "\"sys_enter_sched_setattr\",\n",
    "\"sys_enter_io_submit\",\n",
    "\"sys_enter_sched_setparam\",\n",
    "\"sys_enter_io_uring_enter\",\n",
    "\"sys_enter_sched_setscheduler\",\n",
    "\"sys_enter_io_uring_register\",\n",
    "\"sys_enter_sched_yield\",\n",
    "\"sys_enter_io_uring_setup\",\n",
    "\"sys_enter_seccomp\",\n",
    "\"sys_enter_ioctl\",\n",
    "\"sys_enter_semctl\",\n",
    "\"sys_enter_ioprio_get\",\n",
    "\"sys_enter_semget\",\n",
    "\"sys_enter_ioprio_set\",\n",
    "\"sys_enter_semop\",\n",
    "\"sys_enter_kcmp\",\n",
    "\"sys_enter_semtimedop\",\n",
    "\"sys_enter_kexec_file_load\",\n",
    "\"sys_enter_sendfile64\",\n",
    "\"sys_enter_kexec_load\",\n",
    "\"sys_enter_sendmmsg\",\n",
    "\"sys_enter_keyctl\",\n",
    "\"sys_enter_sendmsg\",\n",
    "\"sys_enter_kill\",\n",
    "\"sys_enter_sendto\",\n",
    "\"sys_enter_landlock_add_rule\",\n",
    "\"sys_enter_set_mempolicy\",\n",
    "\"sys_enter_landlock_create_ruleset\",\n",
    "\"sys_enter_set_robust_list\",\n",
    "\"sys_enter_landlock_restrict_self\",\n",
    "\"sys_enter_set_tid_address\",\n",
    "\"sys_enter_lgetxattr\",\n",
    "\"sys_enter_setdomainname\",\n",
    "\"sys_enter_linkat\",\n",
    "\"sys_enter_setfsgid\",\n",
    "\"sys_enter_listen\",\n",
    "\"sys_enter_setfsuid\",\n",
    "\"sys_enter_listxattr\",\n",
    "\"sys_enter_setgid\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CSV from Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3\n",
    "CLASSES = np.array(['benign', 'sysrv', 'xmrig'])\n",
    "DATASET_DIR = \"raw_data/\"\n",
    "WIDTH = 32\n",
    "HEIGHT = 32\n",
    "SHAPE = (WIDTH, HEIGHT)\n",
    "SIZE = WIDTH * HEIGHT * 1\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(syscalls)\n",
    "\n",
    "def csvToImage(file_path):\n",
    "    try:\n",
    "        data = pd.read_csv(file_path, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "    \n",
    "    data_encoded = label_encoder.fit_transform(data['SYSTEM_CALL'])\n",
    "    image = np.zeros(SHAPE, dtype=np.uint8)\n",
    "    syscall_nums = min(len(data_encoded), SIZE)\n",
    "    image.flat[:syscall_nums] = data_encoded[:syscall_nums]\n",
    "\n",
    "    return image\n",
    "\n",
    "def process_file(args):\n",
    "    file_path, class_idx = args\n",
    "    image = csvToImage(file_path)\n",
    "    return image, class_idx\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    x = []\n",
    "    y = []\n",
    "    classes = [\"0/60sec_0\", \"1/60sec_1\", \"2/60sec_2\"]\n",
    "\n",
    "    file_paths = []\n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        for file_name in os.listdir(class_dir):\n",
    "            if file_name.endswith('.csv'):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                file_paths.append((file_path, class_idx))\n",
    "\n",
    "    with Pool() as pool:\n",
    "        results = pool.map(process_file, file_paths)\n",
    "\n",
    "    x, y = zip(*results)\n",
    "    x = np.array(x).reshape(-1, WIDTH, HEIGHT, 1)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 400\n",
    "nth_image = X[n].reshape(32, 32)\n",
    "\n",
    "plt.imshow(nth_image)\n",
    "plt.title(f'${n}^{{th}}$ Image in Dataset')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validation, Test Split and Nomalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train / 299.0\n",
    "X_val = X_val / 299.0\n",
    "X_test = X_test / 299.0\n",
    "\n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_val = to_categorical(y_val, 3)\n",
    "y_test = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1045, 32, 32, 1)\n",
      "(561, 32, 32, 1)\n",
      "(262, 32, 32, 1)\n",
      "(1045, 3)\n",
      "(561, 3)\n",
      "(262, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 16:28:09.614454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31350 MB memory:  -> device: 0, name: CUDA GPU, pci bus id: 0000:06:00.0, compute capability: 7.0\n",
      "2024-07-29 16:28:09.614982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31350 MB memory:  -> device: 1, name: CUDA GPU, pci bus id: 0000:2f:00.0, compute capability: 7.0\n",
      "2024-07-29 16:28:09.615462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 31350 MB memory:  -> device: 2, name: CUDA GPU, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input((WIDTH, HEIGHT, 1))\n",
    "\n",
    "x = Conv2D(filters=32, kernel_size=3, padding='same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(256)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 16, 16, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)         8320      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 8, 8, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               2097408   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2127235 (8.11 MB)\n",
      "Trainable params: 2126275 (8.11 MB)\n",
      "Non-trainable params: 960 (3.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='/tmp/CNN2d_checkpoint.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 16:28:12.084912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2024-07-29 16:28:13.524807: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9814b064a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-29 16:28:13.524842: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): CUDA GPU, Compute Capability 7.0\n",
      "2024-07-29 16:28:13.524849: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): CUDA GPU, Compute Capability 7.0\n",
      "2024-07-29 16:28:13.524854: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): CUDA GPU, Compute Capability 7.0\n",
      "2024-07-29 16:28:13.530830: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-29 16:28:13.625120: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - ETA: 0s - loss: 0.5916 - accuracy: 0.8612\n",
      "Epoch 1: val_accuracy improved from -inf to 0.72519, saving model to /tmp/CNN2d_checkpoint.h5\n",
      "33/33 [==============================] - 5s 24ms/step - loss: 0.5916 - accuracy: 0.8612 - val_loss: 0.8775 - val_accuracy: 0.7252\n",
      "Epoch 2/100\n",
      " 1/33 [..............................] - ETA: 0s - loss: 0.3068 - accuracy: 0.8125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - ETA: 0s - loss: 0.1963 - accuracy: 0.9464\n",
      "Epoch 2: val_accuracy did not improve from 0.72519\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.1963 - accuracy: 0.9464 - val_loss: 1.0718 - val_accuracy: 0.7252\n",
      "Epoch 3/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.1460 - accuracy: 0.9579\n",
      "Epoch 3: val_accuracy did not improve from 0.72519\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.1634 - accuracy: 0.9483 - val_loss: 1.2757 - val_accuracy: 0.7252\n",
      "Epoch 4/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.1524 - accuracy: 0.9606\n",
      "Epoch 4: val_accuracy did not improve from 0.72519\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.1383 - accuracy: 0.9636 - val_loss: 1.5760 - val_accuracy: 0.7252\n",
      "Epoch 5/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.1168 - accuracy: 0.9783\n",
      "Epoch 5: val_accuracy did not improve from 0.72519\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.1105 - accuracy: 0.9751 - val_loss: 1.9853 - val_accuracy: 0.7252\n",
      "Epoch 6/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0894 - accuracy: 0.9779\n",
      "Epoch 6: val_accuracy did not improve from 0.72519\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 0.9828 - val_loss: 2.4858 - val_accuracy: 0.7252\n",
      "Epoch 7/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0434 - accuracy: 0.9883\n",
      "Epoch 7: val_accuracy did not improve from 0.72519\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 3.0040 - val_accuracy: 0.7252\n",
      "Epoch 8/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0395 - accuracy: 0.9896\n",
      "Epoch 8: val_accuracy did not improve from 0.72519\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9914 - val_loss: 3.5807 - val_accuracy: 0.7252\n",
      "Epoch 9/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0260 - accuracy: 0.9946\n",
      "Epoch 9: val_accuracy did not improve from 0.72519\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 0.9933 - val_loss: 2.8760 - val_accuracy: 0.7252\n",
      "Epoch 10/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0188 - accuracy: 0.9946\n",
      "Epoch 10: val_accuracy did not improve from 0.72519\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0224 - accuracy: 0.9943 - val_loss: 2.7599 - val_accuracy: 0.7252\n",
      "Epoch 11/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0293 - accuracy: 0.9932\n",
      "Epoch 11: val_accuracy did not improve from 0.72519\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0344 - accuracy: 0.9914 - val_loss: 2.4915 - val_accuracy: 0.7252\n",
      "Epoch 12/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0300 - accuracy: 0.9935\n",
      "Epoch 12: val_accuracy improved from 0.72519 to 0.86641, saving model to /tmp/CNN2d_checkpoint.h5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0268 - accuracy: 0.9933 - val_loss: 1.4466 - val_accuracy: 0.8664\n",
      "Epoch 13/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0211 - accuracy: 0.9948\n",
      "Epoch 13: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 0.9962 - val_loss: 1.7516 - val_accuracy: 0.8626\n",
      "Epoch 14/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0126 - accuracy: 0.9974\n",
      "Epoch 14: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0169 - accuracy: 0.9971 - val_loss: 2.6940 - val_accuracy: 0.7328\n",
      "Epoch 15/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0421 - accuracy: 0.9883\n",
      "Epoch 15: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9895 - val_loss: 22.6939 - val_accuracy: 0.2099\n",
      "Epoch 16/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0256 - accuracy: 0.9905\n",
      "Epoch 16: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.9904 - val_loss: 13.3541 - val_accuracy: 0.2099\n",
      "Epoch 17/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0398 - accuracy: 0.9891\n",
      "Epoch 17: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0329 - accuracy: 0.9914 - val_loss: 29.1607 - val_accuracy: 0.2099\n",
      "Epoch 18/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0091 - accuracy: 0.9986\n",
      "Epoch 18: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9895 - val_loss: 40.8302 - val_accuracy: 0.2099\n",
      "Epoch 19/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0231 - accuracy: 0.9937\n",
      "Epoch 19: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 39.2720 - val_accuracy: 0.2099\n",
      "Epoch 20/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0173 - accuracy: 0.9948\n",
      "Epoch 20: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 0.9962 - val_loss: 51.0576 - val_accuracy: 0.2099\n",
      "Epoch 21/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0097 - accuracy: 0.9948\n",
      "Epoch 21: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9952 - val_loss: 41.4242 - val_accuracy: 0.2099\n",
      "Epoch 22/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0075 - accuracy: 0.9975\n",
      "Epoch 22: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 71.2325 - val_accuracy: 0.2099\n",
      "Epoch 23/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 23: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 83.4969 - val_accuracy: 0.2099\n",
      "Epoch 24/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000  \n",
      "Epoch 24: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 92.1211 - val_accuracy: 0.2099\n",
      "Epoch 25/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0132 - accuracy: 0.9961\n",
      "Epoch 25: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 75.0374 - val_accuracy: 0.2099\n",
      "Epoch 26/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0151 - accuracy: 0.9948  \n",
      "Epoch 26: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 72.7599 - val_accuracy: 0.2099\n",
      "Epoch 27/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0217 - accuracy: 0.9935\n",
      "Epoch 27: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 66.3413 - val_accuracy: 0.2099\n",
      "Epoch 28/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0493 - accuracy: 0.9864\n",
      "Epoch 28: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9885 - val_loss: 141.4585 - val_accuracy: 0.2099\n",
      "Epoch 29/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0064 - accuracy: 0.9987\n",
      "Epoch 29: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 123.7462 - val_accuracy: 0.2099\n",
      "Epoch 30/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0119 - accuracy: 0.9935  \n",
      "Epoch 30: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0116 - accuracy: 0.9943 - val_loss: 109.2784 - val_accuracy: 0.2099\n",
      "Epoch 31/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 31: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 106.1985 - val_accuracy: 0.2099\n",
      "Epoch 32/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0094 - accuracy: 0.9974\n",
      "Epoch 32: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0159 - accuracy: 0.9962 - val_loss: 105.0865 - val_accuracy: 0.2099\n",
      "Epoch 33/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0112 - accuracy: 0.9950  \n",
      "Epoch 33: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 0.9943 - val_loss: 81.0283 - val_accuracy: 0.2099\n",
      "Epoch 34/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0054 - accuracy: 0.9975\n",
      "Epoch 34: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 128.3215 - val_accuracy: 0.2099\n",
      "Epoch 35/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0053 - accuracy: 0.9987\n",
      "Epoch 35: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 118.4828 - val_accuracy: 0.2099\n",
      "Epoch 36/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 36: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 105.0127 - val_accuracy: 0.2099\n",
      "Epoch 37/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 37: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 93.2614 - val_accuracy: 0.2099\n",
      "Epoch 38/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 38: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 101.5178 - val_accuracy: 0.2099\n",
      "Epoch 39/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0053 - accuracy: 0.9975\n",
      "Epoch 39: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 127.9998 - val_accuracy: 0.2099\n",
      "Epoch 40/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0052 - accuracy: 0.9987\n",
      "Epoch 40: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 43.9846 - val_accuracy: 0.2099\n",
      "Epoch 41/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000  \n",
      "Epoch 41: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 62.4939 - val_accuracy: 0.2099\n",
      "Epoch 42/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000  \n",
      "Epoch 42: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 58.6968 - val_accuracy: 0.2099\n",
      "Epoch 43/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 8.7771e-04 - accuracy: 1.0000\n",
      "Epoch 43: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.5977e-04 - accuracy: 1.0000 - val_loss: 65.9779 - val_accuracy: 0.2099\n",
      "Epoch 44/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 44: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 73.0915 - val_accuracy: 0.2099\n",
      "Epoch 45/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000  \n",
      "Epoch 45: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 98.5679 - val_accuracy: 0.2099\n",
      "Epoch 46/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
      "Epoch 46: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 112.9844 - val_accuracy: 0.2099\n",
      "Epoch 47/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000  \n",
      "Epoch 47: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 95.7085 - val_accuracy: 0.2099\n",
      "Epoch 48/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0029 - accuracy: 0.9987  \n",
      "Epoch 48: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 66.9560 - val_accuracy: 0.2099\n",
      "Epoch 49/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000  \n",
      "Epoch 49: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 186.3959 - val_accuracy: 0.2099\n",
      "Epoch 50/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 50: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 130.9327 - val_accuracy: 0.2099\n",
      "Epoch 51/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 8.0097e-04 - accuracy: 1.0000\n",
      "Epoch 51: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.8278e-04 - accuracy: 1.0000 - val_loss: 123.8633 - val_accuracy: 0.2099\n",
      "Epoch 52/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 5.6855e-04 - accuracy: 1.0000\n",
      "Epoch 52: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.4677e-04 - accuracy: 1.0000 - val_loss: 130.5035 - val_accuracy: 0.2099\n",
      "Epoch 53/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 5.7456e-04 - accuracy: 1.0000\n",
      "Epoch 53: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.8267e-04 - accuracy: 1.0000 - val_loss: 139.4029 - val_accuracy: 0.2099\n",
      "Epoch 54/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 7.8529e-04 - accuracy: 1.0000\n",
      "Epoch 54: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 7.4640e-04 - accuracy: 1.0000 - val_loss: 126.9174 - val_accuracy: 0.2099\n",
      "Epoch 55/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 4.6064e-04 - accuracy: 1.0000\n",
      "Epoch 55: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.6648e-04 - accuracy: 1.0000 - val_loss: 137.5428 - val_accuracy: 0.2099\n",
      "Epoch 56/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0031 - accuracy: 0.9986  \n",
      "Epoch 56: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 130.5788 - val_accuracy: 0.2099\n",
      "Epoch 57/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 5.6284e-04 - accuracy: 1.0000\n",
      "Epoch 57: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 4.8131e-04 - accuracy: 1.0000 - val_loss: 120.8577 - val_accuracy: 0.2099\n",
      "Epoch 58/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 4.5152e-04 - accuracy: 1.0000\n",
      "Epoch 58: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.2052e-04 - accuracy: 1.0000 - val_loss: 122.0894 - val_accuracy: 0.2099\n",
      "Epoch 59/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000  \n",
      "Epoch 59: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 146.3829 - val_accuracy: 0.2099\n",
      "Epoch 60/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0239 - accuracy: 0.9925  \n",
      "Epoch 60: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 187.4718 - val_accuracy: 0.2099\n",
      "Epoch 61/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0155 - accuracy: 0.9974\n",
      "Epoch 61: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 199.2225 - val_accuracy: 0.2099\n",
      "Epoch 62/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0111 - accuracy: 0.9950\n",
      "Epoch 62: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 0.9962 - val_loss: 175.6031 - val_accuracy: 0.2099\n",
      "Epoch 63/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0047 - accuracy: 0.9975  \n",
      "Epoch 63: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.9981 - val_loss: 122.8515 - val_accuracy: 0.2099\n",
      "Epoch 64/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
      "Epoch 64: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 104.0614 - val_accuracy: 0.2099\n",
      "Epoch 65/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000  \n",
      "Epoch 65: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 124.6832 - val_accuracy: 0.2099\n",
      "Epoch 66/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 66: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 106.7523 - val_accuracy: 0.2099\n",
      "Epoch 67/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 67: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.9990 - val_loss: 123.6371 - val_accuracy: 0.2099\n",
      "Epoch 68/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 5.3016e-04 - accuracy: 1.0000\n",
      "Epoch 68: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.0336e-04 - accuracy: 1.0000 - val_loss: 116.7046 - val_accuracy: 0.2099\n",
      "Epoch 69/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 2.1120e-04 - accuracy: 1.0000\n",
      "Epoch 69: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 5.2793e-04 - accuracy: 1.0000 - val_loss: 112.2027 - val_accuracy: 0.2099\n",
      "Epoch 70/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 8.5118e-04 - accuracy: 1.0000\n",
      "Epoch 70: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 137.9922 - val_accuracy: 0.2099\n",
      "Epoch 71/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000  \n",
      "Epoch 71: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 129.5983 - val_accuracy: 0.2099\n",
      "Epoch 72/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0035 - accuracy: 0.9987\n",
      "Epoch 72: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 127.2425 - val_accuracy: 0.2099\n",
      "Epoch 73/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000  \n",
      "Epoch 73: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.3985e-04 - accuracy: 1.0000 - val_loss: 116.6158 - val_accuracy: 0.2099\n",
      "Epoch 74/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 2.0739e-04 - accuracy: 1.0000\n",
      "Epoch 74: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.3908e-04 - accuracy: 1.0000 - val_loss: 113.9721 - val_accuracy: 0.2099\n",
      "Epoch 75/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 7.7251e-04 - accuracy: 1.0000\n",
      "Epoch 75: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 6.7073e-04 - accuracy: 1.0000 - val_loss: 138.8687 - val_accuracy: 0.2099\n",
      "Epoch 76/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 9.5121e-04 - accuracy: 1.0000\n",
      "Epoch 76: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.4016e-04 - accuracy: 1.0000 - val_loss: 142.9787 - val_accuracy: 0.2099\n",
      "Epoch 77/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 2.2602e-04 - accuracy: 1.0000\n",
      "Epoch 77: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 174.3429 - val_accuracy: 0.2099\n",
      "Epoch 78/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0234 - accuracy: 0.9925\n",
      "Epoch 78: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 0.9914 - val_loss: 172.5638 - val_accuracy: 0.2099\n",
      "Epoch 79/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0078 - accuracy: 0.9973\n",
      "Epoch 79: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 189.4395 - val_accuracy: 0.2099\n",
      "Epoch 80/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0023 - accuracy: 0.9986    \n",
      "Epoch 80: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 138.6644 - val_accuracy: 0.2099\n",
      "Epoch 81/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 8.6964e-04 - accuracy: 1.0000\n",
      "Epoch 81: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 143.7936 - val_accuracy: 0.2099\n",
      "Epoch 82/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987  \n",
      "Epoch 82: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 157.0605 - val_accuracy: 0.2099\n",
      "Epoch 83/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0088 - accuracy: 0.9987  \n",
      "Epoch 83: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0134 - accuracy: 0.9981 - val_loss: 116.0033 - val_accuracy: 0.2099\n",
      "Epoch 84/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 84: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 93.0901 - val_accuracy: 0.2099\n",
      "Epoch 85/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0132 - accuracy: 0.9987\n",
      "Epoch 85: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9990 - val_loss: 70.4034 - val_accuracy: 0.2099\n",
      "Epoch 86/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000  \n",
      "Epoch 86: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 113.6000 - val_accuracy: 0.2099\n",
      "Epoch 87/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000  \n",
      "Epoch 87: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 115.9572 - val_accuracy: 0.2099\n",
      "Epoch 88/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 8.4722e-04 - accuracy: 1.0000\n",
      "Epoch 88: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 78.9544 - val_accuracy: 0.2099\n",
      "Epoch 89/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0052 - accuracy: 0.9975  \n",
      "Epoch 89: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.9981 - val_loss: 112.4472 - val_accuracy: 0.2099\n",
      "Epoch 90/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0322 - accuracy: 0.9909  \n",
      "Epoch 90: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0288 - accuracy: 0.9923 - val_loss: 129.3219 - val_accuracy: 0.2099\n",
      "Epoch 91/100\n",
      "25/33 [=====================>........] - ETA: 0s - loss: 0.0140 - accuracy: 0.9950  \n",
      "Epoch 91: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 108.4668 - val_accuracy: 0.2099\n",
      "Epoch 92/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0243 - accuracy: 0.9961  \n",
      "Epoch 92: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0187 - accuracy: 0.9971 - val_loss: 39.6704 - val_accuracy: 0.2099\n",
      "Epoch 93/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0532 - accuracy: 0.9909\n",
      "Epoch 93: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0447 - accuracy: 0.9923 - val_loss: 138.1112 - val_accuracy: 0.2099\n",
      "Epoch 94/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0225 - accuracy: 0.9932\n",
      "Epoch 94: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0174 - accuracy: 0.9952 - val_loss: 128.0818 - val_accuracy: 0.2099\n",
      "Epoch 95/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0108 - accuracy: 0.9974\n",
      "Epoch 95: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 88.0005 - val_accuracy: 0.2099\n",
      "Epoch 96/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 96: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 81.3526 - val_accuracy: 0.2099\n",
      "Epoch 97/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 97: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 58.6000 - val_accuracy: 0.2099\n",
      "Epoch 98/100\n",
      "23/33 [===================>..........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 98: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 61.2684 - val_accuracy: 0.2099\n",
      "Epoch 99/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0079 - accuracy: 0.9974\n",
      "Epoch 99: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 59.5210 - val_accuracy: 0.2099\n",
      "Epoch 100/100\n",
      "24/33 [====================>.........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n",
      "Epoch 100: val_accuracy did not improve from 0.86641\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 65.9915 - val_accuracy: 0.2099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9a2f8b5a50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 230ms/step - loss: 1.7076 - accuracy: 0.8520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7076060771942139, 0.8520498871803284]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_model = load_model('/tmp/CNN2d_checkpoint.h5')\n",
    "cp_model.evaluate(X_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = cp_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_single = CLASSES[np.argmax(y_pred, axis = -1)]\n",
    "actual_single = CLASSES[np.argmax(y_test, axis = -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ4AAAFCCAYAAACw1xcZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4qElEQVR4nO3de5hX5XUo/jXDfYARQRRNQGwlSlUuRQwXEa0iJi1Ko6KGHjBiwURKqyEhRkUSTOiJJnoaKw3Jr2BOQmLV2HqJ90gSRY1BAeMFMXIxxwgH4qXITZh9/sjPacf9fmHGmT3Xz+d5fB5Zs757v3vPvLOZxXfWKsuyLAsAAAAAaGDlTb0AAAAAAFonhScAAAAACqHwBAAAAEAhFJ4AAAAAKITCEwAAAACFUHgCAAAAoBAKTwAAAAAUQuEJAAAAgEIoPAEAAABQiPa1Tax6Y0AyPv6wIbnYA6+vlFtg7r7y63u++q6hOec+VHVbMt7WjSs/t1HPt2X6yFxsxbyFjboGWpfyPmubegnNTqlnNrQU9nVaqWf2xtuOy8UO/n6XZG7nu3+Vi+2ccEK9c7dNfysXe+/Rg5K5q2ffnIuNnTG9kOOefs7UZG5K2fJVyXjq/kak73HqnkWk71tdckd/9clk7uNzRyTjtVVqDalrrui8K5l70ISXa/X6iIg1Z8+tw+rahlL7etuk/Oe227+lvw5SuaWkjlHq9aXOl1J14pBcrOPv/pDMfeuEw+p1rrqst67X1tLue+oYFa/vTOamPh+pz0VERLtpm2q9hsfGfWO/Od7xBAAAAEAhFJ4AAAAAKITCEwAAAACFUHgCAAAAoBBlWZZltUmsS3NxaI40F0/ThJiWThPiPPuals6+TqtLc/F+5z7X5LkdnuiezD30W8tr9fqIiBdH/+9crNTPH3Vpsl6XpuWp9ZY6X98b0v+uv/WKHbU+X0qqcXpExLAVk2p9jObg2b/8WlMvodk58aEvNvUSWpxfHHdnMp763lCqgXddmmezb5qLAwAAANBkFJ4AAAAAKITCEwAAAACFUHgCAAAAoBC1bi5eqpkhtBSai6c19t7eMn1kLrZi3sJGXQPFaoihE3X5OtGEOE9zcVo6+zpt6L1XNvUSWpwiG3j3WpBuXJ5StnxVLlaXhupjZ0xP5na++1e52M4JJ9Q7N9V8vduiHrXOPfiqdsncB579ajLelmkuTkunuTgAAAAATUbhCQAAAIBCKDwBAAAAUAiFJwAAAAAKofAEAAAAQCHaN/UCgKb1wOsrG/mMjX0+GlvDfE01xDGgGHWd3FjU99m6rKPxv9dThD5/+3YyvueNTY28ktqZsua1ZHzTewfkYg9PHJzMzbp2zsWqVr1Yh1W8XOvM05+cmoz3KpFfl0l1B/fKT4/rd25+ylxExNgJ+Ql2qYl0EempdKO/+mQy9/EYkYynpCbYlVrD5in5a9587a5anwto/bzjCQAAAIBCKDwBAAAAUAiFJwAAAAAKofAEAAAAQCE0FweS6to8tz62TB+ZjK+Yt7DR1gCtSWPuX/avOXw+msMa6uKhqqZeQfO0bfjh6fj0fLPu9x49KJm7evbNuVipr49Uo+y+N9T+360Xzc43vo5IN6neOaF3HXLTx0011X58bu0bapdSqql26v5kL3ZL5u5IdSgvcR2lzlfb3P849sRk7rQF9+diDxxbmcxNXduL31mZzB224mO52EETSjR1t7ehTfKOJwAAAAAKofAEAAAAQCEUngAAAAAohMITAAAAAIVQeAIAAACgEKbaAUkPvL6yEc/WmOeipSo1dcn0K6Ct2DxlRzLed0GXRPTdZO7YGdNzsc6RnqJ28Pfzxy1bns5NTZpLTZmLiHg8aj9pLnXcUlPf7pwyOBermP5WMjc1dS01yS0iot/d+1jgBxw+94lkPHXsA899rta5/eqQ2yG9hLi856u52AMxJJ2ckPraiYiIxD3+/eWjan1coPXzjicAAAAACqHwBAAAAEAhFJ4AAAAAKITCEwAAAACF0Fwc2rhSDZvra8v0kcn4inkLCzkfzV99v9ZKfU0BtBUvjv7fyfj4c4fkYqUaZfe9YVculo3KN+VuCCuGlvg37gn50LYSTcC7LeqRi225+2PJ3A6Pds+vYXaJe1aHptql7k/fG/KxVDP0iIh+5+YbojdEbkXnt3Kxg76VbkQ+cOT/yJ8r0rkppZq6b56SaHBe66MCbYF3PAEAAABQCIUnAAAAAAqh8AQAAABAIRSeAAAAACiEwhMAAAAAhTDVDtq4B15fWdCRizouLVX9v9ZKvf7yeh4XoGVLTTxLTTuLiHhjxEG52OrZNydzU9NI6zItr9Qktk5b87mdFnRJ5pYtT01SSx+3893Lc7Gxa6cnc7fd/VYuVhH5dUVEbL0iGS5hR/p801OT+PJrqGtuSqmpf6nrKyo3TknfS6Bt8o4nAAAAAAqh8AQAAABAIRSeAAAAACiEwhMAAAAAhdBcHEhKNRQtypbpI5PxFfMWNtoaAKC5K/Vs3nxbvqF1RYljdDhlSy42bMWkdPLd+dDBi9JNwN8YUfsfK1Z/Z1Eudvo5U5O52ajBuViqOXlEuvn1QRNSzckjNk/JN0k/+Pvpa+t8d/oYqebpdcndNv2tZO5BE17OxUo1de937nOF5HZ4onsuVqoJ/dgZ+Qbupa4NaJu84wkAAACAQig8AQAAAFAIhScAAAAACqHwBAAAAEAhFJ4AAAAAKISpdkDSA6+vbMSzNea5AKBl+v3lo5LxF0fnp42VmoCXmmJWappbenpceqLcoYlpbqlJbqXWtmtCp2Tu6K8+mYs98Lujk7ndFvVIxmur1ES60lPi8vmlp8Tlf+xaPezfkrljJ+SnxFV0fiuZm5r61/eGZGqd9Hny3Vxs0PWfS+au/k7+6y816S4iIv6yXsuiDvb+f4ck493+Lb+n6mLbpBG1Pm6p3Nq+viF8Zs2GZHzD7oOS8WWTh+Vieyo7J3M3npH/3tllc1kyd+WX8vtk3KQLk7kdf/eH/BrWb0zmptTlmlPXG5G+5tT1RkTEuP2vyTueAAAAACiEwhMAAAAAhVB4AgAAAKAQCk8AAAAAFKIsy7KsNonjys8tei1QqIeqbmvqJTRLjb23t0wfmYutmLewUddA0yjV6La2Ul87ERHP/svl9Tpua+SZTUvnmZ1Wam+nmniXapSdyt02/a1kbqpZd11y69Ksu+8Ntf/38Hbv7k7GyzflG/JuG354rY9bar0NoS5N3Ytax5Q1r+Vim947IJn78MR80/Ksa7rBctWqF2u9Bns7b9A/pLvBt+Zm1KkG3KnrjUhfc+p6I1zz/qSuuSGarD/yiyv3e27veAIAAACgEApPAAAAABRC4QkAAACAQig8AQAAAFAIhScAAAAACmGqHW2GKRppVW8MaOolQL2U91nb1Etodjyzaek8s9PqsrdT0+si0hPTUhPXSqnLJLZSx00doy5T+OqSu2l4u2Ru5av5WJete5O5DTFl7ndXjMrFpk2+P5l7ec/84oatmJTM7bUg/flIKVu+Khdr7M+RvZ034OvfSsZb8xS01OS31PVGNO50v4i2d80NMd3vgZXz93se73gCAAAAoBAKTwAAAAAUQuEJAAAAgEIoPAEAAABQCM3FaTM0M0yrS3Px8YcNKW4hCVumj8zFVsxb2KhroPnTXDzPM5uWzjM7bcxZ1yXj26a/lYt1W9QjmfvmgPa52KHfWp7MTTWe7ntD7f/d+o0RXZPx1bPzjXNLNc9OXUdRjchT97HUGkrlv/douglx6ppPP2dqMjcl1Rg8Iv05qksD+Lo0oS+VW+q+pTz7l1+rdW5bcepJ6XvSmptRpxpwp643ovk2WY9oe9dcqsn6Fcf8dL/H844nAAAAAAqh8AQAAABAIRSeAAAAACiEwhMAAAAAhVB4AgAAAKAQptrRZpiQk1aXqXbQlEpNVbS38zyzaens67Sh917Z1EtgP+oyTbCUukz967UgPxVr6xU7krmpiXupc5U6X0NM7Hv4sauS8bZs/JCrk/HWPAUtNfktdb0RjTvdL6LtXXNDTPf79ID09ND/zjueAAAAACiEwhMAAAAAhVB4AgAAAKAQCk8AAAAAFEJzcdoMjUrTitrbW6aPTMZXzFtYyPlomUo1DK8LezvPM5uWzr5OO+3Ea5PxsuWrcrGNtx2XzD34+/mmtZ3vTjeG3TnhhHrlbpv+VjK3Lk2ux86YXshxU82vSzXlLuXgq9rlYuWbSjQsfmNTnY7dWKaseS0Z3/TeAbnYwxMHJ3OzrvkGyVWrXkzm2tt5C57/ZDLemptRpxpwp643onGbrEe0vWtuiCbrtdnX3vEEAAAAQCEUngAAAAAohMITAAAAAIVQeAIAAACgEApPAAAAABTCVDvaDFM00oZe8q1k3PQ5WoryPmubegnNjmc2LZ1ndlpD7O1sVHoyWUpznZY3+qtPJnMfnzsiGa+tUmsodc0VnXflYt0W9UjmpibxpabwRaQn8ZWaAptaW98bav/egl29OiXjqXuR+lzUNfeX//GFWq+trVi6Nn2vWvMUtNTkt9T1RjTudL+ItnfNDTHdz1Q7AAAAAJqMwhMAAAAAhVB4AgAAAKAQCk8AAAAAFEJzcdoMjUrTqt4YUO9jlGp4WYQt00cm45qht12ai+d5ZtPSeWanDb33ymQ81dD6zQHta33cVDPriIhhKyblYr0WpBsWp6Sak0ekG2KnmpNHFNfkOtXsm+I9+5dfa+olNDulntmtuRl1Sup6Ixq3yXpE27vmhmiyft+r30zG/zvveAIAAACgEApPAAAAABRC4QkAAACAQig8AQAAAFAIhScAAAAACmGqHW2GCTlpDTHVri5SE/De/umRydwDPvlKrY+bmnZn0l3bYKpdnmc2LZ1ndlqpqXb1lZqKF1H/yXipqXgR9Z+Ml5qKF5GejJeadBeRnnZXl9yI9GQ893LfufZ2Xl2e2a1lClp9J78VNd0vom7X3JiTvZuz2uxr73gCAAAAoBAKTwAAAAAUQuEJAAAAgEIoPAEAAABQCIUnAAAAAAphqh1thikaaY091a4uGnNSRGoqXoTJeC2BqXZ5ntm0dJ7ZaWPOui4Zr8t0tVTue4+mJ0Slpqudfs7Ukuv7oNQUtYj0JLXUFLWI9HS0UlPm6pJb33sWkb5vqXsWUbf7tqtXp1ys1JS41L3sd+5zydz6TvIrdR9S981Uu9rzzP6jqhOHJOOpyXj1nYoXUdxkvNRUvIj0ZLzUJMCIxr3mhph+uPbLl+93Td7xBAAAAEAhFJ4AAAAAKITCEwAAAACFUHgCAAAAoBCai9NmaGaYVlRz8YZoDJ5q+K3ZNx+kuXieZzYtnWd22lF3fDUZr+i8Kxc7+Kp2ydzyTYmmtW9sqt/CSshGDU7GU03HU02yI0o3yq6tKWteS8Zv+cxf5WJnLPplMvfhienryLrmm+9WrXqxDqurvbo0VC91L0s1cK/tcRuiqfsv/+MLtV5DWzHoH25IxltzM+pUA+7U9Uakrzl1vRGueX9S19wQTdYf+cWV+z23dzwBAAAAUAiFJwAAAAAKofAEAAAAQCEUngAAAAAohMITAAAAAIVo39QLAFqnB15f2QBHqf0xGmKKXm2lpu1FmLgHQLH++sj8NLiIiMfnjsjFtvcrcZB+3XOhznenp9qlpqOlJuhFRBw04eVc7LXLqtJLWF5ibbVUlwl4167+ZIk15O/ld18cnc59JT1ZL7WOfiWGiqZz63Lc/OS4Urkdnsh/jiMifv6d/AStUn9/Sh334O8nU2PL3R/Lxd571I+ZtbXj4PSQ+SH/+LlcbOW/1WEKWonzpaagLT7q8GRuagrayT9ckcxNTUHrd396DanJb6nrjUhfc8npfolYqalvrnl/XspF6vOuJe94AgAAAKAQCk8AAAAAFELhCQAAAIBCKDwBAAAAUAhd34BWoWGamddWY54LAP7o64esTsbH353/t+RSDbj73pDPzUYNTuYe/P1OuVjnu9MNsXdOOCEXK9UQO5Vb0fmtZO7vLx+Vi704Ot1geeyE6YUc9/RRU5Pxvjckw7WWug8R6fvWELlf3jSo1rmlGomnpBrLb7wt/7VDWv+rnkjGU02u/+fWAcnc9u/szMV2f7RnMnfjxR/JxbpsLkvmnt99ZS42btJZydyO7/whFytfnW9QHRHR/7F8LHW9EelrTl1vRPqaU9cb4Zrft/JL6e97DT24yTueAAAAACiEwhMAAAAAhVB4AgAAAKAQCk8AAAAAFELhCQAAAIBCmGoHNFsNPU1hX7ZMH5mMr5i3sNHWAAD7cvT3PpuMV16Yjx38/b3J3LLl6UlzKZ0Tsd9dkZ8GFxExbfL9udjl33k1mTv+sHxs85T0FL6KU7YkXj8kmbv5th25WN8FXZK5Ee/W+riv3VaVjB/8/fyxU/esZO7dtZ/6N/qrTyZzH48RJc6YyJ2bzy21htRUxIrOu0ocufZTCsmrOnFIMv6/x/fLxfas31jiKPlJatNKTEzbsPugXGzZ5GHJ3HHPXJiLbTwjvae6bP5oLrbyS3eljzspf9zU9UaUuub05LjUNaeuN6K4az7kn0p9jvLO7/5meg2JKXqpCXoR6Sl6qQl6EXWblFg+6OhcbE9lqe9w++cdTwAAAAAUQuEJAAAAgEIoPAEAAABQCIUnAAAAAAqhuThQb/VtAl6ysffrjdnYe2UjngsA6q7jW2XJ+K++fnMuVurZnGoa3feG2v9b9EG/2ZOMP3BsZS72HxOmJ3M7R76hdar5dkTE6K+uysUen5BuqH3w9/OxXb2Sqcmm2ql7ExGRvdgtGd+ROnaiMXip85WSyv2PY09M5k5bkGjq3rNUU/chuVipa05/TaQ/R1uveCsX67aoRzI3/jIdbsuKata9+Kjar6F9/+3JeFGNq9u/szMX2/3RnsncjRd/JBfrsjn9vfD87itzsfGHHZ7MLdWgPBLN3o/83v9JppZu9p7XXO9PqpF5RET56nxufd615B1PAAAAABRC4QkAAACAQig8AQAAAFAIhScAAAAACqHwBAAAAEAhyrIsy2qTOK783KLXAoV6qOq2pl5Cs1T1RnqaQmtW3yl8dVFyYt+8xpzY17qV91nb1Etodjyzaek8s9NK7e2diUlqpaaopXK3TX8rmZuaTFYq9+Cr2uVi5Zv+kMzd88amZLypTVnzWjK+6b0DkvGHJw7OxbKunZO5Vate/PAL24dsVH4NpZQtz08ILDXVLjVlsC5fU6Vy7e28T/zJ55Px+k5M27D7oGTussnD8ueqTH/dpibulZqYtvJLtZ+umVKVmCYXEdHxd/nvI/W9NxHuz/vqcn9S9yYi4oGV8/d7Hu94AgAAAKAQCk8AAAAAFELhCQAAAIBCKDwBAAAAUAjNxWkzNDNMa4vNxWldNBfP88ympfPMThtz1nXJ+OivPpmLPT53RL3Pl2oQXaoZdUXnXblYqjl5RMSbA9rnYod+a3kyN3W+vjek/+186xU7kvGU1tAMPSLdEL05N0O3t/NOPelrybjG1f//+RKNvVP3JiJ9f1L3JsL9eV9D3J/a7GvveAIAAACgEApPAAAAABRC4QkAAACAQig8AQAAAFAIhScAAAAACpEfKQHQAtVl8kJ9bZk+MhlfMW9ho60BgLan09b85LiIiF9fOjQX67w8P5EuIj0lrt+5z9U6t8MT3ZO5B30rf4xSE/BS59ty98eSuRWRv+Y3RuQnPkVErB52Sy5W6u8H2yeckIttvir9o1HfG/ok43Wxq1enXOzn31mUzE2tudS9/NbL+ftWappg51fyXxM7E/chIqLzqnysVO626W/Veg3U3pHf+z+5WKmJaeP/aUguVreJaTuTubs/2jMX23jxR5K5qYlp53dfmcwdN+msXKzjO+mpkuWrX8rF+j+WTE1ec11/RviL597NxVrz/fmfW9MTzssHHZ2LpSbo1ZZ3PAEAAABQCIUnAAAAAAqh8AQAAABAIRSeAAAAACiE5uJAo6pvE/CSjb1fb8zG3isb8VwA8Edbr9iRjB804eVcrFQz6lRz8AdeX5nMPf2cwYlovvFuRLrxdL9z0w3OU7kHTah97uivpjvnjp0xPR+ckExNqkuT9YiIis75xuclG3vfnb++gVP+RzK376jUewOqkrkpbw5I/4i3OvF5Hn9Y+hipa+57Q7q5fSSuOXW9pG08o0sy3v+qdCPxlE2zRuVizblxdft38s26U426IyLKSzRUT7nmtvNzsS6z8k29IyJWfunmZHzcpAtzsUZv7P3YylxsT/qwdWoCfs1t+Z+jUk3PIyJW3p+/P6l7U1ve8QQAAABAIRSeAAAAACiEwhMAAAAAhVB4AgAAAKAQCk8AAAAAFMJUO6BRlZqcU3u1f319J+jVVWri3op5jTltD4DWrNTEtJSDv5+elLVpeJaLnfDlzyZzu/Tam4uVmlaWnqGUtuXY/I8g0xa8k8x94Nj8+e6ckpq2F/HidxblYqefM7X267r7Y8n4wYvS97Lz3fkpeKkpfKWU+hwd/89P5mK75o4ocZTUMdLzr1J/L6rLxL6y5fnpiRERmxPHODhqfx/auiO/93+S8VJTzFK+dOmPcrFmMVGuASamte/fLxfbU2Jd/a96IhdLTZOLaOb35/U63J/f5SfupabtRaQn7tXl/qTuTW15xxMAAAAAhVB4AgAAAKAQCk8AAAAAFELhCQAAAIBClGVZlu8wmDCu/Nyi1wKFeqjqtqZeQrNU9Ua6sR60FOV91jb1Epodz2xaOs/stFJ7O9Uguu8N6X9ffu2yqlws1Ug6IuLgq9rlYuWb8o1sIyL2vLGpVusqtbZdvTolc0s1M29Mpa4j1Ry8Luudsua1ZHzTewfkYg9PTDdU3/vKulys1Hr7nZtvhr7hq/nBKBERla/mYwcuyTdurit7O+/Uk76WjJc/trLWx1h/bf7zWLJx9Zdq37i6Y6JxdanG3imlGlcvPurwWh/jL557NxdbNnlYMndPZX7MwcYz0k383Z8/qsv9Sd2biNr9Xdw7ngAAAAAohMITAAAAAIVQeAIAAACgEApPAAAAABRC4QkAAACAQrRv6gUAFGX8YUMa9XxbpucniqyYt7BR1wBA6/W7K0Yl43878P5c7PLbE2PJImLYikm5WK8F6alGe7vmY1WJ6XUR6Ulq/a/dk8ytWvViLpaftVR3OyecUK/Xl5pIl5peVyq/1Bq2TX8rF/v+Uel1pO5lv1fyE+lK5iam15XK7fhEerLXr76en141fsmQWh+31D2j9tr375eLlZqY1v+q2k8cHP9PQ3KxaWv+I5m7YfdBuVhdJqZdc1t6amKXWbWfmJaaKNfxnfR0zfLVL+Vi/R9LppacKPc/t+Ynfrd/Z2cyd/dHe+bXUIepdtfcdn4y3lzvT6mfrR7KD0vNn3v/KQAAAABQdwpPAAAAABRC4QkAAACAQig8AQAAAFCIsizLstokjis/t+i1QKEeqrqtqZfQLFW9kW+g1xAaorG3Zt3URnmftU29hGbHM5uWzjM7bei9Vybj7z2abwC8ena6EW3q+ZxqDh0R0feG+v0b9a5enZLxujTlrm8D726LetQ69+Cr2iVzyzelG/W+9yd9kvGU1L0o1cy8OZiy5rVc7PtH9U3mpr5+/nbg48nc2X/2QP0W1gqVemb/xXPv5mJ1aey98Yx0g/cum+vZuPp36f1QqvF5SqpxdaqReUTEz45LTDkooXzQ0fl1Je5NhPtTva463J/UvYmIWH3jZfs/934zAAAAAOBDUHgCAAAAoBAKTwAAAAAUQuEJAAAAgEIoPAEAAABQiFpPtQMAAACAuvCOJwAAAAAKofAEAAAAQCEUngAAAAAohMITAAAAAIVQeAIAAACgEApPAAAAABRC4QkAAACAQig8AQAAAFAIhScAAAAACqHwBAAAAEAhFJ4AAAAAKITCEwAAAACFUHgCAAAAoBAKTwAAAAAUQuEJAAAAgEIoPAEAAABQCIUnAAAAAAqh8AQAAABAIRSeAAAAACiEwhMAAAAAhVB4AgAAAKAQCk8AAAAAFELhCQAAAIBCKDwBAAAAUAiFJwAAAAAKofAEAAAAQCEUngAAAAAohMITAAAAAIVQeAIAAACgEApPAAAAABRC4QkAAACAQig8AQAAAFAIhScAAAAACqHwBAAAAEAhFJ4AAAAAKITCEwAAAACFUHgCAAAAoBAKTwAAAAAUQuEJAAAAgEIoPAEAAABQCIUnAAAAAAqh8AQAAABAIRSeAAAAACiEwhMAAAAAhVB4AgAAAKAQCk8AAAAAFELhCQAAAIBCKDwBAAAAUAiFJwAAAAAKofAEAAAAQCEUnj6E/v37x4033ljY8S+88MKYOHFiYcd/37x582LIkCGFnwdaCnsbWh/7GtqWovc8UCzP7dZJ4akNmz17djzyyCNNvQyggdnb0PrY1wDQcnhu19RmC0+7d+9u6iU0uW7dukWvXr2aehnQoOxte5vWx762r2lb7Pk/eu+995p6CfCh2MOe2x/UKgpPJ598csycOTNmzpwZBxxwQBx00EFx9dVXR5Zl1Tn9+/eP+fPnx5QpU6KysjKmT58eERGPPfZYjBkzJrp06RJ9+/aNWbNmxbvvvlv9us2bN8eECROiS5cuccQRR8QPf/jDRruur3zlK9G7d++orKyMSy65pMYGrqqqigULFsQRRxwRXbp0icGDB8ftt99e/fFly5ZFWVlZPPLII3H88cdHRUVFjBo1KtasWVOd88G3/+3ZsydmzZoVPXr0iF69esWcOXNi6tSpNd6KePLJJ8esWbPii1/8YvTs2TP69OkT8+bNK/I20IbZ2/Y2rY99bV/TtrS2Pb9s2bI44YQTomvXrtGjR48YPXp0bNiwIdavXx/l5eXx61//ukb+jTfeGIcffnhUVVXFm2++GZMnT47evXtHly5dYsCAAbF48eKIiFi/fn2UlZXFrbfeGmPHjo3OnTvHwoULo0uXLnHffffVOOadd94Z3bt3j+3btxd+vdDa9vD7PLcbWdYKjB07NuvWrVv293//99lLL72U/eAHP8gqKiqyRYsWVeccfvjhWWVlZXb99ddnr7zySvV/Xbt2zW644Ybs5Zdfzh5//PFs6NCh2YUXXlj9uk984hPZ4MGDsyeeeCL79a9/nY0aNSrr0qVLdsMNN5Rczw9+8IOsa9eu+/zvF7/4RcnXT506NevWrVt23nnnZb/5zW+ye+65J+vdu3f25S9/uTrn2muvzY4++ujs/vvvz377299mixcvzjp16pQtW7Ysy7Ise/TRR7OIyD7+8Y9ny5Yty55//vlszJgx2ahRo6qPcc0112SDBw+uccyePXtmP/nJT7IXX3wxu+SSS7LKysrsrLPOqnGvKysrs3nz5mUvv/xydsstt2RlZWXZgw8+WJtPFdSJvW1v0/rY1/Y1bUtr2vPvvfdedsABB2SzZ8/OXnnlleyFF17IlixZkm3YsCHLsiwbN25c9rnPfa7GawYNGpTNnTs3y7Isu/TSS7MhQ4ZkTz/9dLZu3brsoYceyu66664sy7Js3bp1WURk/fv3z+64447s1VdfzV5//fXsnHPOyf7mb/6mxjHPPvvsXAyK0pr2cJZ5bjeVVlN4GjhwYFZVVVUdmzNnTjZw4MDqPx9++OHZxIkTa7xu2rRp2fTp02vEfvnLX2bl5eXZjh07sjVr1mQRkf3qV7+q/viLL76YRcQ+N8M777yTrV27dp//bd++veTrp06dmvXs2TN79913q2MLFy7MunXrlu3duzfbuXNnVlFRkS1fvjx3PRdccEGWZf+1GR5++OHqj997771ZRGQ7duzIsiy/GQ455JDsuuuuq/7znj17sn79+uU2w4knnljjvMOHD8/mzJlT8nrgw7K3/+t67G1aC/v6v67HvqYtaE17fuvWrVlEVP/w+UG33nprduCBB2Y7d+7MsizLVqxYkZWVlWXr1q3LsizLJkyYkH3mM59Jvvb9wtONN95YI37nnXdm3bp1q/4e8/bbb2edO3fO7rvvvpLXCA2pNe3hLPPcbirtG+2tVQUbMWJElJWVVf955MiR8c1vfjP27t0b7dq1i4iI448/vsZrVq1aFatXr67xlr4sy6KqqirWrVsXL7/8crRv3z6GDRtW/fGjjz46evTosc+1dO/ePbp3716v6xk8eHBUVFTUuJ5t27bFa6+9Ftu2bYvt27fHuHHjarxm9+7dMXTo0BqxQYMGVf//oYceGhF/fEtjv379auS9/fbbsWnTpjjhhBOqY+3atYthw4ZFVVVVyWO+f9zNmzd/iKuE/bO37W1aH/vavqZtaS17vmfPnnHhhRfG+PHjY9y4cXHaaafFpEmTqvfrxIkT49JLL40777wzzj///FiyZEmccsop0b9//4iI+OxnPxtnn312PPPMM3H66afHxIkTY9SoUTXO8cH78MlPfjI6dOgQd911V5x//vlxxx13RGVlZZx22mkf6hrgw2gte/h9ntuNr9UUnmqja9euNf68bdu2mDFjRsyaNSuX269fv3j55Zc/1Hl++MMfxowZM/aZc99998WYMWM+1PG3bdsWERH33ntvfOQjH6nxsU6dOtX4c4cOHar///1vFh/84q6r/37M949b32NCfdjb9jatj31tX9O2tJQ9v3jx4pg1a1bcf//9ceutt8ZVV10VDz30UIwYMSI6duwYU6ZMicWLF8enPvWpWLp0afyv//W/ql/7iU98IjZs2BA//elP46GHHopTTz01Lr300rj++uurcz54Hzp27BjnnHNOLF26NM4///xYunRpnHfeedG+fZv6MY4WoKXs4f3x3C5Gq/mO9dRTT9X485NPPhkDBgyorsCm/Pmf/3m88MILceSRRyY/fvTRR8eePXtixYoVMXz48IiIWLNmTbz11lv7XMuZZ54ZH//4x/eZ88Ev4g9atWpV7NixI7p06RIRf7yebt26Rd++faNnz57RqVOn2LhxY4wdO3afx6mtAw44IA455JB4+umn46STToqIiL1798YzzzxToykaNDZ7u37sbZoj+7p+7Gtamta254cOHRpDhw6NK664IkaOHBlLly6NESNGRETExRdfHMcee2zcfPPNsWfPnvjUpz5V47W9e/eOqVOnxtSpU2PMmDHxhS98oUbhKWXy5Mkxbty4eP755+NnP/tZXHvttfvMh4bW2vaw53bjazWFp40bN8bll18eM2bMiGeeeSa+/e1vxze/+c19vmbOnDkxYsSImDlzZlx88cXRtWvXeOGFF+Khhx6Km266KY466qg444wzYsaMGbFw4cJo3759/MM//EP1F2gpDfH2v927d8e0adPiqquuivXr18c111wTM2fOjPLy8ujevXvMnj07LrvssqiqqooTTzwx3n777Xj88cejsrIypk6d+qHO+Xd/93exYMGCOPLII+Poo4+Ob3/72/Hmm2/WeFslNDZ7296m9bGv7Wvaltay59etWxeLFi2KM888Mw477LBYs2ZNrF27NqZMmVKdM3DgwBgxYkTMmTMnLrroohrrmTt3bgwbNiyOOeaY2LVrV9xzzz0xcODA/Z73pJNOij59+sTkyZPjiCOO2O8P3dDQWssefp/nduNrNYWnKVOmxI4dO+KEE06Idu3axd///d9Xj3EsZdCgQfHzn/88rrzyyhgzZkxkWRZ/+qd/Guedd151zuLFi+Piiy+OsWPHxiGHHBLXXnttXH311UVfTpx66qkxYMCAOOmkk2LXrl1xwQUX1BilOH/+/Ojdu3csWLAgXn311ejRo0f8+Z//eXz5y1/+0OecM2dOvPHGGzFlypRo165dTJ8+PcaPH7/PSjYUzd62t2l97Gv7mraltez5ioqKeOmll+KWW26JrVu3xqGHHhqXXnpp7td+pk2bFsuXL4+LLrqoRrxjx45xxRVXxPr166NLly4xZsyY+PGPf7zf85aVlcUFF1wQ3/jGN2Lu3LkNek1QG61lD7/Pc7vxlWVZljX1Iurr5JNPjiFDhsSNN97Y1EtpVaqqqmLgwIExadKkmD9/flMvhzbI3i6GvU1Tsq+LYV/TXLXFPT9//vy47bbbYvXq1U29FKi3triHG0Nbe263mnc8UX8bNmyIBx98MMaOHRu7du2Km266KdatWxef/vSnm3ppQD3Y29D62NfQ/Gzbti3Wr18fN910kz5MQA1t/bld3tQLoPkoLy+PJUuWxPDhw2P06NHx3HPPxcMPP1yr3z0Hmi97G1of+xqan5kzZ8awYcPi5JNPzv2aHdC2tfXndqv4VTsAAAAAmh/veAIAAACgEApPAAAAABRC4QkAAACAQig8AQAAAFAIhScAAAAACqHwBAAAAEAhFJ4AAAAAKITCEwAAAACFUHgCAAAAoBAKTwAAAAAUQuEJAAAAgEIoPAEAAABQCIUnAAAAAAqh8AQAAABAIRSeAAAAACiEwhMAAAAAhVB4AgAAAKAQCk8AAAAAFELhCQAAAIBCKDwBAAAAUAiFJwAAAAAKofAEAAAAQCEUngAAAAAohMITAAAAAIVQeAIAAACgEApPAAAAABRC4QkAAACAQig8AQAAAFAIhScAAAAACqHwBAAAAEAhFJ4AAAAAKITCEwAAAACFUHgCAAAAoBAKTwAAAAAUQuEJAAAAgEIoPAEAAABQCIUnAAAAAAqh8AQAAABAIRSeAAAAACiEwhMAAAAAhVB4AgAAAKAQCk8AAAAAFELhCQAAAIBCKDwBAAAAUAiFJwAAAAAKofAEAAAAQCEUnprYhRdeGBMnTiz8PPPmzYshQ4YUfh6gaa1fvz7Kyspi5cqVTb0UaHU8swEA6k7hqYTW9pe+2bNnxyOPPNLUy4BmpbXt84iIvn37xu9///s49thjm3op0Gha2172zIZ9a217HrCvW7v2Tb0AGke3bt2iW7duTb0MoEC7d++Ojh07Rp8+fZp6KUA9eGZD2/Pee+9Fhw4dmnoZQAOyr/9Lq33H0/333x8nnnhi9OjRI3r16hV/9Vd/Fb/97W9r5Pzud7+LCy64IHr27Bldu3aN448/Pp566qlYsmRJfOUrX4lVq1ZFWVlZlJWVxZIlSwpd71e+8pXo3bt3VFZWxiWXXBK7d++u/lhVVVUsWLAgjjjiiOjSpUsMHjw4br/99uqPL1u2LMrKyuKRRx6J448/PioqKmLUqFGxZs2a6pwPVpD37NkTs2bNqr4/c+bMialTp9b4FYKTTz45Zs2aFV/84hejZ8+e0adPn5g3b16RtwHqpCXs8507d8YxxxwT06dPr4799re/je7du8e//uu/RkTEkiVLokePHnHPPffEUUcdFRUVFXHOOefE9u3b45Zbbon+/fvHgQceGLNmzYq9e/dWH6d///4xf/78mDJlSlRWVsb06dOTv2p31113xYABA6Jz585xyimnxC233BJlZWXx1ltvNfj1wofREvbyf+eZDfXTUvb8smXL4oQTToiuXbtGjx49YvTo0bFhw4ZYv359lJeXx69//esa+TfeeGMcfvjhUVVVFW+++WZMnjw5evfuHV26dIkBAwbE4sWLI+K/fi3+1ltvjbFjx0bnzp1j4cKF0aVLl7jvvvtqHPPOO++M7t27x/bt2wu5Rmgo9rV9vU9ZK3X77bdnd9xxR7Z27drs2WefzSZMmJAdd9xx2d69e7Msy7L//M//zP7kT/4kGzNmTPbLX/4yW7t2bXbrrbdmy5cvz7Zv3559/vOfz4455pjs97//ffb73/8+2759e/I8P/jBD7KuXbvu879f/OIXJdc5derUrFu3btl5552X/eY3v8nuueeerHfv3tmXv/zl6pxrr702O/roo7P7778/++1vf5stXrw469SpU7Zs2bIsy7Ls0UcfzSIi+/jHP54tW7Yse/7557MxY8Zko0aNqj7GNddckw0ePLjGMXv27Jn95Cc/yV588cXskksuySorK7OzzjqrOmfs2LFZZWVlNm/evOzll1/ObrnllqysrCx78MEHP8ynBBpcS9nnzz77bNaxY8fs3//937M9e/ZkI0aMyP76r/+6+uOLFy/OOnTokI0bNy575plnsp///OdZr169stNPPz2bNGlS9vzzz2d333131rFjx+zHP/5x9esOP/zwrLKyMrv++uuzV155JXvllVeydevWZRGRPfvss1mWZdmrr76adejQIZs9e3b20ksvZT/60Y+yj3zkI1lEZG+++Wb9PwnQAFrKXvbMhobREvb8e++9lx1wwAHZ7Nmzs1deeSV74YUXsiVLlmQbNmzIsizLxo0bl33uc5+r8ZpBgwZlc+fOzbIsyy699NJsyJAh2dNPP52tW7cue+ihh7K77rory7Ks+lndv3//7I477sheffXV7PXXX8/OOeec7G/+5m9qHPPss8/OxaA5sq/t631ptYWnD/q///f/ZhGRPffcc1mWZdl3vvOdrHv37tnWrVuT+R/8S18p77zzTrZ27dp9/ldq02TZH/8S27Nnz+zdd9+tji1cuDDr1q1btnfv3mznzp1ZRUVFtnz58hqvmzZtWnbBBRdkWfZff4l9+OGHqz9+7733ZhGR7dixI3k9hxxySHbddddV/3nPnj1Zv379cn+JPfHEE2ucd/jw4dmcOXP2e1+gKTTXfZ5lWfaNb3wjO+igg7KZM2dmhx56aLZly5bqjy1evDiLiOyVV16pjs2YMSOrqKjI/vM//7M6Nn78+GzGjBnVfz788MOziRMn1jjPBwtPc+bMyY499tgaOVdeeaXCE81ac93LntlQjOa457du3ZpFRHXR+INuvfXW7MADD8x27tyZZVmWrVixIisrK8vWrVuXZVmWTZgwIfvMZz6TfO37z+obb7yxRvzOO+/MunXrVv095u233846d+6c3Xffffu9Vmhu7Os/sq//qNX2eFq7dm3MnTs3nnrqqdiyZUtUVVVFRMTGjRvj2GOPjZUrV8bQoUOjZ8+e9TpP9+7do3v37vU6xuDBg6OioqL6zyNHjoxt27bFa6+9Ftu2bYvt27fHuHHjarxm9+7dMXTo0BqxQYMGVf//oYceGhERmzdvjn79+tXIe/vtt2PTpk1xwgknVMfatWsXw4YNq75PqWO+f9zNmzd/iKuEhteS9vnnP//5+Pd///e46aab4r777otevXrV+HhFRUX86Z/+afWfDznkkOjfv3+NPi+HHHJIbv8df/zx+zzvmjVrYvjw4TVi/33vQ3PQkvayZzbUX0vY8z179owLL7wwxo8fH+PGjYvTTjstJk2aVL1fJ06cGJdeemnceeedcf7558eSJUvilFNOif79+0dExGc/+9k4++yz45lnnonTTz89Jk6cGKNGjapxjg8+wz/5yU9Ghw4d4q677orzzz8/7rjjjqisrIzTTjvtQ10DNCb7+o/s67RW2+NpwoQJ8Yc//CG++93vxlNPPRVPPfVURER1H4YuXbo0yHl++MMfVjcBLfXfL3/5yw99/G3btkVExL333hsrV66s/u+FF16o0TMiImo0LisrK4uIyP2ltK4+2AytrKys3seEhtKS9vnmzZvj5Zdfjnbt2sXatWtzH0/ttdrsv65du37Iq4LmoyXt5X3xzIbaaSl7fvHixfHEE0/EqFGj4tZbb42Pfexj8eSTT0ZERMeOHWPKlCmxePHi2L17dyxdujQuuuii6td+4hOfiA0bNsRll10Wr7/+epx66qkxe/bsGsf/4DO8Y8eOcc4558TSpUsjImLp0qVx3nnnRfv2rfa9ArQi9vUf2ddprfJqt27dGmvWrInvfve7MWbMmIiIeOyxx2rkDBo0KL73ve/FH/7wh2TVtWPHjjWa+JZy5plnxsc//vF95nzkIx/Z58dXrVoVO3bsqN6MTz75ZHTr1i369u0bPXv2jE6dOsXGjRtj7Nix+11PbRxwwAFxyCGHxNNPPx0nnXRSRETs3bs3nnnmGSMsaTFa2j6/6KKL4rjjjotp06bF3/7t38Zpp50WAwcO3O+56+uoo46Kn/70pzViTz/9dOHnhdpqaXvZMxvqp6Xt+aFDh8bQoUPjiiuuiJEjR8bSpUtjxIgRERFx8cUXx7HHHhs333xz7NmzJz71qU/VeG3v3r1j6tSpMXXq1BgzZkx84QtfiOuvv36f55s8eXKMGzcunn/++fjZz34W11577X6vE5qafW1f70+rLDwdeOCB0atXr1i0aFEceuihsXHjxvjSl75UI+eCCy6Ir3/96zFx4sRYsGBBHHroofHss8/GYYcdFiNHjoz+/fvHunXrYuXKlfHRj340unfvHp06dcqdqyHetr979+6YNm1aXHXVVbF+/fq45pprYubMmVFeXh7du3eP2bNnx2WXXRZVVVVx4oknxttvvx2PP/54VFZWxtSpUz/UOf/u7/4uFixYEEceeWQcffTR8e1vfzvefPPN6n91heauJe3zf/7nf44nnngiVq9eHX379o177703Jk+eHE8++WR07NjxQx+3NmbMmBHf+ta3Ys6cOTFt2rRYuXJl9ZQQ+53moCXt5QjPbKivlrLn161bF4sWLYozzzwzDjvssFizZk2sXbs2pkyZUp0zcODAGDFiRMyZMycuuuiiGu/omDt3bgwbNiyOOeaY2LVrV9xzzz21+genk046Kfr06ROTJ0+OI444Yr8/YENzYF/vm33dSn/Vrry8PH784x/HihUr4thjj43LLrssrrvuuho5HTt2jAcffDAOPvjg+OQnPxnHHXdc/OM//mO0a9cuIiLOPvvsOOOMM+KUU06J3r17x49+9KPC1nvqqafGgAED4qSTTorzzjsvzjzzzBojkOfPnx9XX311LFiwIAYOHBhnnHFG3HvvvXHEEUd86HPOmTMnLrjggpgyZUqMHDkyunXrFuPHj4/OnTs3wBVB8VrKPn/ppZfiC1/4Qtx8883Rt2/fiIi4+eabY8uWLXH11Vc3+Pk+6Igjjojbb789fvKTn8SgQYNi4cKFceWVV0ZEJB/m0Nhayl5+n2c21E9L2fMVFRXx0ksvxdlnnx0f+9jHYvr06XHppZfGjBkzauRNmzYtdu/eXePXcd6/hiuuuCIGDRoUJ510UrRr1y5+/OMf7/e8ZWVlccEFF8SqVati8uTJDXpNUBT7et/s64iyLMuypl4ETa+qqioGDhwYkyZNivnz5zf1coACfe1rX4t/+Zd/iddee62plwJ8CJ7Z0HzMnz8/brvttli9enVTLwVoIPZ1w2uVv2rH/m3YsCEefPDBGDt2bOzatStuuummWLduXXz6059u6qUBDezmm2+O4cOHR69eveLxxx+P6667LmbOnNnUywJqyTMbmp9t27bF+vXr46abbmqT/VqgNbKvi9Mqf9WO/SsvL48lS5bE8OHDY/To0fHcc8/Fww8/3CjNjoHGtXbt2jjrrLPiz/7sz2L+/Pnx+c9/vsavBgHNm2c2ND8zZ86MYcOGxcknn5z7dRygZbKvi+NX7QAAAAAohHc8AQAAAFAIhScAAAAACqHwBAAAAEAhFJ4AAAAAKITCEwAAAACFUHgCAAAAoBAKTwAAAAAUQuEJAAAAgEIoPAEAAABQiP8Hov8Sdo+77QkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_to_show = 5\n",
    "indices = np.random.choice(range(len(X_test)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    img = X_test[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, 'pred = ' + str(preds_single[idx]), fontsize=10, ha='center', transform=ax.transAxes) \n",
    "    ax.text(0.5, -0.7, 'act = ' + str(actual_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       377\n",
      "           1       0.99      0.72      0.84       141\n",
      "           2       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.85       561\n",
      "   macro avg       0.60      0.57      0.58       561\n",
      "weighted avg       0.80      0.85      0.82       561\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "y_test_classes = tf.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        Benign  Sysrv  Xmrig\n",
      "Benign     376      1      0\n",
      "Sysrv       39    102      0\n",
      "Xmrig       43      0      0\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "class_labels = ['Benign', 'Sysrv', 'Xmrig']\n",
    "\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (NGC 24.01 / TensorFlow 2.14) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
