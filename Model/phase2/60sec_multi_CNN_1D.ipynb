{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 22:36:53.331907: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-31 22:36:53.383009: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9360] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-31 22:36:53.383051: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-31 22:36:53.383082: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1537] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-31 22:36:53.392073: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Input, Conv1D, BatchNormalization, LeakyReLU, MaxPooling1D, GlobalAveragePooling1D, Dense, Dropout, Activation, Add, Flatten\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Calls List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "syscalls = [\n",
    "\"sys_enter_llistxattr\",\n",
    "\"sys_enter_setgroups\",\n",
    "\"sys_enter_lremovexattr\",\n",
    "\"sys_enter_sethostname\",\n",
    "\"sys_enter_accept\",\n",
    "\"sys_enter_lseek\",\n",
    "\"sys_enter_setitimer\",\n",
    "\"sys_enter_accept4\",\n",
    "\"sys_enter_lsetxattr\",\n",
    "\"sys_enter_setns\",\n",
    "\"sys_enter_acct\",\n",
    "\"sys_enter_madvise\",\n",
    "\"sys_enter_setpgid\",\n",
    "\"sys_enter_add_key\",\n",
    "\"sys_enter_mbind\",\n",
    "\"sys_enter_setpriority\",\n",
    "\"sys_enter_adjtimex\",\n",
    "\"sys_enter_membarrier\",\n",
    "\"sys_enter_setregid\",\n",
    "\"sys_enter_personality\",\n",
    "\"sys_enter_memfd_create\",\n",
    "\"sys_enter_setresgid\",\n",
    "\"sys_enter_bind\",\n",
    "\"sys_enter_memfd_secret\",\n",
    "\"sys_enter_setresuid\",\n",
    "\"sys_enter_bpf\",\n",
    "\"sys_enter_migrate_pages\",\n",
    "\"sys_enter_setreuid\",\n",
    "\"sys_enter_brk\",\n",
    "\"sys_enter_mincore\",\n",
    "\"sys_enter_setrlimit\",\n",
    "\"sys_enter_capget\",\n",
    "\"sys_enter_mkdirat\",\n",
    "\"sys_enter_setsid\",\n",
    "\"sys_enter_capset\",\n",
    "\"sys_enter_mknodat\",\n",
    "\"sys_enter_setsockopt\",\n",
    "\"sys_enter_chdir\",\n",
    "\"sys_enter_mlock\",\n",
    "\"sys_enter_settimeofday\",\n",
    "\"sys_enter_chroot\",\n",
    "\"sys_enter_mlock2\",\n",
    "\"sys_enter_setuid\",\n",
    "\"sys_enter_clock_adjtime\",\n",
    "\"sys_enter_mlockall\",\n",
    "\"sys_enter_setxattr\",\n",
    "\"sys_enter_clock_getres\",\n",
    "\"sys_enter_mmap\",\n",
    "\"sys_enter_shmat\",\n",
    "\"sys_enter_clock_gettime\",\n",
    "\"sys_enter_mount\",\n",
    "\"sys_enter_shmctl\",\n",
    "\"sys_enter_clock_nanosleep\",\n",
    "\"sys_enter_mount_setattr\",\n",
    "\"sys_enter_shmdt\",\n",
    "\"sys_enter_clock_settime\",\n",
    "\"sys_enter_move_mount\",\n",
    "\"sys_enter_shmget\",\n",
    "\"sys_enter_clone\",\n",
    "\"sys_enter_move_pages\",\n",
    "\"sys_enter_shutdown\",\n",
    "\"sys_enter_clone3\",\n",
    "\"sys_enter_mprotect\",\n",
    "\"sys_enter_sigaltstack\",\n",
    "\"sys_enter_close\",\n",
    "\"sys_enter_mq_getsetattr\",\n",
    "\"sys_enter_signalfd4\",\n",
    "\"sys_enter_close_range\",\n",
    "\"sys_enter_mq_notify\",\n",
    "\"sys_enter_socket\",\n",
    "\"sys_enter_connect\",\n",
    "\"sys_enter_mq_open\",\n",
    "\"sys_enter_socketpair\",\n",
    "\"sys_enter_copy_file_range\",\n",
    "\"sys_enter_mq_timedreceive\",\n",
    "\"sys_enter_splice\",\n",
    "\"sys_enter_delete_module\",\n",
    "\"sys_enter_mq_timedsend\",\n",
    "\"sys_enter_statfs\",\n",
    "\"sys_enter_dup\",\n",
    "\"sys_enter_mq_unlink\",\n",
    "\"sys_enter_statx\",\n",
    "\"sys_enter_dup3\",\n",
    "\"sys_enter_mremap\",\n",
    "\"sys_enter_swapoff\",\n",
    "\"sys_enter_epoll_create1\",\n",
    "\"sys_enter_msgctl\",\n",
    "\"sys_enter_swapon\",\n",
    "\"sys_enter_epoll_ctl\",\n",
    "\"sys_enter_msgget\",\n",
    "\"sys_enter_symlinkat\",\n",
    "\"sys_enter_epoll_pwait\",\n",
    "\"sys_enter_msgrcv\",\n",
    "\"sys_enter_sync\",\n",
    "\"sys_enter_epoll_pwait2\",\n",
    "\"sys_enter_msgsnd\",\n",
    "\"sys_enter_sync_file_range\",\n",
    "\"sys_enter_eventfd2\",\n",
    "\"sys_enter_msync\",\n",
    "\"sys_enter_syncfs\",\n",
    "\"sys_enter_execve\",\n",
    "\"sys_enter_munlock\",\n",
    "\"sys_enter_sysinfo\",\n",
    "\"sys_enter_execveat\",\n",
    "\"sys_enter_munlockall\",\n",
    "\"sys_enter_syslog\",\n",
    "\"sys_enter_exit\",\n",
    "\"sys_enter_munmap\",\n",
    "\"sys_enter_tee\",\n",
    "\"sys_enter_exit_group\",\n",
    "\"sys_enter_name_to_handle_at\",\n",
    "\"sys_enter_tgkill\",\n",
    "\"sys_enter_faccessat\",\n",
    "\"sys_enter_nanosleep\",\n",
    "\"sys_enter_timer_create\",\n",
    "\"sys_enter_faccessat2\",\n",
    "\"sys_enter_newfstat\",\n",
    "\"sys_enter_timer_delete\",\n",
    "\"sys_enter_fadvise64\",\n",
    "\"sys_enter_newfstatat\",\n",
    "\"sys_enter_timer_getoverrun\",\n",
    "\"sys_enter_fallocate\",\n",
    "\"sys_enter_newuname\",\n",
    "\"sys_enter_timer_gettime\",\n",
    "\"sys_enter_fanotify_init\",\n",
    "\"sys_enter_open_by_handle_at\",\n",
    "\"sys_enter_timer_settime\",\n",
    "\"sys_enter_fanotify_mark\",\n",
    "\"sys_enter_open_tree\",\n",
    "\"sys_enter_timerfd_create\",\n",
    "\"sys_enter_fchdir\",\n",
    "\"sys_enter_openat\",\n",
    "\"sys_enter_timerfd_gettime\",\n",
    "\"sys_enter_fchmod\",\n",
    "\"sys_enter_openat2\",\n",
    "\"sys_enter_timerfd_settime\",\n",
    "\"sys_enter_fchmodat\",\n",
    "\"sys_enter_perf_event_open\",\n",
    "\"sys_enter_times\",\n",
    "\"sys_enter_fchown\",\n",
    "\"sys_enter_pidfd_getfd\",\n",
    "\"sys_enter_tkill\",\n",
    "\"sys_enter_fchownat\",\n",
    "\"sys_enter_pidfd_open\",\n",
    "\"sys_enter_truncate\",\n",
    "\"sys_enter_fcntl\",\n",
    "\"sys_enter_pidfd_send_signal\",\n",
    "\"sys_enter_umask\",\n",
    "\"sys_enter_fdatasync\",\n",
    "\"sys_enter_pipe2\",\n",
    "\"sys_enter_umount\",\n",
    "\"sys_enter_fgetxattr\",\n",
    "\"sys_enter_pivot_root\",\n",
    "\"sys_enter_unlinkat\",\n",
    "\"sys_enter_finit_module\",\n",
    "\"sys_enter_ppoll\",\n",
    "\"sys_enter_unshare\",\n",
    "\"sys_enter_flistxattr\",\n",
    "\"sys_enter_prctl\",\n",
    "\"sys_enter_userfaultfd\",\n",
    "\"sys_enter_flock\",\n",
    "\"sys_enter_pread64\",\n",
    "\"sys_enter_utimensat\",\n",
    "\"sys_enter_fremovexattr\",\n",
    "\"sys_enter_preadv\",\n",
    "\"sys_enter_vhangup\",\n",
    "\"sys_enter_fsconfig\",\n",
    "\"sys_enter_preadv2\",\n",
    "\"sys_enter_vmsplice\",\n",
    "\"sys_enter_fsetxattr\",\n",
    "\"sys_enter_prlimit64\",\n",
    "\"sys_enter_wait4\",\n",
    "\"sys_enter_fsmount\",\n",
    "\"sys_enter_process_madvise\",\n",
    "\"sys_enter_waitid\",\n",
    "\"sys_enter_fsopen\",\n",
    "\"sys_enter_process_mrelease\",\n",
    "\"sys_enter_write\",\n",
    "\"sys_enter_fspick\",\n",
    "\"sys_enter_process_vm_readv\",\n",
    "\"sys_enter_writev\",\n",
    "\"sys_enter_fstatfs\",\n",
    "\"sys_enter_process_vm_writev\",\n",
    "\"sys_enter_fsync\",\n",
    "\"sys_enter_pselect6\",\n",
    "\"sys_enter_ftruncate\",\n",
    "\"sys_enter_ptrace\",\n",
    "\"sys_enter_futex\",\n",
    "\"sys_enter_pwrite64\",\n",
    "\"sys_enter_get_mempolicy\",\n",
    "\"sys_enter_pwritev\",\n",
    "\"sys_enter_get_robust_list\",\n",
    "\"sys_enter_pwritev2\",\n",
    "\"sys_enter_getcpu\",\n",
    "\"sys_enter_quotactl\",\n",
    "\"sys_enter_getcwd\",\n",
    "\"sys_enter_quotactl_fd\",\n",
    "\"sys_enter_getdents64\",\n",
    "\"sys_enter_read\",\n",
    "\"sys_enter_getegid\",\n",
    "\"sys_enter_readahead\",\n",
    "\"sys_enter_geteuid\",\n",
    "\"sys_enter_readlinkat\",\n",
    "\"sys_enter_getgid\",\n",
    "\"sys_enter_readv\",\n",
    "\"sys_enter_getgroups\",\n",
    "\"sys_enter_reboot\",\n",
    "\"sys_enter_getitimer\",\n",
    "\"sys_enter_recvfrom\",\n",
    "\"sys_enter_getpeername\",\n",
    "\"sys_enter_recvmmsg\",\n",
    "\"sys_enter_getpgid\",\n",
    "\"sys_enter_recvmsg\",\n",
    "\"sys_enter_getpid\",\n",
    "\"sys_enter_remap_file_pages\",\n",
    "\"sys_enter_getppid\",\n",
    "\"sys_enter_removexattr\",\n",
    "\"sys_enter_getpriority\",\n",
    "\"sys_enter_renameat\",\n",
    "\"sys_enter_getrandom\",\n",
    "\"sys_enter_renameat2\",\n",
    "\"sys_enter_getresgid\",\n",
    "\"sys_enter_request_key\",\n",
    "\"sys_enter_getresuid\",\n",
    "\"sys_enter_restart_syscall\",\n",
    "\"sys_enter_getrlimit\",\n",
    "\"sys_enter_rseq\",\n",
    "\"sys_enter_getrusage\",\n",
    "\"sys_enter_rt_sigaction\",\n",
    "\"sys_enter_getsid\",\n",
    "\"sys_enter_rt_sigpending\",\n",
    "\"sys_enter_getsockname\",\n",
    "\"sys_enter_rt_sigprocmask\",\n",
    "\"sys_enter_getsockopt\",\n",
    "\"sys_enter_rt_sigqueueinfo\",\n",
    "\"sys_enter_gettid\",\n",
    "\"sys_enter_rt_sigreturn\",\n",
    "\"sys_enter_gettimeofday\",\n",
    "\"sys_enter_rt_sigsuspend\",\n",
    "\"sys_enter_getuid\",\n",
    "\"sys_enter_rt_sigtimedwait\",\n",
    "\"sys_enter_getxattr\",\n",
    "\"sys_enter_rt_tgsigqueueinfo\",\n",
    "\"sys_enter_init_module\",\n",
    "\"sys_enter_sched_get_priority_max\",\n",
    "\"sys_enter_inotify_add_watch\",\n",
    "\"sys_enter_sched_get_priority_min\",\n",
    "\"sys_enter_inotify_init1\",\n",
    "\"sys_enter_sched_getaffinity\",\n",
    "\"sys_enter_inotify_rm_watch\",\n",
    "\"sys_enter_sched_getattr\",\n",
    "\"sys_enter_io_cancel\",\n",
    "\"sys_enter_sched_getparam\",\n",
    "\"sys_enter_io_destroy\",\n",
    "\"sys_enter_sched_getscheduler\",\n",
    "\"sys_enter_io_getevents\",\n",
    "\"sys_enter_sched_rr_get_interval\",\n",
    "\"sys_enter_io_pgetevents\",\n",
    "\"sys_enter_sched_setaffinity\",\n",
    "\"sys_enter_io_setup\",\n",
    "\"sys_enter_sched_setattr\",\n",
    "\"sys_enter_io_submit\",\n",
    "\"sys_enter_sched_setparam\",\n",
    "\"sys_enter_io_uring_enter\",\n",
    "\"sys_enter_sched_setscheduler\",\n",
    "\"sys_enter_io_uring_register\",\n",
    "\"sys_enter_sched_yield\",\n",
    "\"sys_enter_io_uring_setup\",\n",
    "\"sys_enter_seccomp\",\n",
    "\"sys_enter_ioctl\",\n",
    "\"sys_enter_semctl\",\n",
    "\"sys_enter_ioprio_get\",\n",
    "\"sys_enter_semget\",\n",
    "\"sys_enter_ioprio_set\",\n",
    "\"sys_enter_semop\",\n",
    "\"sys_enter_kcmp\",\n",
    "\"sys_enter_semtimedop\",\n",
    "\"sys_enter_kexec_file_load\",\n",
    "\"sys_enter_sendfile64\",\n",
    "\"sys_enter_kexec_load\",\n",
    "\"sys_enter_sendmmsg\",\n",
    "\"sys_enter_keyctl\",\n",
    "\"sys_enter_sendmsg\",\n",
    "\"sys_enter_kill\",\n",
    "\"sys_enter_sendto\",\n",
    "\"sys_enter_landlock_add_rule\",\n",
    "\"sys_enter_set_mempolicy\",\n",
    "\"sys_enter_landlock_create_ruleset\",\n",
    "\"sys_enter_set_robust_list\",\n",
    "\"sys_enter_landlock_restrict_self\",\n",
    "\"sys_enter_set_tid_address\",\n",
    "\"sys_enter_lgetxattr\",\n",
    "\"sys_enter_setdomainname\",\n",
    "\"sys_enter_linkat\",\n",
    "\"sys_enter_setfsgid\",\n",
    "\"sys_enter_listen\",\n",
    "\"sys_enter_setfsuid\",\n",
    "\"sys_enter_listxattr\",\n",
    "\"sys_enter_setgid\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CSV from Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3\n",
    "CLASSES = np.array(['benign', 'sysrv', 'xmrig'])\n",
    "DATASET_DIR = \"raw_data\"\n",
    "VECTOR_LENGTH = 32 * 32\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(syscalls)\n",
    "\n",
    "def csvToVector(file_path):\n",
    "    try:\n",
    "        data = pd.read_csv(file_path, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "    \n",
    "    data_encoded = label_encoder.fit_transform(data['SYSTEM_CALL'])\n",
    "    vector = np.zeros(VECTOR_LENGTH, dtype=np.uint8)\n",
    "    syscall_nums = min(len(data_encoded), VECTOR_LENGTH)\n",
    "    vector[:syscall_nums] = data_encoded[:syscall_nums]\n",
    "\n",
    "    return vector\n",
    "\n",
    "def process_file(args):\n",
    "    file_path, class_idx = args\n",
    "    vector = csvToVector(file_path)\n",
    "    return vector, class_idx\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    x = []\n",
    "    y = []\n",
    "    classes = [\"0/60sec_0\", \"1/60sec_1\", \"2/60sec_2\"]\n",
    "\n",
    "    file_paths = []\n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        for file_name in os.listdir(class_dir):\n",
    "            if file_name.endswith('.csv'):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                file_paths.append((file_path, class_idx))\n",
    "\n",
    "    with Pool() as pool:\n",
    "        results = pool.map(process_file, file_paths)\n",
    "\n",
    "    x, y = zip(*results)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validation, Test Split and Nomalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train / 299.0\n",
    "X_val = X_val / 299.0\n",
    "X_test = X_test / 299.0\n",
    "\n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_val = to_categorical(y_val, 3)\n",
    "y_test = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1174, 1024)\n",
      "(630, 1024)\n",
      "(1174, 3)\n",
      "(630, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 17:44:49.372218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31350 MB memory:  -> device: 0, name: CUDA GPU, pci bus id: 0000:06:00.0, compute capability: 7.0\n",
      "2024-07-29 17:44:49.372773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31350 MB memory:  -> device: 1, name: CUDA GPU, pci bus id: 0000:2f:00.0, compute capability: 7.0\n",
      "2024-07-29 17:44:49.373264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 31350 MB memory:  -> device: 2, name: CUDA GPU, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(VECTOR_LENGTH, 1))\n",
    "\n",
    "x = Conv1D(filters=32, kernel_size=3, padding='same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Conv1D(filters=64, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Conv1D(filters=128, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(256)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1024, 1)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 1024, 32)          128       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1024, 32)          128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 1024, 32)          0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 512, 32)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 512, 64)           6208      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 512, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 256, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 256, 128)          24704     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 256, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 128, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               4194560   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4228291 (16.13 MB)\n",
      "Trainable params: 4227331 (16.13 MB)\n",
      "Non-trainable params: 960 (3.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='/tmp/CNN1d_checkpoint.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 17:44:52.320672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2024-07-29 17:44:53.733561: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f473221f980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-29 17:44:53.733595: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): CUDA GPU, Compute Capability 7.0\n",
      "2024-07-29 17:44:53.733601: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): CUDA GPU, Compute Capability 7.0\n",
      "2024-07-29 17:44:53.733606: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): CUDA GPU, Compute Capability 7.0\n",
      "2024-07-29 17:44:53.739420: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-29 17:44:53.832902: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.5902 - accuracy: 0.8475\n",
      "Epoch 1: accuracy improved from -inf to 0.84753, saving model to /tmp/CNN1d_checkpoint.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 6s 27ms/step - loss: 0.5902 - accuracy: 0.8475 - val_loss: 0.9799 - val_accuracy: 0.6361 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3010 - accuracy: 0.9208\n",
      "Epoch 2: accuracy improved from 0.84753 to 0.92078, saving model to /tmp/CNN1d_checkpoint.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.3010 - accuracy: 0.9208 - val_loss: 0.9359 - val_accuracy: 0.6361 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1786 - accuracy: 0.9438\n",
      "Epoch 3: accuracy improved from 0.92078 to 0.94378, saving model to /tmp/CNN1d_checkpoint.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.1786 - accuracy: 0.9438 - val_loss: 0.9397 - val_accuracy: 0.6361 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1762 - accuracy: 0.9497\n",
      "Epoch 4: accuracy improved from 0.94378 to 0.94974, saving model to /tmp/CNN1d_checkpoint.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 0.1762 - accuracy: 0.9497 - val_loss: 0.9341 - val_accuracy: 0.6361 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1453 - accuracy: 0.9651\n",
      "Epoch 5: accuracy improved from 0.94974 to 0.96508, saving model to /tmp/CNN1d_checkpoint.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.1453 - accuracy: 0.9651 - val_loss: 1.0138 - val_accuracy: 0.6361 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9642\n",
      "Epoch 6: accuracy did not improve from 0.96508\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1312 - accuracy: 0.9642 - val_loss: 0.9375 - val_accuracy: 0.6361 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9685\n",
      "Epoch 7: accuracy improved from 0.96508 to 0.96848, saving model to /tmp/CNN1d_checkpoint.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.1140 - accuracy: 0.9685 - val_loss: 1.0706 - val_accuracy: 0.2211 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1850 - accuracy: 0.9549\n",
      "Epoch 8: accuracy did not improve from 0.96848\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1850 - accuracy: 0.9549 - val_loss: 2.2592 - val_accuracy: 0.2381 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.1497 - accuracy: 0.9583\n",
      "Epoch 9: accuracy did not improve from 0.96848\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1473 - accuracy: 0.9591 - val_loss: 2.1070 - val_accuracy: 0.2823 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.9744\n",
      "Epoch 10: accuracy improved from 0.96848 to 0.97445, saving model to /tmp/CNN1d_checkpoint.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.1119 - accuracy: 0.9744 - val_loss: 2.5473 - val_accuracy: 0.3061 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.9710\n",
      "Epoch 11: accuracy did not improve from 0.97445\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1242 - accuracy: 0.9710 - val_loss: 2.8663 - val_accuracy: 0.2415 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9727\n",
      "Epoch 12: accuracy did not improve from 0.97445\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1133 - accuracy: 0.9727 - val_loss: 2.9889 - val_accuracy: 0.3231 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9796\n",
      "Epoch 13: accuracy improved from 0.97445 to 0.97956, saving model to /tmp/CNN1d_checkpoint.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0931 - accuracy: 0.9796 - val_loss: 2.8611 - val_accuracy: 0.3299 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.9744\n",
      "Epoch 14: accuracy did not improve from 0.97956\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0980 - accuracy: 0.9744 - val_loss: 0.6629 - val_accuracy: 0.7823 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9736\n",
      "Epoch 15: accuracy did not improve from 0.97956\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1064 - accuracy: 0.9736 - val_loss: 1.6191 - val_accuracy: 0.3707 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1053 - accuracy: 0.9744\n",
      "Epoch 16: accuracy did not improve from 0.97956\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1053 - accuracy: 0.9744 - val_loss: 3.4326 - val_accuracy: 0.3503 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9753\n",
      "Epoch 17: accuracy did not improve from 0.97956\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1146 - accuracy: 0.9753 - val_loss: 4.9849 - val_accuracy: 0.3571 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9796\n",
      "Epoch 18: accuracy did not improve from 0.97956\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0860 - accuracy: 0.9796 - val_loss: 3.4553 - val_accuracy: 0.3571 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9744\n",
      "Epoch 19: accuracy did not improve from 0.97956\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.9744 - val_loss: 3.6661 - val_accuracy: 0.3844 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9727\n",
      "Epoch 20: accuracy did not improve from 0.97956\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0915 - accuracy: 0.9727 - val_loss: 1.5233 - val_accuracy: 0.4150 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9753\n",
      "Epoch 21: accuracy did not improve from 0.97956\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0942 - accuracy: 0.9753 - val_loss: 0.8614 - val_accuracy: 0.4490 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9770\n",
      "Epoch 22: accuracy did not improve from 0.97956\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0869 - accuracy: 0.9770 - val_loss: 1.3318 - val_accuracy: 0.4150 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9796\n",
      "Epoch 23: accuracy did not improve from 0.97956\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0838 - accuracy: 0.9796 - val_loss: 3.5494 - val_accuracy: 0.2517 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9804\n",
      "Epoch 24: accuracy improved from 0.97956 to 0.98041, saving model to /tmp/CNN1d_checkpoint.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0890 - accuracy: 0.9804 - val_loss: 0.8938 - val_accuracy: 0.4082 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0859 - accuracy: 0.9809\n",
      "Epoch 25: accuracy did not improve from 0.98041\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0859 - accuracy: 0.9804 - val_loss: 1.9075 - val_accuracy: 0.2823 - lr: 1.2500e-04\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9813\n",
      "Epoch 26: accuracy improved from 0.98041 to 0.98126, saving model to /tmp/CNN1d_checkpoint.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 0.0799 - accuracy: 0.9813 - val_loss: 2.2834 - val_accuracy: 0.2721 - lr: 1.2500e-04\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9830\n",
      "Epoch 27: accuracy improved from 0.98126 to 0.98296, saving model to /tmp/CNN1d_checkpoint.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0818 - accuracy: 0.9830 - val_loss: 3.2691 - val_accuracy: 0.2517 - lr: 1.2500e-04\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9813\n",
      "Epoch 28: accuracy did not improve from 0.98296\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0882 - accuracy: 0.9813 - val_loss: 1.3824 - val_accuracy: 0.3231 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9787\n",
      "Epoch 29: accuracy did not improve from 0.98296\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0895 - accuracy: 0.9787 - val_loss: 0.3485 - val_accuracy: 0.9014 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9813\n",
      "Epoch 30: accuracy did not improve from 0.98296\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0861 - accuracy: 0.9813 - val_loss: 0.3466 - val_accuracy: 0.8776 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9787\n",
      "Epoch 31: accuracy did not improve from 0.98296\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0897 - accuracy: 0.9787 - val_loss: 0.2150 - val_accuracy: 0.9388 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9821\n",
      "Epoch 32: accuracy did not improve from 0.98296\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0969 - accuracy: 0.9821 - val_loss: 0.1682 - val_accuracy: 0.9660 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9813\n",
      "Epoch 33: accuracy did not improve from 0.98296\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0763 - accuracy: 0.9813 - val_loss: 0.2882 - val_accuracy: 0.8980 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9813\n",
      "Epoch 34: accuracy did not improve from 0.98296\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0899 - accuracy: 0.9813 - val_loss: 0.2093 - val_accuracy: 0.9354 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9838\n",
      "Epoch 35: accuracy improved from 0.98296 to 0.98382, saving model to /tmp/CNN1d_checkpoint.h5\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0770 - accuracy: 0.9838 - val_loss: 0.1548 - val_accuracy: 0.9728 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 0.0967 - accuracy: 0.9750\n",
      "Epoch 36: accuracy did not improve from 0.98382\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1009 - accuracy: 0.9744 - val_loss: 0.1700 - val_accuracy: 0.9592 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0909 - accuracy: 0.9774\n",
      "Epoch 37: accuracy did not improve from 0.98382\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0949 - accuracy: 0.9761 - val_loss: 0.2720 - val_accuracy: 0.9150 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9813\n",
      "Epoch 38: accuracy did not improve from 0.98382\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0804 - accuracy: 0.9813 - val_loss: 0.1842 - val_accuracy: 0.9592 - lr: 1.2500e-04\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9813\n",
      "Epoch 39: accuracy did not improve from 0.98382\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0819 - accuracy: 0.9813 - val_loss: 0.1419 - val_accuracy: 0.9626 - lr: 1.2500e-04\n",
      "Epoch 40/100\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 0.0751 - accuracy: 0.9821\n",
      "Epoch 40: accuracy did not improve from 0.98382\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0756 - accuracy: 0.9821 - val_loss: 0.1551 - val_accuracy: 0.9626 - lr: 1.2500e-04\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9821\n",
      "Epoch 41: accuracy did not improve from 0.98382\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0850 - accuracy: 0.9821 - val_loss: 0.2263 - val_accuracy: 0.9286 - lr: 1.2500e-04\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9821\n",
      "Epoch 42: accuracy did not improve from 0.98382\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0906 - accuracy: 0.9821 - val_loss: 0.3915 - val_accuracy: 0.8605 - lr: 1.2500e-04\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9821\n",
      "Epoch 43: accuracy did not improve from 0.98382\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0808 - accuracy: 0.9821 - val_loss: 0.2307 - val_accuracy: 0.9218 - lr: 1.2500e-04\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9838\n",
      "Epoch 44: accuracy did not improve from 0.98382\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0713 - accuracy: 0.9838 - val_loss: 0.1767 - val_accuracy: 0.9626 - lr: 1.2500e-04\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9838\n",
      "Epoch 45: accuracy did not improve from 0.98382\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0771 - accuracy: 0.9838 - val_loss: 0.1557 - val_accuracy: 0.9592 - lr: 6.2500e-05\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9830\n",
      "Epoch 46: accuracy did not improve from 0.98382\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0678 - accuracy: 0.9830 - val_loss: 0.1717 - val_accuracy: 0.9592 - lr: 6.2500e-05\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9813\n",
      "Epoch 47: accuracy did not improve from 0.98382\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0710 - accuracy: 0.9813 - val_loss: 0.2154 - val_accuracy: 0.9558 - lr: 6.2500e-05\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9830\n",
      "Epoch 48: accuracy did not improve from 0.98382\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0724 - accuracy: 0.9830 - val_loss: 0.1911 - val_accuracy: 0.9626 - lr: 6.2500e-05\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9821\n",
      "Epoch 49: accuracy did not improve from 0.98382\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0677 - accuracy: 0.9821 - val_loss: 0.1667 - val_accuracy: 0.9592 - lr: 6.2500e-05\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9847\n",
      "Epoch 50: accuracy improved from 0.98382 to 0.98467, saving model to /tmp/CNN1d_checkpoint.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0728 - accuracy: 0.9847 - val_loss: 0.1547 - val_accuracy: 0.9626 - lr: 3.1250e-05\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9838\n",
      "Epoch 51: accuracy did not improve from 0.98467\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0742 - accuracy: 0.9838 - val_loss: 0.1461 - val_accuracy: 0.9592 - lr: 3.1250e-05\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9813\n",
      "Epoch 52: accuracy did not improve from 0.98467\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0853 - accuracy: 0.9813 - val_loss: 0.1437 - val_accuracy: 0.9626 - lr: 3.1250e-05\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9838\n",
      "Epoch 53: accuracy did not improve from 0.98467\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0794 - accuracy: 0.9838 - val_loss: 0.1512 - val_accuracy: 0.9592 - lr: 3.1250e-05\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.9855\n",
      "Epoch 54: accuracy improved from 0.98467 to 0.98552, saving model to /tmp/CNN1d_checkpoint.h5\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 0.0743 - accuracy: 0.9855 - val_loss: 0.1482 - val_accuracy: 0.9592 - lr: 3.1250e-05\n",
      "Epoch 55/100\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 0.0695 - accuracy: 0.9839\n",
      "Epoch 55: accuracy did not improve from 0.98552\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0714 - accuracy: 0.9838 - val_loss: 0.1398 - val_accuracy: 0.9626 - lr: 1.5625e-05\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9830\n",
      "Epoch 56: accuracy did not improve from 0.98552\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0645 - accuracy: 0.9830 - val_loss: 0.1357 - val_accuracy: 0.9660 - lr: 1.5625e-05\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9830\n",
      "Epoch 57: accuracy did not improve from 0.98552\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0692 - accuracy: 0.9830 - val_loss: 0.1349 - val_accuracy: 0.9660 - lr: 1.5625e-05\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9813\n",
      "Epoch 58: accuracy did not improve from 0.98552\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0793 - accuracy: 0.9813 - val_loss: 0.1391 - val_accuracy: 0.9660 - lr: 1.5625e-05\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9855\n",
      "Epoch 59: accuracy did not improve from 0.98552\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0644 - accuracy: 0.9855 - val_loss: 0.1343 - val_accuracy: 0.9626 - lr: 1.5625e-05\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9847\n",
      "Epoch 60: accuracy did not improve from 0.98552\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0713 - accuracy: 0.9847 - val_loss: 0.1372 - val_accuracy: 0.9626 - lr: 1.5625e-05\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9813\n",
      "Epoch 61: accuracy did not improve from 0.98552\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0690 - accuracy: 0.9813 - val_loss: 0.1378 - val_accuracy: 0.9626 - lr: 1.5625e-05\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.9830\n",
      "Epoch 62: accuracy did not improve from 0.98552\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0679 - accuracy: 0.9830 - val_loss: 0.1376 - val_accuracy: 0.9626 - lr: 1.5625e-05\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9838\n",
      "Epoch 63: accuracy did not improve from 0.98552\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0687 - accuracy: 0.9838 - val_loss: 0.1395 - val_accuracy: 0.9626 - lr: 1.5625e-05\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9864\n",
      "Epoch 64: accuracy improved from 0.98552 to 0.98637, saving model to /tmp/CNN1d_checkpoint.h5\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0674 - accuracy: 0.9864 - val_loss: 0.1402 - val_accuracy: 0.9626 - lr: 1.5625e-05\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9855\n",
      "Epoch 65: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0645 - accuracy: 0.9855 - val_loss: 0.1424 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9847\n",
      "Epoch 66: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0761 - accuracy: 0.9847 - val_loss: 0.1429 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9855\n",
      "Epoch 67: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0692 - accuracy: 0.9855 - val_loss: 0.1435 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0690 - accuracy: 0.9844\n",
      "Epoch 68: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0680 - accuracy: 0.9847 - val_loss: 0.1426 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9838\n",
      "Epoch 69: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0690 - accuracy: 0.9838 - val_loss: 0.1420 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9847\n",
      "Epoch 70: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0713 - accuracy: 0.9847 - val_loss: 0.1384 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9838\n",
      "Epoch 71: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0711 - accuracy: 0.9838 - val_loss: 0.1391 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9864\n",
      "Epoch 72: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0709 - accuracy: 0.9864 - val_loss: 0.1393 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9830\n",
      "Epoch 73: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0649 - accuracy: 0.9830 - val_loss: 0.1409 - val_accuracy: 0.9660 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9830\n",
      "Epoch 74: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0739 - accuracy: 0.9830 - val_loss: 0.1396 - val_accuracy: 0.9660 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9821\n",
      "Epoch 75: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0704 - accuracy: 0.9821 - val_loss: 0.1393 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9838\n",
      "Epoch 76: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0667 - accuracy: 0.9838 - val_loss: 0.1409 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9847\n",
      "Epoch 77: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0604 - accuracy: 0.9847 - val_loss: 0.1383 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9855\n",
      "Epoch 78: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0763 - accuracy: 0.9855 - val_loss: 0.1386 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 0.9844\n",
      "Epoch 79: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0680 - accuracy: 0.9847 - val_loss: 0.1418 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9847\n",
      "Epoch 80: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0643 - accuracy: 0.9847 - val_loss: 0.1403 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9830\n",
      "Epoch 81: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0719 - accuracy: 0.9830 - val_loss: 0.1423 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 0.0774 - accuracy: 0.9839\n",
      "Epoch 82: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0743 - accuracy: 0.9847 - val_loss: 0.1432 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9804\n",
      "Epoch 83: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0748 - accuracy: 0.9804 - val_loss: 0.1397 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9847\n",
      "Epoch 84: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0702 - accuracy: 0.9847 - val_loss: 0.1401 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9847\n",
      "Epoch 85: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0728 - accuracy: 0.9847 - val_loss: 0.1396 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9838\n",
      "Epoch 86: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0661 - accuracy: 0.9838 - val_loss: 0.1395 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9847\n",
      "Epoch 87: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0630 - accuracy: 0.9847 - val_loss: 0.1377 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9838\n",
      "Epoch 88: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0680 - accuracy: 0.9838 - val_loss: 0.1369 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9847\n",
      "Epoch 89: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0655 - accuracy: 0.9847 - val_loss: 0.1376 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9855\n",
      "Epoch 90: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0690 - accuracy: 0.9855 - val_loss: 0.1359 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9855\n",
      "Epoch 91: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0699 - accuracy: 0.9855 - val_loss: 0.1356 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9847\n",
      "Epoch 92: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0763 - accuracy: 0.9847 - val_loss: 0.1354 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.9821\n",
      "Epoch 93: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0788 - accuracy: 0.9821 - val_loss: 0.1349 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9847\n",
      "Epoch 94: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0690 - accuracy: 0.9847 - val_loss: 0.1375 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.9855\n",
      "Epoch 95: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0657 - accuracy: 0.9855 - val_loss: 0.1369 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9821\n",
      "Epoch 96: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0749 - accuracy: 0.9821 - val_loss: 0.1377 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9847\n",
      "Epoch 97: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0733 - accuracy: 0.9847 - val_loss: 0.1399 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.9855\n",
      "Epoch 98: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0679 - accuracy: 0.9855 - val_loss: 0.1392 - val_accuracy: 0.9626 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9864\n",
      "Epoch 99: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0642 - accuracy: 0.9864 - val_loss: 0.1448 - val_accuracy: 0.9660 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9864\n",
      "Epoch 100: accuracy did not improve from 0.98637\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0709 - accuracy: 0.9864 - val_loss: 0.1392 - val_accuracy: 0.9626 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f4a9c777fa0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[reduce_lr, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 22:38:26.089294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31350 MB memory:  -> device: 0, name: CUDA GPU, pci bus id: 0000:06:00.0, compute capability: 7.0\n",
      "2024-07-31 22:38:26.089840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31350 MB memory:  -> device: 1, name: CUDA GPU, pci bus id: 0000:2f:00.0, compute capability: 7.0\n",
      "2024-07-31 22:38:26.090332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 31350 MB memory:  -> device: 2, name: CUDA GPU, pci bus id: 0000:86:00.0, compute capability: 7.0\n",
      "2024-07-31 22:38:27.556346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 699ms/step - loss: 0.1107 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1107228696346283, 0.9666666388511658]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_model = load_model('/tmp/60_CNN1d_checkpoint.h5')\n",
    "cp_model.evaluate(X_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = cp_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_single = CLASSES[np.argmax(y_pred, axis = -1)]\n",
    "actual_single = CLASSES[np.argmax(y_test, axis = -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(X_test)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    data = X_test[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i+1)\n",
    "    ax.plot(data)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.2, 'pred = ' + str(preds_single[idx]), fontsize=10, ha='center', transform=ax.transAxes) \n",
    "    ax.text(0.5, -0.4, 'act = ' + str(actual_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9689    0.9894    0.9791       378\n",
      "           1     0.9934    0.9677    0.9804       155\n",
      "           2     0.9140    0.8763    0.8947        97\n",
      "\n",
      "    accuracy                         0.9667       630\n",
      "   macro avg     0.9588    0.9445    0.9514       630\n",
      "weighted avg     0.9665    0.9667    0.9664       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "y_test_classes = tf.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_test_classes, y_pred_classes, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        Benign  Sysrv  Xmrig\n",
      "Benign     374      0      4\n",
      "Sysrv        1    150      4\n",
      "Xmrig       11      1     85\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "class_labels = ['Benign', 'Sysrv', 'Xmrig']\n",
    "\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (NGC 24.01 / TensorFlow 2.14) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
