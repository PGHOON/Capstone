{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 04:24:11.311941: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-31 04:24:11.366648: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9360] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-31 04:24:11.366687: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-31 04:24:11.366715: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1537] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-31 04:24:11.376174: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Input, Conv1D, BatchNormalization, LeakyReLU, MaxPooling1D, GlobalAveragePooling1D, Dense, Dropout, Activation, Add, Flatten\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load csv from Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "CLASSES = np.array(['Legitimate', 'Suspicious'])\n",
    "DATASET_DIR = \"./\"\n",
    "VECTOR_LENGTH = 1 * 1360\n",
    "\n",
    "def csvToVector(file_path):\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    vector = data.values.flatten()\n",
    "    return vector\n",
    "\n",
    "def process_file(class_idx, file_path):\n",
    "    vector = csvToVector(file_path)\n",
    "    return (vector, class_idx)\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    subdirs = ['benign_cms2', 'malware_cms2']\n",
    "    futures = []\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for class_idx, class_name in enumerate(subdirs):\n",
    "            class_dir = os.path.join(dataset_dir, class_name)\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                if file_name.endswith('.csv'):\n",
    "                    file_path = os.path.join(class_dir, file_name)\n",
    "                    futures.append(executor.submit(process_file, class_idx, file_path))\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            vector, class_idx = future.result()\n",
    "            X.append(vector)\n",
    "            y.append(class_idx)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4020, 1360)\n",
      "(4020,)\n",
      "[[  146     0     0 ...     0   792   265]\n",
      " [  284     0     0 ...    13  1243   438]\n",
      " [  201     0     0 ...     0   274    26]\n",
      " ...\n",
      " [  153     0     0 ...     0  4061   118]\n",
      " [  189     0     0 ...     0  4077    98]\n",
      " [  127     0     0 ...     3 56578   240]]\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Validation, Test Split and Nomalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train / 299.0\n",
    "X_val = X_val / 299.0\n",
    "X_test = X_test / 299.0\n",
    "\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_val = to_categorical(y_val, 2)\n",
    "y_test = to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2251, 1360)\n",
      "(1206, 1360)\n",
      "(2251, 2)\n",
      "(1206, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "#print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 12:23:19.118492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31350 MB memory:  -> device: 0, name: CUDA GPU, pci bus id: 0000:06:00.0, compute capability: 7.0\n",
      "2024-07-30 12:23:19.119032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31350 MB memory:  -> device: 1, name: CUDA GPU, pci bus id: 0000:2f:00.0, compute capability: 7.0\n",
      "2024-07-30 12:23:19.119513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 31350 MB memory:  -> device: 2, name: CUDA GPU, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(VECTOR_LENGTH, 1))\n",
    "\n",
    "x = Conv1D(filters=32, kernel_size=3, padding='same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Conv1D(filters=64, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Conv1D(filters=128, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(256)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1360, 1)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 1360, 32)          128       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1360, 32)          128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 1360, 32)          0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 680, 32)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 680, 64)           6208      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 680, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 680, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 340, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 340, 128)          24704     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 340, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 340, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 170, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 21760)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               5570816   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5604290 (21.38 MB)\n",
      "Trainable params: 5603330 (21.38 MB)\n",
      "Non-trainable params: 960 (3.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='/tmp/CMS2_CNN_1D_CheckPoint.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 12:23:21.840928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2024-07-30 12:23:23.254975: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8b4830bf20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-30 12:23:23.255015: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): CUDA GPU, Compute Capability 7.0\n",
      "2024-07-30 12:23:23.255022: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): CUDA GPU, Compute Capability 7.0\n",
      "2024-07-30 12:23:23.255026: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): CUDA GPU, Compute Capability 7.0\n",
      "2024-07-30 12:23:23.261055: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-30 12:23:23.354303: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - ETA: 0s - loss: 0.5161 - accuracy: 0.7970\n",
      "Epoch 1: val_accuracy improved from -inf to 0.87567, saving model to /tmp/CMS2_CNN_1D_CheckPoint.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 6s 17ms/step - loss: 0.5161 - accuracy: 0.7970 - val_loss: 0.3255 - val_accuracy: 0.8757 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2806 - accuracy: 0.8801\n",
      "Epoch 2: val_accuracy did not improve from 0.87567\n",
      "71/71 [==============================] - 1s 7ms/step - loss: 0.2806 - accuracy: 0.8801 - val_loss: 0.4355 - val_accuracy: 0.7744 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.9183\n",
      "Epoch 3: val_accuracy did not improve from 0.87567\n",
      "71/71 [==============================] - 1s 7ms/step - loss: 0.2106 - accuracy: 0.9183 - val_loss: 0.3999 - val_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1729 - accuracy: 0.9387\n",
      "Epoch 4: val_accuracy did not improve from 0.87567\n",
      "71/71 [==============================] - 1s 7ms/step - loss: 0.1729 - accuracy: 0.9387 - val_loss: 0.4658 - val_accuracy: 0.8011 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1612 - accuracy: 0.9404\n",
      "Epoch 5: val_accuracy improved from 0.87567 to 0.95382, saving model to /tmp/CMS2_CNN_1D_CheckPoint.h5\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1625 - accuracy: 0.9409 - val_loss: 0.1333 - val_accuracy: 0.9538 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1421 - accuracy: 0.9492\n",
      "Epoch 6: val_accuracy did not improve from 0.95382\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1451 - accuracy: 0.9489 - val_loss: 0.1285 - val_accuracy: 0.9503 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1346 - accuracy: 0.9521\n",
      "Epoch 7: val_accuracy improved from 0.95382 to 0.96270, saving model to /tmp/CMS2_CNN_1D_CheckPoint.h5\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1343 - accuracy: 0.9516 - val_loss: 0.1067 - val_accuracy: 0.9627 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1430 - accuracy: 0.9497\n",
      "Epoch 8: val_accuracy improved from 0.96270 to 0.97158, saving model to /tmp/CMS2_CNN_1D_CheckPoint.h5\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1457 - accuracy: 0.9494 - val_loss: 0.0948 - val_accuracy: 0.9716 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1521 - accuracy: 0.9360\n",
      "Epoch 9: val_accuracy did not improve from 0.97158\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1475 - accuracy: 0.9387 - val_loss: 0.1124 - val_accuracy: 0.9609 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1413 - accuracy: 0.9502\n",
      "Epoch 10: val_accuracy did not improve from 0.97158\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1423 - accuracy: 0.9507 - val_loss: 0.1061 - val_accuracy: 0.9680 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1255 - accuracy: 0.9551\n",
      "Epoch 11: val_accuracy did not improve from 0.97158\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1277 - accuracy: 0.9542 - val_loss: 0.1114 - val_accuracy: 0.9609 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1302 - accuracy: 0.9521\n",
      "Epoch 12: val_accuracy did not improve from 0.97158\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1338 - accuracy: 0.9489 - val_loss: 0.0948 - val_accuracy: 0.9716 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "63/71 [=========================>....] - ETA: 0s - loss: 0.1269 - accuracy: 0.9519\n",
      "Epoch 13: val_accuracy did not improve from 0.97158\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1320 - accuracy: 0.9494 - val_loss: 0.1289 - val_accuracy: 0.9520 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1119 - accuracy: 0.9570\n",
      "Epoch 14: val_accuracy improved from 0.97158 to 0.97336, saving model to /tmp/CMS2_CNN_1D_CheckPoint.h5\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1153 - accuracy: 0.9556 - val_loss: 0.0975 - val_accuracy: 0.9734 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1200 - accuracy: 0.9556\n",
      "Epoch 15: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1173 - accuracy: 0.9565 - val_loss: 0.1098 - val_accuracy: 0.9645 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1151 - accuracy: 0.9580\n",
      "Epoch 16: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1185 - accuracy: 0.9565 - val_loss: 0.0896 - val_accuracy: 0.9734 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1099 - accuracy: 0.9565\n",
      "Epoch 17: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1131 - accuracy: 0.9569 - val_loss: 0.0904 - val_accuracy: 0.9734 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1144 - accuracy: 0.9585\n",
      "Epoch 18: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1164 - accuracy: 0.9574 - val_loss: 0.0885 - val_accuracy: 0.9734 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1130 - accuracy: 0.9619\n",
      "Epoch 19: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1118 - accuracy: 0.9631 - val_loss: 0.0853 - val_accuracy: 0.9734 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1204 - accuracy: 0.9570\n",
      "Epoch 20: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1175 - accuracy: 0.9574 - val_loss: 0.0946 - val_accuracy: 0.9716 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1019 - accuracy: 0.9624\n",
      "Epoch 21: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1008 - accuracy: 0.9631 - val_loss: 0.0903 - val_accuracy: 0.9663 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1057 - accuracy: 0.9600\n",
      "Epoch 22: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.9596 - val_loss: 0.0919 - val_accuracy: 0.9680 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1130 - accuracy: 0.9536\n",
      "Epoch 23: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1150 - accuracy: 0.9534 - val_loss: 0.0863 - val_accuracy: 0.9734 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1067 - accuracy: 0.9575\n",
      "Epoch 24: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1096 - accuracy: 0.9560 - val_loss: 0.0981 - val_accuracy: 0.9645 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1105 - accuracy: 0.9561\n",
      "Epoch 25: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1106 - accuracy: 0.9565 - val_loss: 0.0870 - val_accuracy: 0.9680 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0989 - accuracy: 0.9624\n",
      "Epoch 26: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0985 - accuracy: 0.9614 - val_loss: 0.0845 - val_accuracy: 0.9698 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1026 - accuracy: 0.9590\n",
      "Epoch 27: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1020 - accuracy: 0.9596 - val_loss: 0.0970 - val_accuracy: 0.9698 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0947 - accuracy: 0.9663\n",
      "Epoch 28: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0969 - accuracy: 0.9653 - val_loss: 0.1055 - val_accuracy: 0.9627 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0955 - accuracy: 0.9648\n",
      "Epoch 29: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0997 - accuracy: 0.9645 - val_loss: 0.1076 - val_accuracy: 0.9609 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0993 - accuracy: 0.9629\n",
      "Epoch 30: val_accuracy did not improve from 0.97336\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.1022 - accuracy: 0.9609 - val_loss: 0.1300 - val_accuracy: 0.9609 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1022 - accuracy: 0.9604\n",
      "Epoch 31: val_accuracy improved from 0.97336 to 0.97513, saving model to /tmp/CMS2_CNN_1D_CheckPoint.h5\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0980 - accuracy: 0.9614 - val_loss: 0.0870 - val_accuracy: 0.9751 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 0.9683\n",
      "Epoch 32: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 1s 7ms/step - loss: 0.0975 - accuracy: 0.9685 - val_loss: 0.0840 - val_accuracy: 0.9680 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "63/71 [=========================>....] - ETA: 0s - loss: 0.0919 - accuracy: 0.9658\n",
      "Epoch 33: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0970 - accuracy: 0.9667 - val_loss: 0.0866 - val_accuracy: 0.9698 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0993 - accuracy: 0.9648\n",
      "Epoch 34: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0994 - accuracy: 0.9653 - val_loss: 0.0899 - val_accuracy: 0.9663 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0998 - accuracy: 0.9609\n",
      "Epoch 35: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0980 - accuracy: 0.9622 - val_loss: 0.0857 - val_accuracy: 0.9645 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0977 - accuracy: 0.9658\n",
      "Epoch 36: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0962 - accuracy: 0.9667 - val_loss: 0.0865 - val_accuracy: 0.9734 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0932 - accuracy: 0.9688\n",
      "Epoch 37: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0946 - accuracy: 0.9671 - val_loss: 0.0970 - val_accuracy: 0.9645 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0903 - accuracy: 0.9668\n",
      "Epoch 38: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0906 - accuracy: 0.9658 - val_loss: 0.0898 - val_accuracy: 0.9680 - lr: 6.2500e-05\n",
      "Epoch 39/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0870 - accuracy: 0.9653\n",
      "Epoch 39: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.9653 - val_loss: 0.0918 - val_accuracy: 0.9609 - lr: 6.2500e-05\n",
      "Epoch 40/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0945 - accuracy: 0.9634\n",
      "Epoch 40: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0901 - accuracy: 0.9653 - val_loss: 0.0994 - val_accuracy: 0.9627 - lr: 6.2500e-05\n",
      "Epoch 41/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0878 - accuracy: 0.9658\n",
      "Epoch 41: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0897 - accuracy: 0.9636 - val_loss: 0.0878 - val_accuracy: 0.9680 - lr: 6.2500e-05\n",
      "Epoch 42/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0944 - accuracy: 0.9585\n",
      "Epoch 42: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0907 - accuracy: 0.9605 - val_loss: 0.0912 - val_accuracy: 0.9627 - lr: 6.2500e-05\n",
      "Epoch 43/100\n",
      "63/71 [=========================>....] - ETA: 0s - loss: 0.0976 - accuracy: 0.9618\n",
      "Epoch 43: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0970 - accuracy: 0.9622 - val_loss: 0.0884 - val_accuracy: 0.9663 - lr: 3.1250e-05\n",
      "Epoch 44/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0913 - accuracy: 0.9629\n",
      "Epoch 44: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0925 - accuracy: 0.9636 - val_loss: 0.0900 - val_accuracy: 0.9645 - lr: 3.1250e-05\n",
      "Epoch 45/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0934 - accuracy: 0.9668\n",
      "Epoch 45: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0914 - accuracy: 0.9680 - val_loss: 0.0936 - val_accuracy: 0.9609 - lr: 3.1250e-05\n",
      "Epoch 46/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0943 - accuracy: 0.9653\n",
      "Epoch 46: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0936 - accuracy: 0.9649 - val_loss: 0.0912 - val_accuracy: 0.9645 - lr: 3.1250e-05\n",
      "Epoch 47/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0893 - accuracy: 0.9639\n",
      "Epoch 47: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0875 - accuracy: 0.9645 - val_loss: 0.0897 - val_accuracy: 0.9663 - lr: 3.1250e-05\n",
      "Epoch 48/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0879 - accuracy: 0.9644\n",
      "Epoch 48: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0875 - accuracy: 0.9645 - val_loss: 0.0912 - val_accuracy: 0.9645 - lr: 1.5625e-05\n",
      "Epoch 49/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0865 - accuracy: 0.9688\n",
      "Epoch 49: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0884 - accuracy: 0.9671 - val_loss: 0.0899 - val_accuracy: 0.9645 - lr: 1.5625e-05\n",
      "Epoch 50/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0885 - accuracy: 0.9678\n",
      "Epoch 50: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0891 - accuracy: 0.9676 - val_loss: 0.0879 - val_accuracy: 0.9680 - lr: 1.5625e-05\n",
      "Epoch 51/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0872 - accuracy: 0.9663\n",
      "Epoch 51: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0886 - accuracy: 0.9658 - val_loss: 0.0924 - val_accuracy: 0.9609 - lr: 1.5625e-05\n",
      "Epoch 52/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0903 - accuracy: 0.9658\n",
      "Epoch 52: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0878 - accuracy: 0.9671 - val_loss: 0.0909 - val_accuracy: 0.9645 - lr: 1.5625e-05\n",
      "Epoch 53/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0847 - accuracy: 0.9653\n",
      "Epoch 53: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0872 - accuracy: 0.9636 - val_loss: 0.0909 - val_accuracy: 0.9645 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "63/71 [=========================>....] - ETA: 0s - loss: 0.0858 - accuracy: 0.9678\n",
      "Epoch 54: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0908 - accuracy: 0.9667 - val_loss: 0.0880 - val_accuracy: 0.9663 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0989 - accuracy: 0.9639\n",
      "Epoch 55: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0957 - accuracy: 0.9649 - val_loss: 0.0964 - val_accuracy: 0.9609 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0909 - accuracy: 0.9673\n",
      "Epoch 56: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0907 - accuracy: 0.9680 - val_loss: 0.0990 - val_accuracy: 0.9627 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0849 - accuracy: 0.9702\n",
      "Epoch 57: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9702 - val_loss: 0.0928 - val_accuracy: 0.9609 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0862 - accuracy: 0.9653\n",
      "Epoch 58: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0865 - accuracy: 0.9658 - val_loss: 0.0904 - val_accuracy: 0.9645 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0842 - accuracy: 0.9668\n",
      "Epoch 59: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0846 - accuracy: 0.9676 - val_loss: 0.0897 - val_accuracy: 0.9645 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.1002 - accuracy: 0.9590\n",
      "Epoch 60: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0972 - accuracy: 0.9609 - val_loss: 0.0885 - val_accuracy: 0.9663 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0866 - accuracy: 0.9673\n",
      "Epoch 61: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0848 - accuracy: 0.9685 - val_loss: 0.0880 - val_accuracy: 0.9663 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0923 - accuracy: 0.9614\n",
      "Epoch 62: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0906 - accuracy: 0.9622 - val_loss: 0.0885 - val_accuracy: 0.9663 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0875 - accuracy: 0.9678\n",
      "Epoch 63: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0913 - accuracy: 0.9680 - val_loss: 0.0873 - val_accuracy: 0.9680 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0908 - accuracy: 0.9678\n",
      "Epoch 64: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0885 - accuracy: 0.9685 - val_loss: 0.0875 - val_accuracy: 0.9663 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0799 - accuracy: 0.9697\n",
      "Epoch 65: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9676 - val_loss: 0.0883 - val_accuracy: 0.9680 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0862 - accuracy: 0.9702\n",
      "Epoch 66: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0888 - accuracy: 0.9680 - val_loss: 0.0930 - val_accuracy: 0.9609 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0940 - accuracy: 0.9634\n",
      "Epoch 67: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0908 - accuracy: 0.9645 - val_loss: 0.0972 - val_accuracy: 0.9627 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "63/71 [=========================>....] - ETA: 0s - loss: 0.0861 - accuracy: 0.9638\n",
      "Epoch 68: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0871 - accuracy: 0.9653 - val_loss: 0.0935 - val_accuracy: 0.9609 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0828 - accuracy: 0.9648\n",
      "Epoch 69: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.9645 - val_loss: 0.0900 - val_accuracy: 0.9645 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0871 - accuracy: 0.9653\n",
      "Epoch 70: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0864 - accuracy: 0.9658 - val_loss: 0.0968 - val_accuracy: 0.9627 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0914 - accuracy: 0.9658\n",
      "Epoch 71: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0903 - accuracy: 0.9653 - val_loss: 0.0968 - val_accuracy: 0.9627 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0852 - accuracy: 0.9707\n",
      "Epoch 72: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9716 - val_loss: 0.0953 - val_accuracy: 0.9609 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0829 - accuracy: 0.9702\n",
      "Epoch 73: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0859 - accuracy: 0.9685 - val_loss: 0.0907 - val_accuracy: 0.9627 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0863 - accuracy: 0.9678\n",
      "Epoch 74: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9680 - val_loss: 0.0885 - val_accuracy: 0.9645 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0828 - accuracy: 0.9702\n",
      "Epoch 75: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0842 - accuracy: 0.9698 - val_loss: 0.0852 - val_accuracy: 0.9680 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0890 - accuracy: 0.9663\n",
      "Epoch 76: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0918 - accuracy: 0.9667 - val_loss: 0.0831 - val_accuracy: 0.9680 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0794 - accuracy: 0.9707\n",
      "Epoch 77: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0848 - accuracy: 0.9693 - val_loss: 0.0873 - val_accuracy: 0.9645 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0905 - accuracy: 0.9692\n",
      "Epoch 78: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0891 - accuracy: 0.9693 - val_loss: 0.0868 - val_accuracy: 0.9663 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0860 - accuracy: 0.9722\n",
      "Epoch 79: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0873 - accuracy: 0.9716 - val_loss: 0.0881 - val_accuracy: 0.9663 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0800 - accuracy: 0.9697\n",
      "Epoch 80: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0864 - accuracy: 0.9662 - val_loss: 0.0904 - val_accuracy: 0.9627 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0913 - accuracy: 0.9658\n",
      "Epoch 81: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0907 - accuracy: 0.9653 - val_loss: 0.0887 - val_accuracy: 0.9645 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0852 - accuracy: 0.9673\n",
      "Epoch 82: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0862 - accuracy: 0.9667 - val_loss: 0.0910 - val_accuracy: 0.9627 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0849 - accuracy: 0.9663\n",
      "Epoch 83: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.9662 - val_loss: 0.0909 - val_accuracy: 0.9609 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0878 - accuracy: 0.9673\n",
      "Epoch 84: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0899 - accuracy: 0.9653 - val_loss: 0.0928 - val_accuracy: 0.9609 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0851 - accuracy: 0.9663\n",
      "Epoch 85: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0842 - accuracy: 0.9676 - val_loss: 0.0913 - val_accuracy: 0.9645 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0869 - accuracy: 0.9692\n",
      "Epoch 86: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0877 - accuracy: 0.9693 - val_loss: 0.0886 - val_accuracy: 0.9627 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0819 - accuracy: 0.9692\n",
      "Epoch 87: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9685 - val_loss: 0.0941 - val_accuracy: 0.9627 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9627\n",
      "Epoch 88: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0886 - accuracy: 0.9627 - val_loss: 0.0955 - val_accuracy: 0.9609 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0889 - accuracy: 0.9644\n",
      "Epoch 89: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0877 - accuracy: 0.9645 - val_loss: 0.0975 - val_accuracy: 0.9645 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0833 - accuracy: 0.9678\n",
      "Epoch 90: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9671 - val_loss: 0.0989 - val_accuracy: 0.9645 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0860 - accuracy: 0.9653\n",
      "Epoch 91: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0851 - accuracy: 0.9667 - val_loss: 0.0926 - val_accuracy: 0.9609 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0977 - accuracy: 0.9629\n",
      "Epoch 92: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0929 - accuracy: 0.9653 - val_loss: 0.0932 - val_accuracy: 0.9609 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0846 - accuracy: 0.9683\n",
      "Epoch 93: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0853 - accuracy: 0.9676 - val_loss: 0.0880 - val_accuracy: 0.9663 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0803 - accuracy: 0.9673\n",
      "Epoch 94: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0843 - accuracy: 0.9662 - val_loss: 0.0895 - val_accuracy: 0.9627 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0819 - accuracy: 0.9688\n",
      "Epoch 95: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 0.9667 - val_loss: 0.0887 - val_accuracy: 0.9627 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0794 - accuracy: 0.9707\n",
      "Epoch 96: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9685 - val_loss: 0.0888 - val_accuracy: 0.9627 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0893 - accuracy: 0.9653\n",
      "Epoch 97: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.9653 - val_loss: 0.0946 - val_accuracy: 0.9609 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0841 - accuracy: 0.9673\n",
      "Epoch 98: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0871 - accuracy: 0.9662 - val_loss: 0.0955 - val_accuracy: 0.9609 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0897 - accuracy: 0.9678\n",
      "Epoch 99: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0893 - accuracy: 0.9680 - val_loss: 0.0972 - val_accuracy: 0.9645 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "64/71 [==========================>...] - ETA: 0s - loss: 0.0871 - accuracy: 0.9653\n",
      "Epoch 100: val_accuracy did not improve from 0.97513\n",
      "71/71 [==============================] - 0s 7ms/step - loss: 0.0839 - accuracy: 0.9671 - val_loss: 0.0883 - val_accuracy: 0.9645 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f8d445ae560>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[reduce_lr, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0858 - accuracy: 0.9710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0857851579785347, 0.9709784388542175]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_model = load_model('/tmp/CMS2_CNN_1D_CheckPoint.h5')\n",
    "cp_model.evaluate(X_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = cp_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_single = CLASSES[np.argmax(y_pred, axis = -1)]\n",
    "actual_single = CLASSES[np.argmax(y_test, axis = -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(X_test)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    data = X_test[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i+1)\n",
    "    ax.plot(data)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.2, 'pred = ' + str(preds_single[idx]), fontsize=10, ha='center', transform=ax.transAxes) \n",
    "    ax.text(0.5, -0.4, 'act = ' + str(actual_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       624\n",
      "           1       0.98      0.96      0.97       582\n",
      "\n",
      "    accuracy                           0.97      1206\n",
      "   macro avg       0.97      0.97      0.97      1206\n",
      "weighted avg       0.97      0.97      0.97      1206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "y_test_classes = tf.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion MatriX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "            Legitimate  Suspicious\n",
      "Legitimate         611          13\n",
      "Suspicious          22         560\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "class_labels = ['Legitimate', 'Suspicious']\n",
    "\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (NGC 24.01 / TensorFlow 2.14) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
