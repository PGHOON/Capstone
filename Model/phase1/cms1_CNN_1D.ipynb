{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 11:11:21.746823: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-30 11:11:21.797752: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9360] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-30 11:11:21.797788: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-30 11:11:21.797818: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1537] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-30 11:11:21.806783: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Input, Conv1D, BatchNormalization, LeakyReLU, MaxPooling1D, GlobalAveragePooling1D, Dense, Dropout, Activation, Add, Flatten\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load csv from Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "CLASSES = np.array(['Legitimate', 'Suspicious'])\n",
    "DATASET_DIR = \"./\"\n",
    "VECTOR_LENGTH = 1 * 816\n",
    "\n",
    "def csvToVector(file_path):\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    vector = data.values.flatten()\n",
    "    return vector\n",
    "\n",
    "def process_file(class_idx, file_path):\n",
    "    vector = csvToVector(file_path)\n",
    "    return (vector, class_idx)\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    subdirs = ['benign_cms1', 'malware_cms1']\n",
    "    futures = []\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for class_idx, class_name in enumerate(subdirs):\n",
    "            class_dir = os.path.join(dataset_dir, class_name)\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                if file_name.endswith('.csv'):\n",
    "                    file_path = os.path.join(class_dir, file_name)\n",
    "                    futures.append(executor.submit(process_file, class_idx, file_path))\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            vector, class_idx = future.result()\n",
    "            X.append(vector)\n",
    "            y.append(class_idx)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4020, 816)\n",
      "(4020,)\n",
      "[[  229     0     0 ...  1864     0   237]\n",
      " [  588     0     0 ...   965     0    40]\n",
      " [  189     0     0 ...  1774     0   226]\n",
      " ...\n",
      " [  145     0     0 ... 34875     0    53]\n",
      " [  186     0     0 ...  2669     0    57]\n",
      " [  127     0     0 ...  2675     0    59]]\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Validation, Test Split and Nomalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train / 299.0\n",
    "X_val = X_val / 299.0\n",
    "X_test = X_test / 299.0\n",
    "\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_val = to_categorical(y_val, 2)\n",
    "y_test = to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2251, 816)\n",
      "(1206, 816)\n",
      "(2251, 2)\n",
      "(1206, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "#print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 11:12:08.310601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31350 MB memory:  -> device: 0, name: CUDA GPU, pci bus id: 0000:06:00.0, compute capability: 7.0\n",
      "2024-07-30 11:12:08.311154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31350 MB memory:  -> device: 1, name: CUDA GPU, pci bus id: 0000:2f:00.0, compute capability: 7.0\n",
      "2024-07-30 11:12:08.311658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 31350 MB memory:  -> device: 2, name: CUDA GPU, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(VECTOR_LENGTH, 1))\n",
    "\n",
    "x = Conv1D(filters=32, kernel_size=3, padding='same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Conv1D(filters=64, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Conv1D(filters=128, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(256)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 816, 1)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 816, 32)              128       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 816, 32)              128       ['conv1d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)     (None, 816, 32)              0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1  (None, 408, 32)              0         ['leaky_re_lu[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 408, 32)              3104      ['max_pooling1d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 408, 32)              128       ['conv1d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 408, 32)              0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 408, 32)              3104      ['leaky_re_lu_1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 408, 32)              128       ['conv1d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 408, 32)              0         ['max_pooling1d[0][0]',       \n",
      "                                                                     'batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 408, 32)              0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPoolin  (None, 204, 32)              0         ['leaky_re_lu_2[0][0]']       \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 204, 64)              6208      ['max_pooling1d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 204, 64)              256       ['conv1d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 204, 64)              0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPoolin  (None, 102, 64)              0         ['leaky_re_lu_3[0][0]']       \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 102, 64)              12352     ['max_pooling1d_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 102, 64)              256       ['conv1d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 102, 64)              0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 102, 64)              12352     ['leaky_re_lu_4[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 102, 64)              256       ['conv1d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 102, 64)              0         ['max_pooling1d_2[0][0]',     \n",
      "                                                                     'batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 102, 64)              0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPoolin  (None, 51, 64)               0         ['leaky_re_lu_5[0][0]']       \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 51, 128)              24704     ['max_pooling1d_3[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 51, 128)              512       ['conv1d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 51, 128)              0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPoolin  (None, 25, 128)              0         ['leaky_re_lu_6[0][0]']       \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 25, 128)              49280     ['max_pooling1d_4[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 25, 128)              512       ['conv1d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 25, 128)              0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 25, 128)              49280     ['leaky_re_lu_7[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 25, 128)              512       ['conv1d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 25, 128)              0         ['max_pooling1d_4[0][0]',     \n",
      "                                                                     'batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 25, 128)              0         ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPoolin  (None, 12, 128)              0         ['leaky_re_lu_8[0][0]']       \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 128)                  0         ['max_pooling1d_5[0][0]']     \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  33024     ['global_average_pooling1d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 256)                  1024      ['dense[0][0]']               \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 256)                  0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 256)                  0         ['leaky_re_lu_9[0][0]']       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 2)                    514       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 2)                    0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 197762 (772.51 KB)\n",
      "Trainable params: 195906 (765.26 KB)\n",
      "Non-trainable params: 1856 (7.25 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='/tmp/CMS_CNN_1D_CheckPoint.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 11:12:13.507004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2024-07-30 11:12:14.942106: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6e6627d650 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-30 11:12:14.942141: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): CUDA GPU, Compute Capability 7.0\n",
      "2024-07-30 11:12:14.942147: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): CUDA GPU, Compute Capability 7.0\n",
      "2024-07-30 11:12:14.942153: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): CUDA GPU, Compute Capability 7.0\n",
      "2024-07-30 11:12:14.948058: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-30 11:12:15.041581: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - ETA: 0s - loss: 0.3576 - accuracy: 0.8570\n",
      "Epoch 1: val_accuracy improved from -inf to 0.87744, saving model to /tmp/CMS_CNN_1D_CheckPoint.h5\n",
      "71/71 [==============================] - 10s 26ms/step - loss: 0.3576 - accuracy: 0.8570 - val_loss: 0.3548 - val_accuracy: 0.8774 - lr: 0.0010\n",
      "Epoch 2/100\n",
      " 5/71 [=>............................] - ETA: 0s - loss: 0.2370 - accuracy: 0.9000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/71 [============================>.] - ETA: 0s - loss: 0.2215 - accuracy: 0.9185\n",
      "Epoch 2: val_accuracy did not improve from 0.87744\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.2241 - accuracy: 0.9169 - val_loss: 0.4576 - val_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1903 - accuracy: 0.9307\n",
      "Epoch 3: val_accuracy improved from 0.87744 to 0.89343, saving model to /tmp/CMS_CNN_1D_CheckPoint.h5\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.1903 - accuracy: 0.9307 - val_loss: 0.2545 - val_accuracy: 0.8934 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9424\n",
      "Epoch 4: val_accuracy did not improve from 0.89343\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1738 - accuracy: 0.9418 - val_loss: 0.5987 - val_accuracy: 0.8135 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.1397 - accuracy: 0.9484\n",
      "Epoch 5: val_accuracy did not improve from 0.89343\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1380 - accuracy: 0.9489 - val_loss: 0.5995 - val_accuracy: 0.8206 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.1295 - accuracy: 0.9565\n",
      "Epoch 6: val_accuracy did not improve from 0.89343\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1320 - accuracy: 0.9551 - val_loss: 0.4213 - val_accuracy: 0.8757 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1253 - accuracy: 0.9520\n",
      "Epoch 7: val_accuracy improved from 0.89343 to 0.94849, saving model to /tmp/CMS_CNN_1D_CheckPoint.h5\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.1253 - accuracy: 0.9520 - val_loss: 0.2051 - val_accuracy: 0.9485 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.1369 - accuracy: 0.9499\n",
      "Epoch 8: val_accuracy did not improve from 0.94849\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1374 - accuracy: 0.9489 - val_loss: 0.2091 - val_accuracy: 0.9378 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.9605\n",
      "Epoch 9: val_accuracy improved from 0.94849 to 0.97158, saving model to /tmp/CMS_CNN_1D_CheckPoint.h5\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.1218 - accuracy: 0.9605 - val_loss: 0.0859 - val_accuracy: 0.9716 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 0.9583\n",
      "Epoch 10: val_accuracy did not improve from 0.97158\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1141 - accuracy: 0.9587 - val_loss: 0.1330 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.1135 - accuracy: 0.9619\n",
      "Epoch 11: val_accuracy did not improve from 0.97158\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1131 - accuracy: 0.9618 - val_loss: 0.1069 - val_accuracy: 0.9520 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.9574\n",
      "Epoch 12: val_accuracy did not improve from 0.97158\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1180 - accuracy: 0.9574 - val_loss: 0.1506 - val_accuracy: 0.9449 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.1198 - accuracy: 0.9573\n",
      "Epoch 13: val_accuracy did not improve from 0.97158\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1240 - accuracy: 0.9556 - val_loss: 2.0581 - val_accuracy: 0.5684 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.1309 - accuracy: 0.9504\n",
      "Epoch 14: val_accuracy did not improve from 0.97158\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1290 - accuracy: 0.9511 - val_loss: 0.4301 - val_accuracy: 0.7744 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.1117 - accuracy: 0.9606\n",
      "Epoch 15: val_accuracy did not improve from 0.97158\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1124 - accuracy: 0.9600 - val_loss: 0.3641 - val_accuracy: 0.8046 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.9618\n",
      "Epoch 16: val_accuracy did not improve from 0.97158\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1029 - accuracy: 0.9618 - val_loss: 0.0896 - val_accuracy: 0.9609 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "67/71 [===========================>..] - ETA: 0s - loss: 0.1181 - accuracy: 0.9590\n",
      "Epoch 17: val_accuracy did not improve from 0.97158\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1229 - accuracy: 0.9578 - val_loss: 0.1030 - val_accuracy: 0.9698 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9636\n",
      "Epoch 18: val_accuracy did not improve from 0.97158\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1012 - accuracy: 0.9636 - val_loss: 0.1057 - val_accuracy: 0.9698 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 0.9665\n",
      "Epoch 19: val_accuracy improved from 0.97158 to 0.97691, saving model to /tmp/CMS_CNN_1D_CheckPoint.h5\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0937 - accuracy: 0.9667 - val_loss: 0.0844 - val_accuracy: 0.9769 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.1017 - accuracy: 0.9598\n",
      "Epoch 20: val_accuracy did not improve from 0.97691\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.1013 - accuracy: 0.9600 - val_loss: 0.0799 - val_accuracy: 0.9769 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9642\n",
      "Epoch 21: val_accuracy did not improve from 0.97691\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0932 - accuracy: 0.9640 - val_loss: 0.2409 - val_accuracy: 0.9183 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 0.9669\n",
      "Epoch 22: val_accuracy did not improve from 0.97691\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0963 - accuracy: 0.9667 - val_loss: 0.0830 - val_accuracy: 0.9627 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9636\n",
      "Epoch 23: val_accuracy did not improve from 0.97691\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0928 - accuracy: 0.9636 - val_loss: 0.1066 - val_accuracy: 0.9751 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9671\n",
      "Epoch 24: val_accuracy did not improve from 0.97691\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0947 - accuracy: 0.9671 - val_loss: 0.1059 - val_accuracy: 0.9716 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.0965 - accuracy: 0.9655\n",
      "Epoch 25: val_accuracy did not improve from 0.97691\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0965 - accuracy: 0.9653 - val_loss: 0.1020 - val_accuracy: 0.9663 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.0922 - accuracy: 0.9660\n",
      "Epoch 26: val_accuracy did not improve from 0.97691\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0939 - accuracy: 0.9658 - val_loss: 0.0739 - val_accuracy: 0.9751 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 0.9676\n",
      "Epoch 27: val_accuracy did not improve from 0.97691\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0884 - accuracy: 0.9676 - val_loss: 0.1060 - val_accuracy: 0.9591 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.0909 - accuracy: 0.9665\n",
      "Epoch 28: val_accuracy did not improve from 0.97691\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0897 - accuracy: 0.9667 - val_loss: 0.1125 - val_accuracy: 0.9734 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0840 - accuracy: 0.9683\n",
      "Epoch 29: val_accuracy did not improve from 0.97691\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0848 - accuracy: 0.9680 - val_loss: 0.1527 - val_accuracy: 0.9556 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "67/71 [===========================>..] - ETA: 0s - loss: 0.0937 - accuracy: 0.9641\n",
      "Epoch 30: val_accuracy did not improve from 0.97691\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0928 - accuracy: 0.9645 - val_loss: 0.1206 - val_accuracy: 0.9716 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "67/71 [===========================>..] - ETA: 0s - loss: 0.0783 - accuracy: 0.9692\n",
      "Epoch 31: val_accuracy did not improve from 0.97691\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0844 - accuracy: 0.9662 - val_loss: 0.1806 - val_accuracy: 0.9307 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0791 - accuracy: 0.9688\n",
      "Epoch 32: val_accuracy did not improve from 0.97691\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0805 - accuracy: 0.9680 - val_loss: 0.1200 - val_accuracy: 0.9609 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9685\n",
      "Epoch 33: val_accuracy improved from 0.97691 to 0.97869, saving model to /tmp/CMS_CNN_1D_CheckPoint.h5\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0792 - accuracy: 0.9685 - val_loss: 0.0726 - val_accuracy: 0.9787 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9649\n",
      "Epoch 34: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0850 - accuracy: 0.9649 - val_loss: 0.0814 - val_accuracy: 0.9751 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0766 - accuracy: 0.9701\n",
      "Epoch 35: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0762 - accuracy: 0.9702 - val_loss: 0.0702 - val_accuracy: 0.9751 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "67/71 [===========================>..] - ETA: 0s - loss: 0.0744 - accuracy: 0.9715\n",
      "Epoch 36: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0762 - accuracy: 0.9711 - val_loss: 0.1946 - val_accuracy: 0.9218 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0804 - accuracy: 0.9688\n",
      "Epoch 37: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0801 - accuracy: 0.9689 - val_loss: 0.0681 - val_accuracy: 0.9787 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0779 - accuracy: 0.9706\n",
      "Epoch 38: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0784 - accuracy: 0.9707 - val_loss: 0.0898 - val_accuracy: 0.9698 - lr: 1.2500e-04\n",
      "Epoch 39/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9728\n",
      "Epoch 39: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0751 - accuracy: 0.9729 - val_loss: 0.2502 - val_accuracy: 0.8899 - lr: 1.2500e-04\n",
      "Epoch 40/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0797 - accuracy: 0.9665\n",
      "Epoch 40: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0788 - accuracy: 0.9671 - val_loss: 0.0759 - val_accuracy: 0.9769 - lr: 1.2500e-04\n",
      "Epoch 41/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9688\n",
      "Epoch 41: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0766 - accuracy: 0.9689 - val_loss: 0.0785 - val_accuracy: 0.9751 - lr: 1.2500e-04\n",
      "Epoch 42/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0756 - accuracy: 0.9706\n",
      "Epoch 42: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0754 - accuracy: 0.9707 - val_loss: 0.2728 - val_accuracy: 0.8544 - lr: 1.2500e-04\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 0.9716\n",
      "Epoch 43: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0747 - accuracy: 0.9716 - val_loss: 0.0827 - val_accuracy: 0.9734 - lr: 6.2500e-05\n",
      "Epoch 44/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0667 - accuracy: 0.9754\n",
      "Epoch 44: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0669 - accuracy: 0.9751 - val_loss: 0.1038 - val_accuracy: 0.9663 - lr: 6.2500e-05\n",
      "Epoch 45/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0780 - accuracy: 0.9665\n",
      "Epoch 45: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0777 - accuracy: 0.9667 - val_loss: 0.0739 - val_accuracy: 0.9769 - lr: 6.2500e-05\n",
      "Epoch 46/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 0.9751\n",
      "Epoch 46: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0759 - accuracy: 0.9747 - val_loss: 0.0742 - val_accuracy: 0.9769 - lr: 6.2500e-05\n",
      "Epoch 47/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.0670 - accuracy: 0.9733\n",
      "Epoch 47: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0691 - accuracy: 0.9729 - val_loss: 0.1081 - val_accuracy: 0.9645 - lr: 6.2500e-05\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9720\n",
      "Epoch 48: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0693 - accuracy: 0.9720 - val_loss: 0.0743 - val_accuracy: 0.9769 - lr: 3.1250e-05\n",
      "Epoch 49/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0662 - accuracy: 0.9746\n",
      "Epoch 49: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0664 - accuracy: 0.9747 - val_loss: 0.0734 - val_accuracy: 0.9769 - lr: 3.1250e-05\n",
      "Epoch 50/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.0695 - accuracy: 0.9715\n",
      "Epoch 50: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0682 - accuracy: 0.9720 - val_loss: 0.0706 - val_accuracy: 0.9769 - lr: 3.1250e-05\n",
      "Epoch 51/100\n",
      "67/71 [===========================>..] - ETA: 0s - loss: 0.0728 - accuracy: 0.9743\n",
      "Epoch 51: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0720 - accuracy: 0.9747 - val_loss: 0.0713 - val_accuracy: 0.9769 - lr: 3.1250e-05\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9707\n",
      "Epoch 52: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0695 - accuracy: 0.9707 - val_loss: 0.0701 - val_accuracy: 0.9769 - lr: 3.1250e-05\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9742\n",
      "Epoch 53: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0731 - accuracy: 0.9742 - val_loss: 0.0700 - val_accuracy: 0.9751 - lr: 1.5625e-05\n",
      "Epoch 54/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9723\n",
      "Epoch 54: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0683 - accuracy: 0.9725 - val_loss: 0.0772 - val_accuracy: 0.9769 - lr: 1.5625e-05\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9742\n",
      "Epoch 55: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0644 - accuracy: 0.9742 - val_loss: 0.0733 - val_accuracy: 0.9769 - lr: 1.5625e-05\n",
      "Epoch 56/100\n",
      "67/71 [===========================>..] - ETA: 0s - loss: 0.0655 - accuracy: 0.9706\n",
      "Epoch 56: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0661 - accuracy: 0.9702 - val_loss: 0.0739 - val_accuracy: 0.9769 - lr: 1.5625e-05\n",
      "Epoch 57/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 0.9755\n",
      "Epoch 57: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0651 - accuracy: 0.9751 - val_loss: 0.0712 - val_accuracy: 0.9769 - lr: 1.5625e-05\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9716\n",
      "Epoch 58: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0680 - accuracy: 0.9716 - val_loss: 0.0729 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "67/71 [===========================>..] - ETA: 0s - loss: 0.0711 - accuracy: 0.9739\n",
      "Epoch 59: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0714 - accuracy: 0.9733 - val_loss: 0.0746 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 0.9741\n",
      "Epoch 60: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0646 - accuracy: 0.9733 - val_loss: 0.0756 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.0747 - accuracy: 0.9710\n",
      "Epoch 61: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0756 - accuracy: 0.9711 - val_loss: 0.0736 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9711\n",
      "Epoch 62: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0676 - accuracy: 0.9711 - val_loss: 0.0712 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9733\n",
      "Epoch 63: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0618 - accuracy: 0.9733 - val_loss: 0.0714 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9778\n",
      "Epoch 64: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0572 - accuracy: 0.9778 - val_loss: 0.0718 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0665 - accuracy: 0.9755\n",
      "Epoch 65: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0656 - accuracy: 0.9760 - val_loss: 0.0725 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0655 - accuracy: 0.9719\n",
      "Epoch 66: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0658 - accuracy: 0.9716 - val_loss: 0.0724 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9719\n",
      "Epoch 67: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0675 - accuracy: 0.9720 - val_loss: 0.0719 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0615 - accuracy: 0.9768\n",
      "Epoch 68: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0613 - accuracy: 0.9769 - val_loss: 0.0751 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "67/71 [===========================>..] - ETA: 0s - loss: 0.0612 - accuracy: 0.9762\n",
      "Epoch 69: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0605 - accuracy: 0.9765 - val_loss: 0.0773 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0634 - accuracy: 0.9732\n",
      "Epoch 70: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0631 - accuracy: 0.9733 - val_loss: 0.0744 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.0609 - accuracy: 0.9756\n",
      "Epoch 71: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0603 - accuracy: 0.9760 - val_loss: 0.0769 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 0.9733\n",
      "Epoch 72: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0670 - accuracy: 0.9733 - val_loss: 0.0769 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 0.9759\n",
      "Epoch 73: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0635 - accuracy: 0.9756 - val_loss: 0.0793 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 0.9724\n",
      "Epoch 74: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0638 - accuracy: 0.9729 - val_loss: 0.0754 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 0.9733\n",
      "Epoch 75: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0638 - accuracy: 0.9733 - val_loss: 0.0724 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0590 - accuracy: 0.9778\n",
      "Epoch 76: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0590 - accuracy: 0.9778 - val_loss: 0.0724 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0626 - accuracy: 0.9737\n",
      "Epoch 77: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0642 - accuracy: 0.9733 - val_loss: 0.0757 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0623 - accuracy: 0.9732\n",
      "Epoch 78: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0623 - accuracy: 0.9733 - val_loss: 0.0746 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.0651 - accuracy: 0.9733\n",
      "Epoch 79: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0638 - accuracy: 0.9738 - val_loss: 0.0752 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9746\n",
      "Epoch 80: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0605 - accuracy: 0.9747 - val_loss: 0.0736 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0647 - accuracy: 0.9710\n",
      "Epoch 81: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0638 - accuracy: 0.9716 - val_loss: 0.0744 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9720\n",
      "Epoch 82: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0609 - accuracy: 0.9720 - val_loss: 0.0748 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9765\n",
      "Epoch 83: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0595 - accuracy: 0.9765 - val_loss: 0.0739 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0607 - accuracy: 0.9751\n",
      "Epoch 84: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0607 - accuracy: 0.9751 - val_loss: 0.0753 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9706\n",
      "Epoch 85: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.0671 - accuracy: 0.9711 - val_loss: 0.0756 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9742\n",
      "Epoch 86: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0584 - accuracy: 0.9742 - val_loss: 0.0744 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9733\n",
      "Epoch 87: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0587 - accuracy: 0.9733 - val_loss: 0.0764 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.0658 - accuracy: 0.9738\n",
      "Epoch 88: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0647 - accuracy: 0.9738 - val_loss: 0.0777 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0711 - accuracy: 0.9710\n",
      "Epoch 89: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0714 - accuracy: 0.9707 - val_loss: 0.0747 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 0.9769\n",
      "Epoch 90: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0594 - accuracy: 0.9773 - val_loss: 0.0727 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0597 - accuracy: 0.9792\n",
      "Epoch 91: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0593 - accuracy: 0.9791 - val_loss: 0.0733 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0632 - accuracy: 0.9760\n",
      "Epoch 92: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0628 - accuracy: 0.9760 - val_loss: 0.0757 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9774\n",
      "Epoch 93: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0578 - accuracy: 0.9773 - val_loss: 0.0764 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.0591 - accuracy: 0.9784\n",
      "Epoch 94: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0623 - accuracy: 0.9769 - val_loss: 0.0786 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 0.9728\n",
      "Epoch 95: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0631 - accuracy: 0.9733 - val_loss: 0.0740 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 0.9759\n",
      "Epoch 96: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0583 - accuracy: 0.9760 - val_loss: 0.0744 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9756\n",
      "Epoch 97: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0587 - accuracy: 0.9756 - val_loss: 0.0739 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0570 - accuracy: 0.9763\n",
      "Epoch 98: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0576 - accuracy: 0.9760 - val_loss: 0.0757 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "68/71 [===========================>..] - ETA: 0s - loss: 0.0621 - accuracy: 0.9775\n",
      "Epoch 99: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0611 - accuracy: 0.9782 - val_loss: 0.0734 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "69/71 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9764\n",
      "Epoch 100: val_accuracy did not improve from 0.97869\n",
      "71/71 [==============================] - 1s 14ms/step - loss: 0.0602 - accuracy: 0.9765 - val_loss: 0.0738 - val_accuracy: 0.9769 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f706c13e260>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[reduce_lr, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Best CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 41ms/step - loss: 0.0896 - accuracy: 0.9643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08962170779705048, 0.9643449187278748]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_model = load_model('/tmp/CMS_CNN_1D_CheckPoint.h5')\n",
    "cp_model.evaluate(X_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = cp_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_single = CLASSES[np.argmax(y_pred, axis = -1)]\n",
    "actual_single = CLASSES[np.argmax(y_test, axis = -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(X_test)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    data = X_test[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i+1)\n",
    "    ax.plot(data)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.2, 'pred = ' + str(preds_single[idx]), fontsize=10, ha='center', transform=ax.transAxes) \n",
    "    ax.text(0.5, -0.4, 'act = ' + str(actual_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       624\n",
      "           1       0.97      0.96      0.96       582\n",
      "\n",
      "    accuracy                           0.96      1206\n",
      "   macro avg       0.96      0.96      0.96      1206\n",
      "weighted avg       0.96      0.96      0.96      1206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "y_test_classes = tf.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion MatriX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "            Legitimate  Suspicious\n",
      "Legitimate         606          18\n",
      "Suspicious          25         557\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "class_labels = ['Legitimate', 'Suspicious']\n",
    "\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (NGC 24.01 / TensorFlow 2.14) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
