{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Input, LSTM, BatchNormalization, Dropout, Dense, Add, Flatten\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Calls List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "syscalls = [\n",
    "\"sys_enter_llistxattr\",\n",
    "\"sys_enter_setgroups\",\n",
    "\"sys_enter_lremovexattr\",\n",
    "\"sys_enter_sethostname\",\n",
    "\"sys_enter_accept\",\n",
    "\"sys_enter_lseek\",\n",
    "\"sys_enter_setitimer\",\n",
    "\"sys_enter_accept4\",\n",
    "\"sys_enter_lsetxattr\",\n",
    "\"sys_enter_setns\",\n",
    "\"sys_enter_acct\",\n",
    "\"sys_enter_madvise\",\n",
    "\"sys_enter_setpgid\",\n",
    "\"sys_enter_add_key\",\n",
    "\"sys_enter_mbind\",\n",
    "\"sys_enter_setpriority\",\n",
    "\"sys_enter_adjtimex\",\n",
    "\"sys_enter_membarrier\",\n",
    "\"sys_enter_setregid\",\n",
    "\"sys_enter_personality\",\n",
    "\"sys_enter_memfd_create\",\n",
    "\"sys_enter_setresgid\",\n",
    "\"sys_enter_bind\",\n",
    "\"sys_enter_memfd_secret\",\n",
    "\"sys_enter_setresuid\",\n",
    "\"sys_enter_bpf\",\n",
    "\"sys_enter_migrate_pages\",\n",
    "\"sys_enter_setreuid\",\n",
    "\"sys_enter_brk\",\n",
    "\"sys_enter_mincore\",\n",
    "\"sys_enter_setrlimit\",\n",
    "\"sys_enter_capget\",\n",
    "\"sys_enter_mkdirat\",\n",
    "\"sys_enter_setsid\",\n",
    "\"sys_enter_capset\",\n",
    "\"sys_enter_mknodat\",\n",
    "\"sys_enter_setsockopt\",\n",
    "\"sys_enter_chdir\",\n",
    "\"sys_enter_mlock\",\n",
    "\"sys_enter_settimeofday\",\n",
    "\"sys_enter_chroot\",\n",
    "\"sys_enter_mlock2\",\n",
    "\"sys_enter_setuid\",\n",
    "\"sys_enter_clock_adjtime\",\n",
    "\"sys_enter_mlockall\",\n",
    "\"sys_enter_setxattr\",\n",
    "\"sys_enter_clock_getres\",\n",
    "\"sys_enter_mmap\",\n",
    "\"sys_enter_shmat\",\n",
    "\"sys_enter_clock_gettime\",\n",
    "\"sys_enter_mount\",\n",
    "\"sys_enter_shmctl\",\n",
    "\"sys_enter_clock_nanosleep\",\n",
    "\"sys_enter_mount_setattr\",\n",
    "\"sys_enter_shmdt\",\n",
    "\"sys_enter_clock_settime\",\n",
    "\"sys_enter_move_mount\",\n",
    "\"sys_enter_shmget\",\n",
    "\"sys_enter_clone\",\n",
    "\"sys_enter_move_pages\",\n",
    "\"sys_enter_shutdown\",\n",
    "\"sys_enter_clone3\",\n",
    "\"sys_enter_mprotect\",\n",
    "\"sys_enter_sigaltstack\",\n",
    "\"sys_enter_close\",\n",
    "\"sys_enter_mq_getsetattr\",\n",
    "\"sys_enter_signalfd4\",\n",
    "\"sys_enter_close_range\",\n",
    "\"sys_enter_mq_notify\",\n",
    "\"sys_enter_socket\",\n",
    "\"sys_enter_connect\",\n",
    "\"sys_enter_mq_open\",\n",
    "\"sys_enter_socketpair\",\n",
    "\"sys_enter_copy_file_range\",\n",
    "\"sys_enter_mq_timedreceive\",\n",
    "\"sys_enter_splice\",\n",
    "\"sys_enter_delete_module\",\n",
    "\"sys_enter_mq_timedsend\",\n",
    "\"sys_enter_statfs\",\n",
    "\"sys_enter_dup\",\n",
    "\"sys_enter_mq_unlink\",\n",
    "\"sys_enter_statx\",\n",
    "\"sys_enter_dup3\",\n",
    "\"sys_enter_mremap\",\n",
    "\"sys_enter_swapoff\",\n",
    "\"sys_enter_epoll_create1\",\n",
    "\"sys_enter_msgctl\",\n",
    "\"sys_enter_swapon\",\n",
    "\"sys_enter_epoll_ctl\",\n",
    "\"sys_enter_msgget\",\n",
    "\"sys_enter_symlinkat\",\n",
    "\"sys_enter_epoll_pwait\",\n",
    "\"sys_enter_msgrcv\",\n",
    "\"sys_enter_sync\",\n",
    "\"sys_enter_epoll_pwait2\",\n",
    "\"sys_enter_msgsnd\",\n",
    "\"sys_enter_sync_file_range\",\n",
    "\"sys_enter_eventfd2\",\n",
    "\"sys_enter_msync\",\n",
    "\"sys_enter_syncfs\",\n",
    "\"sys_enter_execve\",\n",
    "\"sys_enter_munlock\",\n",
    "\"sys_enter_sysinfo\",\n",
    "\"sys_enter_execveat\",\n",
    "\"sys_enter_munlockall\",\n",
    "\"sys_enter_syslog\",\n",
    "\"sys_enter_exit\",\n",
    "\"sys_enter_munmap\",\n",
    "\"sys_enter_tee\",\n",
    "\"sys_enter_exit_group\",\n",
    "\"sys_enter_name_to_handle_at\",\n",
    "\"sys_enter_tgkill\",\n",
    "\"sys_enter_faccessat\",\n",
    "\"sys_enter_nanosleep\",\n",
    "\"sys_enter_timer_create\",\n",
    "\"sys_enter_faccessat2\",\n",
    "\"sys_enter_newfstat\",\n",
    "\"sys_enter_timer_delete\",\n",
    "\"sys_enter_fadvise64\",\n",
    "\"sys_enter_newfstatat\",\n",
    "\"sys_enter_timer_getoverrun\",\n",
    "\"sys_enter_fallocate\",\n",
    "\"sys_enter_newuname\",\n",
    "\"sys_enter_timer_gettime\",\n",
    "\"sys_enter_fanotify_init\",\n",
    "\"sys_enter_open_by_handle_at\",\n",
    "\"sys_enter_timer_settime\",\n",
    "\"sys_enter_fanotify_mark\",\n",
    "\"sys_enter_open_tree\",\n",
    "\"sys_enter_timerfd_create\",\n",
    "\"sys_enter_fchdir\",\n",
    "\"sys_enter_openat\",\n",
    "\"sys_enter_timerfd_gettime\",\n",
    "\"sys_enter_fchmod\",\n",
    "\"sys_enter_openat2\",\n",
    "\"sys_enter_timerfd_settime\",\n",
    "\"sys_enter_fchmodat\",\n",
    "\"sys_enter_perf_event_open\",\n",
    "\"sys_enter_times\",\n",
    "\"sys_enter_fchown\",\n",
    "\"sys_enter_pidfd_getfd\",\n",
    "\"sys_enter_tkill\",\n",
    "\"sys_enter_fchownat\",\n",
    "\"sys_enter_pidfd_open\",\n",
    "\"sys_enter_truncate\",\n",
    "\"sys_enter_fcntl\",\n",
    "\"sys_enter_pidfd_send_signal\",\n",
    "\"sys_enter_umask\",\n",
    "\"sys_enter_fdatasync\",\n",
    "\"sys_enter_pipe2\",\n",
    "\"sys_enter_umount\",\n",
    "\"sys_enter_fgetxattr\",\n",
    "\"sys_enter_pivot_root\",\n",
    "\"sys_enter_unlinkat\",\n",
    "\"sys_enter_finit_module\",\n",
    "\"sys_enter_ppoll\",\n",
    "\"sys_enter_unshare\",\n",
    "\"sys_enter_flistxattr\",\n",
    "\"sys_enter_prctl\",\n",
    "\"sys_enter_userfaultfd\",\n",
    "\"sys_enter_flock\",\n",
    "\"sys_enter_pread64\",\n",
    "\"sys_enter_utimensat\",\n",
    "\"sys_enter_fremovexattr\",\n",
    "\"sys_enter_preadv\",\n",
    "\"sys_enter_vhangup\",\n",
    "\"sys_enter_fsconfig\",\n",
    "\"sys_enter_preadv2\",\n",
    "\"sys_enter_vmsplice\",\n",
    "\"sys_enter_fsetxattr\",\n",
    "\"sys_enter_prlimit64\",\n",
    "\"sys_enter_wait4\",\n",
    "\"sys_enter_fsmount\",\n",
    "\"sys_enter_process_madvise\",\n",
    "\"sys_enter_waitid\",\n",
    "\"sys_enter_fsopen\",\n",
    "\"sys_enter_process_mrelease\",\n",
    "\"sys_enter_write\",\n",
    "\"sys_enter_fspick\",\n",
    "\"sys_enter_process_vm_readv\",\n",
    "\"sys_enter_writev\",\n",
    "\"sys_enter_fstatfs\",\n",
    "\"sys_enter_process_vm_writev\",\n",
    "\"sys_enter_fsync\",\n",
    "\"sys_enter_pselect6\",\n",
    "\"sys_enter_ftruncate\",\n",
    "\"sys_enter_ptrace\",\n",
    "\"sys_enter_futex\",\n",
    "\"sys_enter_pwrite64\",\n",
    "\"sys_enter_get_mempolicy\",\n",
    "\"sys_enter_pwritev\",\n",
    "\"sys_enter_get_robust_list\",\n",
    "\"sys_enter_pwritev2\",\n",
    "\"sys_enter_getcpu\",\n",
    "\"sys_enter_quotactl\",\n",
    "\"sys_enter_getcwd\",\n",
    "\"sys_enter_quotactl_fd\",\n",
    "\"sys_enter_getdents64\",\n",
    "\"sys_enter_read\",\n",
    "\"sys_enter_getegid\",\n",
    "\"sys_enter_readahead\",\n",
    "\"sys_enter_geteuid\",\n",
    "\"sys_enter_readlinkat\",\n",
    "\"sys_enter_getgid\",\n",
    "\"sys_enter_readv\",\n",
    "\"sys_enter_getgroups\",\n",
    "\"sys_enter_reboot\",\n",
    "\"sys_enter_getitimer\",\n",
    "\"sys_enter_recvfrom\",\n",
    "\"sys_enter_getpeername\",\n",
    "\"sys_enter_recvmmsg\",\n",
    "\"sys_enter_getpgid\",\n",
    "\"sys_enter_recvmsg\",\n",
    "\"sys_enter_getpid\",\n",
    "\"sys_enter_remap_file_pages\",\n",
    "\"sys_enter_getppid\",\n",
    "\"sys_enter_removexattr\",\n",
    "\"sys_enter_getpriority\",\n",
    "\"sys_enter_renameat\",\n",
    "\"sys_enter_getrandom\",\n",
    "\"sys_enter_renameat2\",\n",
    "\"sys_enter_getresgid\",\n",
    "\"sys_enter_request_key\",\n",
    "\"sys_enter_getresuid\",\n",
    "\"sys_enter_restart_syscall\",\n",
    "\"sys_enter_getrlimit\",\n",
    "\"sys_enter_rseq\",\n",
    "\"sys_enter_getrusage\",\n",
    "\"sys_enter_rt_sigaction\",\n",
    "\"sys_enter_getsid\",\n",
    "\"sys_enter_rt_sigpending\",\n",
    "\"sys_enter_getsockname\",\n",
    "\"sys_enter_rt_sigprocmask\",\n",
    "\"sys_enter_getsockopt\",\n",
    "\"sys_enter_rt_sigqueueinfo\",\n",
    "\"sys_enter_gettid\",\n",
    "\"sys_enter_rt_sigreturn\",\n",
    "\"sys_enter_gettimeofday\",\n",
    "\"sys_enter_rt_sigsuspend\",\n",
    "\"sys_enter_getuid\",\n",
    "\"sys_enter_rt_sigtimedwait\",\n",
    "\"sys_enter_getxattr\",\n",
    "\"sys_enter_rt_tgsigqueueinfo\",\n",
    "\"sys_enter_init_module\",\n",
    "\"sys_enter_sched_get_priority_max\",\n",
    "\"sys_enter_inotify_add_watch\",\n",
    "\"sys_enter_sched_get_priority_min\",\n",
    "\"sys_enter_inotify_init1\",\n",
    "\"sys_enter_sched_getaffinity\",\n",
    "\"sys_enter_inotify_rm_watch\",\n",
    "\"sys_enter_sched_getattr\",\n",
    "\"sys_enter_io_cancel\",\n",
    "\"sys_enter_sched_getparam\",\n",
    "\"sys_enter_io_destroy\",\n",
    "\"sys_enter_sched_getscheduler\",\n",
    "\"sys_enter_io_getevents\",\n",
    "\"sys_enter_sched_rr_get_interval\",\n",
    "\"sys_enter_io_pgetevents\",\n",
    "\"sys_enter_sched_setaffinity\",\n",
    "\"sys_enter_io_setup\",\n",
    "\"sys_enter_sched_setattr\",\n",
    "\"sys_enter_io_submit\",\n",
    "\"sys_enter_sched_setparam\",\n",
    "\"sys_enter_io_uring_enter\",\n",
    "\"sys_enter_sched_setscheduler\",\n",
    "\"sys_enter_io_uring_register\",\n",
    "\"sys_enter_sched_yield\",\n",
    "\"sys_enter_io_uring_setup\",\n",
    "\"sys_enter_seccomp\",\n",
    "\"sys_enter_ioctl\",\n",
    "\"sys_enter_semctl\",\n",
    "\"sys_enter_ioprio_get\",\n",
    "\"sys_enter_semget\",\n",
    "\"sys_enter_ioprio_set\",\n",
    "\"sys_enter_semop\",\n",
    "\"sys_enter_kcmp\",\n",
    "\"sys_enter_semtimedop\",\n",
    "\"sys_enter_kexec_file_load\",\n",
    "\"sys_enter_sendfile64\",\n",
    "\"sys_enter_kexec_load\",\n",
    "\"sys_enter_sendmmsg\",\n",
    "\"sys_enter_keyctl\",\n",
    "\"sys_enter_sendmsg\",\n",
    "\"sys_enter_kill\",\n",
    "\"sys_enter_sendto\",\n",
    "\"sys_enter_landlock_add_rule\",\n",
    "\"sys_enter_set_mempolicy\",\n",
    "\"sys_enter_landlock_create_ruleset\",\n",
    "\"sys_enter_set_robust_list\",\n",
    "\"sys_enter_landlock_restrict_self\",\n",
    "\"sys_enter_set_tid_address\",\n",
    "\"sys_enter_lgetxattr\",\n",
    "\"sys_enter_setdomainname\",\n",
    "\"sys_enter_linkat\",\n",
    "\"sys_enter_setfsgid\",\n",
    "\"sys_enter_listen\",\n",
    "\"sys_enter_setfsuid\",\n",
    "\"sys_enter_listxattr\",\n",
    "\"sys_enter_setgid\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CSV from Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3\n",
    "CLASSES = np.array(['benign', 'sysrv', 'xmrig'])\n",
    "DATASET_DIR = \"dataset/\"\n",
    "VECTOR_LENGTH = 32 * 32\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(syscalls)\n",
    "\n",
    "def csvToVector(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data_encoded = label_encoder.fit_transform(data['SYSTEM_CALL'])\n",
    "    vector = np.zeros(VECTOR_LENGTH, dtype=np.uint8)\n",
    "    syscall_nums = min(len(data_encoded), VECTOR_LENGTH)\n",
    "    vector[:syscall_nums] = data_encoded[:syscall_nums]\n",
    "\n",
    "    return vector\n",
    "\n",
    "def process_file(args):\n",
    "    file_path, class_idx = args\n",
    "    vector = csvToVector(file_path)\n",
    "    return vector, class_idx\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    x = []\n",
    "    y = []\n",
    "    classes = [\"0\", \"1\", \"2\"]\n",
    "\n",
    "    file_paths = []\n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        for file_name in os.listdir(class_dir):\n",
    "            if file_name.endswith('.csv'):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                file_paths.append((file_path, class_idx))\n",
    "\n",
    "    with Pool() as pool:\n",
    "        results = pool.map(process_file, file_paths)\n",
    "\n",
    "    x, y = zip(*results)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validation, Test Split and Nomalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train / 299.0\n",
    "X_val = X_val / 299.0\n",
    "X_test = X_test / 299.0\n",
    "\n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_val = to_categorical(y_val, 3)\n",
    "y_test = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1359, 1024)\n",
      "(729, 1024)\n",
      "(340, 1024)\n",
      "(1359, 3)\n",
      "(729, 3)\n",
      "(340, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(VECTOR_LENGTH, 1))\n",
    "\n",
    "x = LSTM(32, return_sequences=True)(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = LSTM(64, return_sequences=True)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = LSTM(128, return_sequences=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "output_layer = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1024, 1)]         0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 1024, 32)          4352      \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 1024, 32)          128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1024, 32)          0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 1024, 64)          24832     \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 1024, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 1024, 64)          0         \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               98816     \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163715 (639.51 KB)\n",
      "Trainable params: 162755 (635.76 KB)\n",
      "Non-trainable params: 960 (3.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='/tmp/LSTM_checkpoint.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.7271 - accuracy: 0.6505\n",
      "Epoch 1: val_accuracy improved from -inf to 0.48529, saving model to /tmp/checkpoint.h5\n",
      "43/43 [==============================] - 12s 143ms/step - loss: 2.7271 - accuracy: 0.6505 - val_loss: 2.5172 - val_accuracy: 0.4853 - lr: 0.0010\n",
      "Epoch 2/50\n",
      " 1/43 [..............................] - ETA: 4s - loss: 2.2056 - accuracy: 0.7188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 2.4021 - accuracy: 0.7071\n",
      "Epoch 2: val_accuracy did not improve from 0.48529\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 2.4021 - accuracy: 0.7071 - val_loss: 2.3493 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.0785 - accuracy: 0.7432\n",
      "Epoch 3: val_accuracy did not improve from 0.48529\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 2.0785 - accuracy: 0.7432 - val_loss: 2.2124 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.9696 - accuracy: 0.7366\n",
      "Epoch 4: val_accuracy did not improve from 0.48529\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 1.9696 - accuracy: 0.7366 - val_loss: 2.0807 - val_accuracy: 0.4853 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.8414 - accuracy: 0.7307\n",
      "Epoch 5: val_accuracy did not improve from 0.48529\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 1.8414 - accuracy: 0.7307 - val_loss: 2.0117 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.6369 - accuracy: 0.7609\n",
      "Epoch 6: val_accuracy did not improve from 0.48529\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 1.6369 - accuracy: 0.7609 - val_loss: 2.0038 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.5484 - accuracy: 0.7807\n",
      "Epoch 7: val_accuracy did not improve from 0.48529\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 1.5484 - accuracy: 0.7807 - val_loss: 1.9296 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.4833 - accuracy: 0.7513\n",
      "Epoch 8: val_accuracy did not improve from 0.48529\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 1.4833 - accuracy: 0.7513 - val_loss: 1.8227 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.3724 - accuracy: 0.7667\n",
      "Epoch 9: val_accuracy did not improve from 0.48529\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 1.3724 - accuracy: 0.7667 - val_loss: 1.8040 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.2521 - accuracy: 0.7925\n",
      "Epoch 10: val_accuracy did not improve from 0.48529\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 1.2521 - accuracy: 0.7925 - val_loss: 2.0269 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.2128 - accuracy: 0.7829\n",
      "Epoch 11: val_accuracy did not improve from 0.48529\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 1.2128 - accuracy: 0.7829 - val_loss: 1.7172 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.1010 - accuracy: 0.8006\n",
      "Epoch 12: val_accuracy did not improve from 0.48529\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 1.1010 - accuracy: 0.8006 - val_loss: 1.5622 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 1.0415 - accuracy: 0.7925\n",
      "Epoch 13: val_accuracy did not improve from 0.48529\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 1.0415 - accuracy: 0.7925 - val_loss: 1.8926 - val_accuracy: 0.4176 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.9987 - accuracy: 0.8021\n",
      "Epoch 14: val_accuracy improved from 0.48529 to 0.68529, saving model to /tmp/checkpoint.h5\n",
      "43/43 [==============================] - 5s 107ms/step - loss: 0.9987 - accuracy: 0.8021 - val_loss: 1.2016 - val_accuracy: 0.6853 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.9324 - accuracy: 0.8175\n",
      "Epoch 15: val_accuracy did not improve from 0.68529\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.9324 - accuracy: 0.8175 - val_loss: 2.5889 - val_accuracy: 0.6147 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.8965 - accuracy: 0.8072\n",
      "Epoch 16: val_accuracy did not improve from 0.68529\n",
      "43/43 [==============================] - 4s 105ms/step - loss: 0.8965 - accuracy: 0.8072 - val_loss: 1.5109 - val_accuracy: 0.6382 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.8737 - accuracy: 0.7962\n",
      "Epoch 17: val_accuracy did not improve from 0.68529\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.8737 - accuracy: 0.7962 - val_loss: 1.3470 - val_accuracy: 0.6647 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.8452 - accuracy: 0.8028\n",
      "Epoch 18: val_accuracy did not improve from 0.68529\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.8452 - accuracy: 0.8028 - val_loss: 1.2653 - val_accuracy: 0.6618 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.7692 - accuracy: 0.8197\n",
      "Epoch 19: val_accuracy did not improve from 0.68529\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.7692 - accuracy: 0.8197 - val_loss: 1.1761 - val_accuracy: 0.4265 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.7407 - accuracy: 0.8219\n",
      "Epoch 20: val_accuracy improved from 0.68529 to 0.79118, saving model to /tmp/checkpoint.h5\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 0.7407 - accuracy: 0.8219 - val_loss: 0.8801 - val_accuracy: 0.7912 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.7376 - accuracy: 0.8241\n",
      "Epoch 21: val_accuracy did not improve from 0.79118\n",
      "43/43 [==============================] - 4s 105ms/step - loss: 0.7376 - accuracy: 0.8241 - val_loss: 1.6797 - val_accuracy: 0.6441 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.7156 - accuracy: 0.8116\n",
      "Epoch 22: val_accuracy did not improve from 0.79118\n",
      "43/43 [==============================] - 4s 105ms/step - loss: 0.7156 - accuracy: 0.8116 - val_loss: 1.4763 - val_accuracy: 0.6353 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6587 - accuracy: 0.8271\n",
      "Epoch 23: val_accuracy did not improve from 0.79118\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.6587 - accuracy: 0.8271 - val_loss: 1.1069 - val_accuracy: 0.6882 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6681 - accuracy: 0.8212\n",
      "Epoch 24: val_accuracy did not improve from 0.79118\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.6681 - accuracy: 0.8212 - val_loss: 1.2400 - val_accuracy: 0.4235 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6672 - accuracy: 0.8168\n",
      "Epoch 25: val_accuracy improved from 0.79118 to 0.80588, saving model to /tmp/checkpoint.h5\n",
      "43/43 [==============================] - 5s 107ms/step - loss: 0.6672 - accuracy: 0.8168 - val_loss: 0.6886 - val_accuracy: 0.8059 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6499 - accuracy: 0.8175\n",
      "Epoch 26: val_accuracy did not improve from 0.80588\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.6499 - accuracy: 0.8175 - val_loss: 1.1776 - val_accuracy: 0.6735 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6024 - accuracy: 0.8403\n",
      "Epoch 27: val_accuracy did not improve from 0.80588\n",
      "43/43 [==============================] - 4s 105ms/step - loss: 0.6024 - accuracy: 0.8403 - val_loss: 1.1189 - val_accuracy: 0.6912 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.6457 - accuracy: 0.8116\n",
      "Epoch 28: val_accuracy did not improve from 0.80588\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.6457 - accuracy: 0.8116 - val_loss: 0.6467 - val_accuracy: 0.7912 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5848 - accuracy: 0.8278\n",
      "Epoch 29: val_accuracy did not improve from 0.80588\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5848 - accuracy: 0.8278 - val_loss: 0.6577 - val_accuracy: 0.7912 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.8322\n",
      "Epoch 30: val_accuracy did not improve from 0.80588\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5688 - accuracy: 0.8322 - val_loss: 0.6704 - val_accuracy: 0.7853 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5731 - accuracy: 0.8286\n",
      "Epoch 31: val_accuracy did not improve from 0.80588\n",
      "43/43 [==============================] - 4s 105ms/step - loss: 0.5731 - accuracy: 0.8286 - val_loss: 0.9680 - val_accuracy: 0.6824 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5893 - accuracy: 0.8212\n",
      "Epoch 32: val_accuracy improved from 0.80588 to 0.82059, saving model to /tmp/checkpoint.h5\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 0.5893 - accuracy: 0.8212 - val_loss: 0.6041 - val_accuracy: 0.8206 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5687 - accuracy: 0.8293\n",
      "Epoch 33: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5687 - accuracy: 0.8293 - val_loss: 1.2538 - val_accuracy: 0.6676 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5366 - accuracy: 0.8374\n",
      "Epoch 34: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5366 - accuracy: 0.8374 - val_loss: 0.6638 - val_accuracy: 0.7529 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5494 - accuracy: 0.8337\n",
      "Epoch 35: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5494 - accuracy: 0.8337 - val_loss: 1.3204 - val_accuracy: 0.6647 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.8286\n",
      "Epoch 36: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5611 - accuracy: 0.8286 - val_loss: 2.0163 - val_accuracy: 0.6265 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.8403\n",
      "Epoch 37: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5259 - accuracy: 0.8403 - val_loss: 0.7319 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5129 - accuracy: 0.8521\n",
      "Epoch 38: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 0.5129 - accuracy: 0.8521 - val_loss: 0.5939 - val_accuracy: 0.8088 - lr: 5.0000e-04\n",
      "Epoch 39/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.8550\n",
      "Epoch 39: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.4922 - accuracy: 0.8550 - val_loss: 0.5719 - val_accuracy: 0.7912 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4940 - accuracy: 0.8543\n",
      "Epoch 40: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.4940 - accuracy: 0.8543 - val_loss: 0.5343 - val_accuracy: 0.8176 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.8447\n",
      "Epoch 41: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5066 - accuracy: 0.8447 - val_loss: 1.2970 - val_accuracy: 0.3176 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5870 - accuracy: 0.7954\n",
      "Epoch 42: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5870 - accuracy: 0.7954 - val_loss: 0.9252 - val_accuracy: 0.7294 - lr: 5.0000e-04\n",
      "Epoch 43/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5077 - accuracy: 0.8425\n",
      "Epoch 43: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5077 - accuracy: 0.8425 - val_loss: 1.1521 - val_accuracy: 0.4176 - lr: 5.0000e-04\n",
      "Epoch 44/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5798 - accuracy: 0.7962\n",
      "Epoch 44: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5798 - accuracy: 0.7962 - val_loss: 1.6005 - val_accuracy: 0.4147 - lr: 5.0000e-04\n",
      "Epoch 45/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5716 - accuracy: 0.8035\n",
      "Epoch 45: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5716 - accuracy: 0.8035 - val_loss: 1.3823 - val_accuracy: 0.4176 - lr: 5.0000e-04\n",
      "Epoch 46/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5285 - accuracy: 0.8175\n",
      "Epoch 46: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 4s 105ms/step - loss: 0.5285 - accuracy: 0.8175 - val_loss: 1.0752 - val_accuracy: 0.4176 - lr: 2.5000e-04\n",
      "Epoch 47/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5245 - accuracy: 0.8278\n",
      "Epoch 47: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5245 - accuracy: 0.8278 - val_loss: 1.2226 - val_accuracy: 0.4176 - lr: 2.5000e-04\n",
      "Epoch 48/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5397 - accuracy: 0.8160\n",
      "Epoch 48: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5397 - accuracy: 0.8160 - val_loss: 1.2558 - val_accuracy: 0.4176 - lr: 2.5000e-04\n",
      "Epoch 49/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5234 - accuracy: 0.8315\n",
      "Epoch 49: val_accuracy did not improve from 0.82059\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.5234 - accuracy: 0.8315 - val_loss: 0.9778 - val_accuracy: 0.4618 - lr: 2.5000e-04\n",
      "Epoch 50/50\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.5227 - accuracy: 0.8249\n",
      "Epoch 50: val_accuracy improved from 0.82059 to 0.82941, saving model to /tmp/checkpoint.h5\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 0.5227 - accuracy: 0.8249 - val_loss: 0.6843 - val_accuracy: 0.8294 - lr: 2.5000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fcbf4335780>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[reduce_lr, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.6863 - accuracy: 0.8381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6863484978675842, 0.8381344079971313]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_model = load_model('/tmp/LSTM_checkpoint.h5')\n",
    "cp_model.evaluate(X_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 2s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = cp_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_single = CLASSES[np.argmax(y_pred, axis = -1)]\n",
    "actual_single = CLASSES[np.argmax(y_test, axis = -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKkAAAIyCAYAAAAAMpkEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPbElEQVR4nO3deZQdZZ0//s/N0tk6CwkRAoQkAkIEApE9LMGRgMsAURiQyXwJgoJKBscBjSviRMWjzsj3iDDjLAkzivIVhEEQB0RRh02WsMgSAlkAAUMgBLJ2kn5+f/BLk046t9fbdavq9Ton56Tv+tz63Kp66l1PPbeSUkoBAAAAABnqk3UDAAAAAEBIBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZK5f1g2g/q1avzGuue+5OGzCyPiX3y2K19Y0ReOAfvHQc6/F2g2b4ntnTI7nXl0b//PYS/Hg0hXxvv13jvuXrIj/++HJce/iV2Jjc4qRgxti/abmeP9+O8f18/8UA/r1iS//92NxzlETYsXqpnhh5do4buJOLe85/9nX4rkVa+KgcTvEYRNGxT2LXon/fuhPsWLNhrhyxrti0fLV8dyra2Ln4QNj6MD+ccxeO8a1Dzwf//K7RXHiAbvEHqOHRCUq8crq9fGfdy+NA8eOiJffWB/fOnVS/OfdS+J/HvtzDB/UPz4+dY+465nlcfC4kfHMy6ti5JCGWLdhU+y989BIKaJxQL/45989E0fvuWPcu/jV2H/X4TFxzLBIEXHrYy/FiQfsEo8+vzIOGrdDrGnaGLvtMDi+eMOjceSeO8Y/nXZgZjWrpd8+9XJ8+YY/xryPHBJvH90YERE3zP9T9O/bJz4wacw2j79jwbJ4fsXamHHY7lGpVCIi4tHnV8bdi5bH/zl8fAxq6BuvrWmKL1z/aDz2wutx/rv3jHfv/bb40JV3xi7DB8UHJ+8aq5s2xRmHjo3BDV3fZP3xTyvjrmeWx98cPq7N10kpxeeuezQeeu61eOcuw+JtwwbEBX+xVyxftT4+9p/3x5yT94vD3j6qy+9fTzZsao4f3bM0jtprx9jzbUOzbg6wlf+6e0lc+8Dz8dWT94sDx47Iujn0oJRS/PgPz8V+uw6LSbuNiBWrm+K6B5+PPUY3xqLlqyMiYkhD32ja1BxNG5tjYP++MWxQ/1j2+rrYbYdB8eLKddGcIgY39I2NzSnWb9gUA/r1if59+8Tqpk1RiTf7Lm+s3xgREUMH9IvVTRu3ec7OwwfGitVNsX5jc4wZPiiWr1ofGzY1x6CGvhERsbZpU/Tv2ydGDx0QL7y2NibsOCSefXVN1ffe/H5bv/em5hSDG/pFc0qxbovnrGnaFAteeiM2pRSTdhseA/v3jTfWbYxKRAwZ0DfWbWhuadNOQwfGce/caZvlWW+eePH1uH/JqzHjsHHRp08l6+ZQY3c9szxefmN9nHzgrlk3hR6w4KU34p5Fr8SMw3aPfn2N5clSJaWUsm4E9e0zP304fvrA81k3I3f+5++Oib13Ll4AMP5zN7f8f8k3PxDLXl8Xh37j9oiIePgrx8fwQf1b7k8pxYTP/yIiIq77xBFx0LiRERFx8Ndui+WrmuJLH5gYHz367fGRuX+I3yx4uer7njVlfFxy0r5dbvfh37g9Xnp9Xcx+7z7xiWP32Ob+B5auiFOuvKvVbWccunv8+A/Ptvy95Jsf6PL715N//d2i+PovnoiI4nwmKIqVazbEAf9wa0REDOrfN56Y896MW0RPuvWxl+Lc/3ogIt7c/v6ff783fr9wecatyocn/uG9LSFavdrcR/rWKZPitEPGZtwaam1zvX/191Njz7c1ZtwaumtzPedM3y/+z+HjMm5NuYkIadfvFlYPD2jbCyvXZt2EXrH57GlExPoNm7b7uJffWN/y/+WrmiIi4pHnV0ZEtBtQRUTc/cwrXW1iRES89Pq6iIh46LkV22nfum1uu/PpYh44zN/OMgCy98b6DS3/X1tlm0o+PfXnN1r9LaDquKaNzVk3ocMee2Fl1k2gF/359W37kOTXo8+/lnUTSk9IRbsqYbgyAAAAUFtCKiAXKj2UlQpdAQAA6pOQinb1VDhQNhZbzzJ7Xs8R1AEAAPVISAV0S7XfXshTsJSntgIAABSRkIp2GXPRNRVD0Lay7fLozCLqscv9lAUAAKAuCalol7AFAHqHfS7kn/W4XFS7WEyLkT0hFdRItcvgiqr6J9723hIuovpg3wsAANQhIRVAlOwyQOEgADmTcrTzKuOJSiiKPG1rikpIBZRKqcIoAOqKy8AAoDohFe3Sn6Kaauca8nQeolQnPbdap3/5xxfj1CvviudXrMmmPQAAOVWmLiT0BiEV0Eu69+t+1M7Hf/hg3L90RXz+Z49m3RQAAKDEhFRAqfjFju1buXZD1k2A0rOFgvxzWWe5qHaxOFbInpCKdtnPQrFYpQEAgHokpKJd0mTqQY+dlfR1BgAAqEtCKqBbtpxwfOvJx/0EMwAAAB0lpIIaEc8AAABAx/XLugHUP3NSwZtWrt0QkSIG9O8TA/v3zbo5Pc7ANwCATnKsBD1KSEW7bHfhTQd89daW/9/yqaNj4phhGbYGAACgWFzuB5RKT4Wu373tqR56JQAAACKEVEC3bf8asTxdPZantnZXj/1SIgAAQA8SUtEuB7T0hLa+Rp35ZvXUt9D3GQCAHlOmM53QC4RUtMshPQAAAFBrJk6nfVIqSqBMX/PtfdbkVCAAQJtWrd8Yf3v1g7HH6MYYM2LQW3eUqRMJvUBIBbVSwuP9aiFHauOuEi4igKpckQxQn/7h54/Fbxa8HL9Z8HLWTaGG7Iez53I/gC4oYsBWcSoQAKBNv1+4POsmQCkIqWiXw1aqaWuEVFv3dfesRE+d1dj+pW4AAECZVTu2oXcIqWiXX0OjVvL8zcpz2wEgbxw4ApSDkAooFZkrAABAfRJS0S7H9FAOft0PAKBzzOkJPUtIBbVif0WdMpoM6peDHQDIjn5y9oRUtMuK2kUlGZRS7WMamQMAAEBHCamgRsoY0JRpUtMSfVQAAIBeIaSiXS49oB701Ig+32bLAACgp5TxxDTUkpAKoGR0pQAAOqdMVwxAloRUtMucVF1jBFp9qvTQF7qI1dX5Aqgtfaqus+yoV/r80LOEVFAjhv5Sr3SlALLhZEDXWXZkTVAKvUNIBSW2fuOm+NINj8b4z90cF/x4fkREpJTiu7c9Fb95clmHXqNap3HL+7LYr//0/ufiP+9e0uq26+f/KU66/H/j+RVrWt2u86vzBQAAZEtIBSU2984l8cN7no2IiBsffiEeef61+J/H/hz/9/aF8ZF599X8/Ttz6V1nh1Jvak7xmWsfiYv/+7F4aeW6Vvc98vzKOPPf/9Cp1wMAAKC2hFRQI3kYmbPo5VWt/n5ldVO88NrajFrTs5q3KMDqpo3b3L9o+epWf3d2FFEOyrtdPTUvFwBAWeShbw9FIKSiXQ5ou6aMi63avrut+5K9PQAAOVbGPj/UkpCKdtnudo38pX6oRcdYTgAAbRNGQe8QUkGJtTXPU+cve+tYstHd/XqtOwYCGqAeOAiC/LMeQ35Zf7MnpIIayesGrjfDms5cStqddtWiFjktLwAAQN0SUtGuvIYtdEFBRxMZJQVAPdCnguLRzywW9cyekIp26VAVV1u1rdd6d7ZddfoxAIAuyNNxo4NcgK4TUtGutuYton257KAUqNS1Xvx5LO9mBSozAECm6vUEL+SVkApqJJchVRfaXO1zbnlfZ+afAgAAoHyEVFAjzTlIqXo6N0pVPnO1+6gPSgTZE+dD/jkvV0zb6yfd+fTy3m0INWX9zZ6QinZZUbvml398KesmdF4d17qOm5Y/FiYAQKe89Pq6Nm//3q+f7uWWQLEJqaBGnl+xNusmdF6BRtIYFdR5AmkAACBLQiqgFTlFx+R6OQnwAACAOiSkAlqRXwBAbfjFZACoTkgFdEvVX/fbIvIq2q/75TrMK1YpACgBuy6AchBS0S5z+xTZtl2+3uwEduq9OhlypXzHSJmwrgPUln1T11lyAOUgpIIa0REFAACAjuuXdQOofwW7SosaqnrpXxt3dibGe/i51+L8Hz0YzSlF/759Yu2GTRER0bdSiYZ+b/29WdPG5pb/P/L8a22+5uvrNsSwgf070YpiMCcKQDYWv7w66ybk1ur1G2PkkIasmwFAjQmpoMR6OoB8+uVVMXbk4Dbvu/2JZXH8vju3uu36+X+K755+YIdf/+ZHX+xSu/7+/z3c5u2TLrk1FnztvTGgX98uvS4AdMZPH3g+6ybk1tHf+k088433R98+TrQAFJnL/WiXeWqoZsvLGm9+pHWItOV355r7n+utJnXKstfXR4TLMwGg3q3fuKn9BwGQa0IqgC7I83lcl/ACQO24rB6g64RUUCN56KC01cKKBKND8jzuanujI/P8maAwbIIBIEN2xFkTUgGttDXBecef24MNAQAAoFSEVFAj5jjKh83BWh5GvgEAALXkGC5rQiqokTyMKmrryr7OXu635efc+qk5WAQtyhQqbq/EYjoA6L4y9SkAepqQCugxeQjmAIB80s8AKD4hFdRIHuYf7+nOnjOHAEDZmUIAoOuEVLRL8ADFsr2uszUdsufgFgCyZD+cNSEVlFgeRnsBAABQDkIqqBHzJuSDkYIAAAD1QUhFu1x6QFclSR0AAAAdJKSiXUaaFFePB5C+KgBAjehmABSfkAooNSMFAYCeZM5PgK4TUgEtjJrruDxfybi9zrPLMyF7Dm7Lwza3uJQWoOuEVFBibR0Mle0AqevBnB4o0PMc3ML2layLQh1pbrZxht4ipKJdOszl0ZVL37b8fmz9VcnTV8f3HACAtlw//09ZNwFKQ0gFtHC5X2c4nwsAUAaPvfB61k2A0hBS0a6yXf5VJluXdsXqDZm0g961vRFzFSs7AHXMqTSA4hNSQYk9v2Jtq7+/8YsnWv29ePnq3mxOzuS3q2zEHADUjnM+AF0npKJd5urpmjwstnUbN7X6+5XVTa3+XtvU+v4i2vz91qH0S1NQD2yLACA79sPZE1IB3VJtVE6eMo88tbW7ujJBPgBAWQkuoPcIqaBGyrgvK9NInCJ+1HUbij9yDqBeFHE/ApB3ts3ZE1JBjZRx+1bGz1wkS15Zk3UTAACAEhNSQYm1ddnXlreYYLuYDFkHII/KNGIboKyEVECPkX0AAADQVUIqoMc4vwnQPcJ+AMiOKw6yJ6SCGsnD9q0nNsJVR95LrQAAAOggIRXtcvl/1xRhsak9AAAAvUVIBTVics9iU10AusN+pPMqrsMhI7550HuEVLRLf6BkSlbwrh4kCCEBoHfZ9wIUn5AKaG2LDmBn8yp9x3woWQ4JAL3KbrZ4dHGh9wipaJfgoWvKMiQ9bef/b/6dny9PfloKAABQTEIqKLE2g7QtbhNQbl9eQsgnX3o91jZtanXbc6+uzag1AFB8uk/Fk49eHxRDv6wbAGSnp+d2sAOvLzc+/EJc8OP5ERGx5JsfiIiI+5a8Gv/79PIsmwUAANAmI6mAHpPHM4ebg7oiBmybA6ot/dfdSzNoCQAAQPuEVFAjefgFmrxcslaP8lDftuSz1QAAQBkIqaDElr6yOusm5FZew57mnIZrAEWT15MdWcrLEnMKsHic14XeI6SCElv6ypptbvv5Qy906jWqdbLz0P/ePJosB03tEQ6KAACgbfLI7AmpgFb+sOTVrJtADTU3Z90CAIB8cY4Peo+QiqoeWLoiHn/x9aybQU7kcZROHtvcHak0Y8YAAKBz9JSzJ6SiqlOuvCvrJgA9qNmeFwCgU8xJBb1HSAX0GPlH/SvbyDEAACA/hFRAt1SLPIoch+Q168lruwEAgOITUkGNlDELMBK6/jVLqQDqgq0xQP1xPJO9flk3ACiOPHa489jmrvjGL56IiIjfLHg545YAAORLxaRU0GuEVABdkLdw6we/W5R1EwAAcsmcntB7XO4HNVLE8y3t7qDtv+vWO8cMi3OPeXuMGzU466YAAAC0SUgFbFdHThpVe0yezjrlqa1dceiEkfGF90+Mz79vYtZNAQAAaJOQCmqk2JEHeRspZyoFAPIuL+eT7HOLx5xU0HuEVABdkJN+cotK7mI1AACgbIRUAFH8M2R9iv3xAKBu5GXEF0A9ElIBPSblbnxR1+VtDqs+UirIhXxtWeiOnO1GAKBXCKmADtOhzi8RFQBA1+hHQe8RUgHd9FZytfW8R3nKtPI2Mqqzin45IwBArbTXSyx6PxJ6k5AKaqSM+6oyXe6XN5uv9pNVAZBbOelm2NcCdJ2QCugxeQzm8tjmrtBhBgDoGt2o8tBnzl6/rBsARWUDRz3p08Ev5PjP3VzjltS/86a+PT7/volZNwMAAErHSCooqedXrGn3MS7fKw5zUnXcv/x2UdZNAAAgA2W5yqKeCamgRup9A7epufMNbOsZ1T5nvS+DMhFRAdQXJ4K6wM4MoPCEVAAl0NHL/QAA2IpuFPQaIRVQcuU4ky2jAiD3yrHLph757kGvEVIBPaZMl/fl7bP2+f9Dqry1GwCg3ulfFYcTu9kTUgHbZYe7fXmbS8TE6QAAQL0TUgEdltpIrapFNfkIcsoR3sioAAC6SD8Keo2QCtiuzgYb+QilekYlZ70VE6cDAAD1TkgFlFw5grU+LRlVOT4vAEBvuWfxK1k3AQpDSAVslzmpimPzyC81BagPtsedl5cR2+aBLJ/Fy1dn3QQoDCEV1Eg+ulF0Vb13lLeeP2x7/eWHn3ut9o0BAMixvE3zAHkmpAIooJlz72vz9qZNza3+Pvn7d/ZGcwAAcqu9k5NGRkLPEVIBHdbW/rfqTrnAO+x674z87qmXW/29985DIyLijXUbW92+64hBvdYmoH31vm0B2tfWryED0DFCKqDUytKPHD9qSJu33/m5v+jllgAAALRNSAU1UoQr1zub35Ql8AEAoDzMSQW9R0gFAADUvbwEBX7dD6DrhFRQIwYVAQD0nHr/ZV0g//IShheZkApqpYDXvrX1kbacHHTru4u3BAAAAKgVIRWwXe2dR5j/7IpeaQfd58oDAACozojN7AmpoFYKkAq0t4n+4BV3RdOm5l5pS70p4EA5AACATAmpgG5Zt6GkIVVOz7Lks9UAAPVL/wp6jpAK6JbUi0OKlnzzAy3/v2LGu1r9/a1TJ8WSb36g5R8AAAD5IqQCumXLiGrrvKqW+dXWF1N29+JKl+8BQH2zryYrBZjFgw7y637ZE1IBHdbWJW6tR1L1Xu9x685CpYu9h6622A4MAACgZwmpgO3qyKV89XJWs7uRUdHPkLWEePVSMICSszkGgG0JqaBWStL7bP0pezPpKXiqBABAPpSk3w+9QUgFdEtW++RtL/fr3ffP66/7AQAA1CshFdAtrcOaXpyTauu/ezukymtGVfTrGgEgY/a0AF0npAK6pVpYU8vRRltPlN7Vicw3tz+3oRMAlIRdNUDxCamADmsryGmuk3THAKHqWhZPndQLAKAwdEShxwipgFzSFQCKyHx3kH/W4uLR74TeI6QCumXLgTm9OUinp05YOfEFQBYEkgCwLSEV0C1ZdbK3/XW/7qVNwioAALrEdArQY4RUUCN7jG7Mugm9otVIqir39bStJ0rvasbU1YnT89oVyWu7ASAvnPcqH/0r6DlCKqiRo9+xY9ZN6LaO7HCb62SvbCQUABRbMloFqDHHFNkTUkGNbD3Sp6i27DD26ifu4Tcr+twgdrids37jpqybAAAApSOkghopeuiRta0zl7KEggAAQG0YsJk9IRXQLWk7/6+17k6U3m12YAAAAD2qX9YNALJx3YN/avcxH7riroiI+Nknp8S7dt+hzcd89tpHWv7/6yeXxfjP3bzd12vrvmqPr2abkVRdzKxOuOx3273v2VfXdO1FAQAojKzPjUKZGEkFZdWJsaybw6osfeuUSRERcdC4HWLYwH5xyPiRERExZY9R0TigXxzzjtG92yCdFQC6wSUlALAtI6mgrLpwSiirDvVTX3tfNPR7M1P/6XlHxKaUon/fN//+0UcPiw2bUsv9veXUg3br1fcDgLKT6wG1ZtRc9oRUUFY5OoW7ZQDVp08l+mwxjKlSqURDv97fmwxu6Nvr79kdmyeWz1HZAQCAknG5H9SIMKDY1BcAAKBnCamgrIxlhe0SQgIAQO8TUgEAAEAXObkFPUdIBXRYMmUpJWGgIQBdZh8C0GVCKoASELoA1BenfSA/Ku0kj8lQKugxQiooKZkFAJAncgCA4hNSQY3oSAEAlJA+IECXCamgpFz+BVCHHNyWhsuDoDgqOtbQY4RUACXioAgAAKhXQiqgw+QbAADtMKgGoMuEVAAloL/cOQJZAIDy0WfOnpAKoAtkGADQu5K9L3XKdArQc4RUACWiC9Ux5j8Fas32GPJDv6A8bJuzJ6SCGqn3DVzFYNZusfQAAIio/34/5ImQCgAAALbD1XzQe/p158kppVi7YVNPtaWUBvXvGxXjR8kJ++f8s7XJP/ve7qvnfe+jf1rZ6u/xn7u55f+/vnBqvH10Y283CQCg13QrpFq7YVO88+L/6am2lNLj/3BCDG7oVhmgS+r0+Cw3chfYqXdh2Pd2Xz3vexcuW7Xd+/7iH38bS775gV5sDQAR+s1lotTZc7kflJQNcDnlLlwDKJAdGxuybkKuDerfN+smQJv0q6HndOs04qD+fePxfzihp9pSSna2AHSGfW/32feSHYey3TF0YP+smwBtchIQek63QqpKpVK3w+Uha6nOZ1is79ZBtup59bXvhWKo5+0MAGTF5X5Ah9V78AaQd8bZFJt5bcqhYk0uHBWF3iOkgpKysy2XzR1mOSMAAFCvhFQAsBWjHYCac9IAcsPqCr1HSAUAAL1A/g0A1QmpAAAAYDsEzNB7hFRQUi5nAoDe5ZIhKCZzfkLPEVJBjRRxX1XEzwQAWUj2qlAY1mboOUIqKKmKoVTdknJ2yky5Oydn5QVywqYYism6XRyOkbInpAIAgF7g2AdyysoLvUZIBdAFzrIAAJSEIdalkberJYpISAVQIna7UN/k3wBAmQmpgA5zYgEAgNJxBgF6jZAKakWgU2iGAgMAbZFnlI9eIfQcIRVACegvA2SvYmsMUNfMO5s9IRUAQJ0QYpSHAbnFpbYAXSekAgCAXuAEPeSTVRd6j5AKSkpHGQAAgHoipIKS6tIlJYavA0CPsEuF/LC+Qu8RUkGNJLsz6pBfJQTIjkHM5WC0OkDXCakASsAvlUA+WFUB6k97m2YnAaHnCKnYrqaNzVk3Idd+eM+zWTcBAAAAckNIxXZtanZGoDse/dPKrJsAANQpIy8AYFtCKrarb59KNA7ol3UzAAAKwaXXAFCdkIrtaujXJ67+2GFZN4M6YjJ4AADKRr4MvUdIRVUVv0MDhWBNBgDoGlfnQu8RUkFJOSME26czCgAAvU9IRVWCjOJSWgAAAOqJkAoAAAC2w4l76D1CKqDDXAIFAABArQipoKScEQKA7DjvAwDbElJRlSCjuIyKKhfrMkD2bIvLQZkBuk5IBVAiwkkAgM6piB6h1wipqMoGGQB6T8VQG8g954OKJ6kq9BohFZSU4yDYPp1RoBa23Pca2QrFYX2GntMv6wZQ3wQZbPa3P54fTRs3Zd0Musk6DQAA1CshFVU5oGWznz/8QtZNoAc40wcA0DmmQIHeI6SCkurszvYrJ74zIiLuX7oibn7kxVo0iRrSuQKoLy4rLi57XICuE1JRlQPb4urMKLkj9xwVHzlyQkRETNptuJAKoEbsdYtNvwqKydUn0HNMnA4AAL3AgSwAVCekoiqdKbZmTqM3WQ4AAAA9S0gFtEsgUxzmQAEA6Fn6ytBzhFRUZSAVWzO67k25Ww55ay+UVO62LQA4CQg9SEgFtMtBE2XjjChZ8d0DAMpMSEVVwgki/BoRAADl5ZioPNQ6e0IqoF2GMG/LaAcAusV+BAC2IaSiHaJktuY7AQBdYQ8KxbRy7Yasm0APcSI6e0IqKKmKsawAdcemGaD+9OtbfeP8/d8800stgeITUlGVzjLbcnohj6zLAABd867dd8i6CVAaQiqgXYa9FodaAmRny1HMNsfF5cRQ8ey36/CsmwClIaSiKvvY4up6bX0rInRAAQCgaPTxsyekgpLqzBlcG+ttGZEE1ILNLUD9sW2G3iOkoiqTaxMRUbFrpmRkkECtOdlRXGoL0HVCKqBdySF7YagkAEDnOG8PvUdIRVW2x8XV1draSeeTsgFkb8tt8YZNzZm1A4C3LF6+uuX/jzy/Mh5+7rVY+Oc3IhkWmQkhFdApttX5JqwCqA+f+NEDWTeBGnFCD/LlG794ouX/DyxdESd//86Y9t3fxX/evTTDVpWXkIqq7GSLS227xyWQQC2YC7I8/vin17NuAtBB5mctth0bG1r9PXRAv4iIWPTyqiyaU3pCKqBdRk8BAABFdOmHJrX6+yNHjs+mIUSEkIp2OGtQXOak6p68rhvyRgCAztH/LSf95mwIqYB22THnn0uIAOqATTEAVCWkoirHtUTkd9QQdJVfcyEr9rsAkDE740wJqYB2mSR8W5YJUAvy0YJTX4DcsE/OhpAK6BTnFfLNzhYAAKhXQiqqMtKx64q67GQcAACUSVH79bRNubMlpAIAgN7gyAcgN0zvkQ0hFVX5RbDi6kxtXSKWf5urbZWG+mYdBQDKTEgFNVLvxxldPRCq98/VW/L6i4cCRwCAzslrv4+uccIoW0IqqrJ+QtsM/wUA2iLQgGJwcjcbQiqokSJdKlmgjwIAAECdElJRlXACKCMnzsiK3W6xqS/kk2OicjEaMltCKqiRet+0dbV9RRohBgDQ00wJAMVgTc6GkIqqpMhsLbk4O5c2Z4s6zgAAneOICHqPkApKSlTRPbI6AAAoHheOZEtIRVVW0K4r0rITyAAAdIwrEaAYHANlQ0gFJWVOqu6xGICasHEpNPtQyCfrLvQeIRVV2Rx3nbNoAAAA+eIoLltCKqiVet+6deKMkJNH+Sc0BQDoGr2osnK9XxaEVFRniwxtco16sakvAAD0PiEVlFSX56Tq0VYAsCXbWADIlqtIsiWkoiqXCLE1A0zyzQghgOzoVUE+CS3KSb85G0IqqBH7MgA6S3+42NQXAKoTUlGVswZEOIsAAEB5VRwUlYp6Z0tIBTVS1G1bQT9Wp+WtvnlrLwAAZMmJ+mwIqajKcW3Xmc+r2Oy0gFqw5wAAykxIBbTLKBwA6D67UwCoTkhFVa7HLS6lBQDoefpYUAzJz11kQkhFVfaxxeVyRKhCnwQAAHqdkApqxFk0ADrLvgMAslOp2BdnTUhFVVZQaJuJ0wGAtugjQDFYl7MhpIIaKVK+ZwMNAN3n5B8AVCekoirzFhVXVzvKOthvshwAAKBYKuEYOGtCKgAAgB7iRBbkV9rO/+k9Qiqqs5Ptskqd91A6cwlfnX8U2nDZ6Qe2eXtqo/D77Dy0xq0BOsrZWwCgzIRUACUgaAQAgOoqod+cNSEVVVlBu67eF53adk+RJpMv0mcBqGdGygHkhz5yNoRUUCt13g+t8+ZRI21dhiqw3FYyCwEAAPQ6IRVVOXaFYmlrTiqgfgiNASA7lYoxr1kTUgHtkmsAAABlYmR9NoRUVFXvv1BH13W1tM4tvMmqAdSCkwIAQJkJqaBGZBjFlrcDSeEiAABU59f9siekoirrJxE21HnUmZoZMQkAANH6Ar+cnZQuCiEV1IgDf+pR3kaAQdnYdQAAZSakoiqd5a6z7AAAAPKjEqbJyJqQCgC2YsQZAF3l8BaKQXcwG0IqqpIiQ9uKtNOylgP0DqOsAaA6IRWUVGcCSKNK8s+BEeSDVRUAslOp6DdnTUhFVVbQrqv7RdfFBvpOvMliAACA4krO1GdCSAU14tf9AADKx2EtQNcJqQAAAIDSMydz9oRUACXS1tldg/4AoOfYrUJ+pS16y0ZFZkNIRVUOXourM6X1PdhW3nZaSgj5YHsLAJSZkIqqDHfsOksOAAAgPypRMbdwxoRUACVnP7ytvI2UAwCgZ/lxv2wIqajKwWvXFWnZ2UADQPc5Ow8A1QmpoGZ0RIssr9X9wKQxWTcBqMJl9gCQoUp++/lFIaSiKisotC2vg8v2GN2YdRMAoNiMmINCyGt/P++EVAAlUO0SEyM3AKAHmScBoMuEVFRl7gQoPqs51I/kvC0AZKYS+sZZE1JBjdT7xq0zAWS9fxa6xwlfAABofYlf0knOhJCKqmQTkE9GQUI+ufwWACgzIRXUiMOMYqv3MyudaZ88CwB6kB0r5FYlHMdlTUhFVfaxXVekZVfneQzdVKCvao+p9xASAIDa0hvMhpAKauTovUZn3YSquhpMFCl86468XU6Xr9YCAABlJKSiqrwdiNeTS07aN+smVOXMAJv5LkAdsdstNOWFYjj7yAnRxwpdSJWKY+CsCamgRhoH9Mu6CZRYp369sYbtAAAoku+dMTkuPvGd8Y6dhmbdFGrNmdxMCKkAys7ZIgAAoA4IqaCkOhNLyDC2ZWJtAIDy0QMstkpUWo59kmpnQkgFUHYCNwAAEEzVASEVQAkYDQf5YFUtNttiyD+rMdSWkApol4E2BeeoaRu+8gBAW/QRiq0SlZYg0jFQNoRUUFJdzSUqzh9FRLF+mrY4nwQAoHcIMKA2hFQAXWDidAAAKJZKJVxlkDEhFUDJidugfhRplCaUlbW42JyoLA+lzoaQCkrqbUMHdvixk3Yb0fL/YYP61aA19LStO8gOfAGyZ1MMANUJqaCkpuwxqsOPnfUXe7b8f7cdBseQhr61aFKbbr9wapee9/Gpe7T6+2efnNITzSkkx0wA0HMMvoD8qoS+cdYMiYCS6tOn7c3vnOn7xf85fFzV5z72D++tRZN61NCBb23elnzzA9vcf9Hx74jv3PpURET81UG7xbf/6oBYvX5j7PuV/+m1NgJszWUkxaa8APmRRM6ZMJIKoAvssgAAAHqWkAoovSLOEbL7yMEdfuzhb+/4pZ9AbZk/DvLJKMjyMcqmuOyKsyWkAkqv0oUrz+t933XA2BExfFD/Dj32747bq8atyZ+B/Xtv3jWgPBz4lIMyQzHInrMhpAJKr6gHDf91zqEdepxAZluNA0zZCABsS3ABtSWkAkqvqCEVAAC10ZWR+NS/SqWithkTUgHYEQF1wtYIIB/MSVV8KpwNIRVQel0ZSWWnBQBQPsIpqC0hFVB6mzMql/0BUEsuISku8xRBMVTCMUHWhFRA6RV1R6TDDADQs/SvykOtsyGkAlor8da4xB8dAIBO0G+E2hBSAaVU2WL4VFcuv8jD4KuijhCDIrPeAkC27IqzJaQCSiltcfrLxOkAAHTEuFGDI8JJhXLQ489Cv6wbANSZEu5xTZwOQG+wn4H8uu4TR8Sil1fHQeNGZt0UKDQhFVB6lYIeNZgrAQB6h11u8R00bmSrgEo/q6AqTihkzeV+AAB1QscY8s96DMUgiMyGkAoAAACAzAmpgNJzxhMAAKhE1375m54jpAJK69SDdouIiLOPnBAREYP69+3wc0945841aRMAxeWwpxxcIgTFYFXOhonTgdL6zl8dEN/44P7R0O/NvL5SqcQz33h/rN+4KSLe7GT27VOJvn0q0bSxOTY2v7mrGtS/b8tzAKCjHPAAQHVCKqDUtg6b+vapxOCGbTeN/fvmL5RyMAQAvSMZPgXFYdhrpvJ31AUAAFCnzHUJxSB8zoaQCgAAADpBfAG1IaQCAIBeYIANQH2rVPy2X9aEVAAFZQcL+aNrDAD1wWi5bAipAAAAAMickAqgoLZ39ufIPUdFRMS8jxzSctsVM97VCy3Kh+kH7pJ1EwDIGSMuoBgqlTcv+SM72/7OOgCF9qOPHr7Nbe/ff0ws+eYHMmgNAADUHz/ulw0jqQAAoDc4Ow8AVQmpAADqhAwDIB+SYTaFZVecLSEVAAAAwBbEkNkQUgEUlDN8AAC1YXJtqA0hFQAAQDc4LwTFUAmX3mdNSAUAAL3AcU85VFS6FIxYLz41zoaQCgAAAIDMCakAAACA0qtUKi73y1i/rBsAAEDHfOMXT2TdhLo27Z07xSHjR2bdDErutideitVNG7NuRq7stsOgOPOI8Vk3o1tsn7fvuIk7xaET8rdtXvTyanXtgFl/sWcMG9i/x15PSAW0sseOQ7JuQo94x05Dt7ltQL8+sX5jc0RE7NXG/UUzeuiArJsAdNLYkYOr3v+D3y3qpZbk05jhA+s6pJqyx6h46LnXsm4GNfbHP70ef/zT61k3I1cOHrdD7kKqI/fcMZ55eXXL37bP27fTsIF1H1LtMnxgvLByXRyz144xpOHNmORPr61V1w44+8gJQip613WfOCIWvbw6Ju02Ii658bEY1dgQgxv6xu8XLo+mjc1x+V+/K/6w+NX4t98vimn77hQREU+8+EaceMCYuO6B5+P0Q8bG7iMHx+trN8aE0UNi8cur4+o/PBtNG5vjgvfsFf9x5+JY9vq6+Nr0/WPpq6tjbdOmePj5lfH0slXxvv12jrEjB8VND78Ytz+5LMaOHBQXHb93/Pn1dbHo5dUxsH/fuO3xP8e/n3Vw/PMdz8QND70QJx+4S9yz6JX4wP67xKLlq+KOBS/HPjsPjZ2GDYwv/+XEmHX1/HjypTfiXbuPiBMP2CWufeD5OHDsiBg6sH+sXLshKpWIY/YaHctXrY8Hlq6ITc0pGvr1iedXrIkdGwfEh961azz6/OvxhyWvxJF77hivrGqKpa+siYgUz726NkYOaYgvvH9itkXroJ/POip+dO/SeOcuw2L+s6/F6KEDYsqeO2bdrB5x3MS3xTc+uH/st+uwltt+9fdT47u/eir23WV4HP/OnTJsXe/YbYfBcflfT44RgxqybgrQQZPHjoi/OXz3+H/3Px+nHzw2/uuepS33zThs9xgyQNetmv12HZ51E6r6+LF7xJMvvRGPvbAy3rffmJh315LM2tK/byU2bHpzUuA+lYjmOp4f+O2jh8TXp++fdTOq6lOJ+MtJY+KmR16MM48YFwP79826Sbmy2w6Dsm5Cp33uffvEK6ua4uZHX4yPHjUh+vRxjdj27F/n2+aIiOs+OSV+8ehLcdrBu0VDvz7xpQ9MjGVvrM+6WbkweEDPbu8qyZT1AAAAAGTMxOkAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZE5IBQAAAEDmhFQAAAAAZK6uQ6rx48fHZZddlnUzesSSJUuiUqnEQw89lHVT6k6R6kxralts6lsMta7jWWedFdOnT6/Z6292ySWXxIEHHljz98kb9S2PIm2T9Zutu0WnvsWltt1X1yFVkYwdOzZefPHF2G+//bJuCgAUzkUXXRS333571s2gRtS3XPSbi8O6W2zqW1xZ1rbmIVVTU1Ot36LuNTU1Rd++fWPnnXeOfv36Zd2cmlDnN23YsCHrJvQ4tX1TEWsbob6b5b2+6hjR2NgYo0aNyroZNaG+xa7vltS6WP1m9Sz2uqu+xa2v2mZb206FVMcee2zMmjUrZs2aFcOHD48dd9wxvvzlL0dKqeUx48ePjzlz5sSZZ54Zw4YNi3PPPTciIv73f/83jj766Bg0aFCMHTs2Lrjggli9enXL85YtWxYnnnhiDBo0KCZMmBA/+tGPeugjtm3dunWx7777trQvIuKZZ56JoUOHxn/8x39ERMS8efNixIgRcdNNN8Xee+8dgwcPjlNPPTXWrFkTV111VYwfPz522GGHuOCCC2LTpk1Vl0Fbw5ZvvPHG2GuvvWLgwIHx7ne/O6666qqoVCrx2muv1fSzt6dIdY6IuOOOO+LQQw+NIUOGxIgRI+LII4+MpUuXxpIlS6JPnz5x//33t3r8ZZddFuPGjYvm5uZYsWJFzJgxI0aPHh2DBg2KvfbaK+bOnRsRbw1Fv+aaa2Lq1KkxcODAuPLKK2PQoEFxyy23tHrN66+/PoYOHRpr1qyp+eetRm2LW9sI9S1KfYtWx82++tWvxujRo2PYsGHx8Y9/vFUHsLm5OS699NKYMGFCDBo0KA444IC49tprW+6/4447olKpxO233x4HH3xwDB48OKZMmRILFixoeczWw9I3btwYF1xwQYwYMSJGjRoVs2fPjpkzZ7YaIn/sscfGBRdcEJ/97Gdj5MiRsfPOO8cll1xSy8WgvgWv75aKVGv95mLVc0vW3bfeU32LWV+1zWFtUydMnTo1NTY2pk996lPpySefTD/84Q/T4MGD0w9+8IOWx4wbNy4NGzYsfec730lPP/10y78hQ4ak7373u+mpp55Kd955Z5o8eXI666yzWp73vve9Lx1wwAHp7rvvTvfff3+aMmVKGjRoUPrud7+73fb88Ic/TEOGDKn673e/+912nz9//vzU0NCQbrjhhrRx48Z0+OGHpw9+8IMt98+dOzf1798/TZs2LT344IPpt7/9bRo1alQ6/vjj02mnnZYee+yx9POf/zw1NDSkn/zkJ1WXweLFi1NEpPnz56eUUlq0aFHq379/uuiii9KTTz6ZfvzjH6ddd901RURasWJFZ8rS44pU5w0bNqThw4eniy66KD399NPp8ccfT/PmzUtLly5NKaU0bdq09MlPfrLVcyZNmpQuvvjilFJK559/fjrwwAPTfffdlxYvXpxuu+22dOONN6aUUktNx48fn6677rq0aNGi9MILL6RTTz01/c3f/E2r1zzllFO2uS0Lalvc2qakvkWpb5HqmFJKM2fOTI2Njen0009Pf/zjH9NNN92URo8enb7whS+0POZrX/ta2meffdIvf/nL9Mwzz6S5c+emAQMGpDvuuCOllNJvfvObFBHpsMMOS3fccUd67LHH0tFHH52mTJnS8hpf+cpX0gEHHNDqNUeOHJl+9rOfpSeeeCJ9/OMfT8OGDUsnn3xyq2U9bNiwdMkll6SnnnoqXXXVValSqaRbb721I6XqEvUtdn23VLRal73fXLR6WndbU9/i1ldt81fbTodUEydOTM3NzS23zZ49O02cOLHl73HjxqXp06e3et4555yTzj333Fa3/f73v099+vRJa9euTQsWLEgRkf7whz+03P/EE0+kiKha4Ndffz0tXLiw6r81a9ZU/Uzf+ta30o477phmzZqVxowZk5YvX95y39y5c1NEpKeffrrltvPOOy8NHjw4vfHGGy23nXDCCem8886rugy23tnOnj077bfffq0e88UvfrFuQqqi1PmVV15JEdGyQm7tmmuuSTvssENat25dSimlBx54IFUqlbR48eKUUkonnnhi+shHPtLmczfX9LLLLmt1+/XXX58aGxvT6tWrU0oprVy5Mg0cODDdcsst2/2MvUVti1vblNS3KPUtUh1TerMzNXLkyJblmlJKV155ZWpsbEybNm1K69atS4MHD0533XXXNp/njDPOSCm91Zn61a9+1XL/zTffnCIirV27NqW0bWdqp512St/+9rdb/t64cWPafffdt+lMHXXUUa3e95BDDkmzZ8/e7ufpLvV96/MUsb5bKlqtUyp3v7lo9bTutqa+b32eotVXbd/6PHmpbacv9D788MOjUqm0/H3EEUfEP/7jP8amTZuib9++ERFx8MEHt3rOww8/HI888kir4W8ppWhubo7FixfHU089Ff369YuDDjqo5f599tknRowYUbUtQ4cOjaFDh3b2I7Ry4YUXxg033BCXX3553HLLLdtcdzl48ODYY489Wv7eaaedYvz48dHY2NjqtmXLlrV63tbLYGsLFiyIQw45pNVthx56aFc/Ro8rSp1HjhwZZ511Vpxwwgkxbdq0OO644+K0006LMWPGRETE9OnT4/zzz4/rr78+PvzhD8e8efPi3e9+d4wfPz4iIj7xiU/EKaecEg8++GAcf/zxMX369JgyZUqr99h6Obz//e+P/v37x4033hgf/vCH47rrrothw4bFcccd16XP0NPUdnxEFLO2EepblPoWpY6bHXDAATF48OBWn2fVqlXx3HPPxapVq2LNmjUxbdq0Vs9pamqKyZMnt7pt0qRJLf/f/F1YtmxZ7L777q0et3Llyvjzn//car/at2/fOOigg6K5uXm7r7n5dbfep/c09S12fbdUtFqXvd9ctHpad1tT3+LWV23zVduaTJw+ZMiQVn+vWrUqzjvvvHjooYda/j388MOxcOHCVjuyzvrRj34UjY2NVf/9/ve/r/oay5Yti6eeeir69u0bCxcu3Ob+/v37t/q7Uqm0edvWxdl6GRRRXuo8d+7cuPvuu2PKlClxzTXXxDve8Y645557IiKioaEhzjzzzJg7d240NTXF1VdfHWeffXbLc9/3vvfF0qVL49Of/nS88MIL8Z73vCcuuuiiqsuhoaEhTj311Lj66qsjIuLqq6+O008/PVeTf6pt28uhCLWNUN/tLYe81TcvdWzPqlWrIiLi5ptvbtX2xx9/vNX8CRGt98mbO5tb7387qyP79Cyob7Hru6U81Vq/uX15qmc11t22qW9x66u29VPbTve877333lZ/33PPPbHXXnu1JJBtede73hWPP/547Lnnnm3ev88++8TGjRvjgQceaDlLsmDBgnYnQjzppJPisMMOq/qYXXfdter9Z599duy///5xzjnnxMc+9rE47rjjYuLEiVWf0xP23nvv+MUvftHqtvvuu6/m79tRRavz5MmTY/LkyfH5z38+jjjiiLj66qvj8MMPj4iIj370o7HffvvFFVdcERs3bowPfehDrZ47evTomDlzZsycOTOOPvro+MxnPhPf+c53qr7fjBkzYtq0afHYY4/Fr3/96/ja175W9fG9SW3fUrTaRqjvlvJc36LV8eGHH461a9fGoEGDIuLNz9PY2Bhjx46NkSNHxoABA+LZZ5+NqVOnVn2djho+fHjstNNOcd9998UxxxwTERGbNm2KBx98sNUkoFlR3+6p9/puqWi1Lnu/uWj1tO62pr7dU8/1Vdvu6e3adjqkevbZZ+Pv//7v47zzzosHH3wwvve978U//uM/Vn3O7Nmz4/DDD49Zs2bFRz/60RgyZEg8/vjjcdttt8Xll18ee++9d7z3ve+N8847L6688sro169f/N3f/V3LQt+e7g6V+/73vx933313PPLIIzF27Ni4+eabY8aMGXHPPfdEQ0NDl1+3I84777z4p3/6p5g9e3acc8458dBDD8W8efMiIloNRcxKUeq8ePHi+MEPfhAnnXRS7LLLLrFgwYJYuHBhnHnmmS2PmThxYhx++OExe/bsOPvss1u15+KLL46DDjoo9t1331i/fn3cdNNNHeqMHXPMMbHzzjvHjBkzYsKECe1uiHqT2r6piLWNUN/N8l7fotRxs6ampjjnnHPiS1/6UixZsiS+8pWvxKxZs6JPnz4xdOjQuOiii+LTn/50NDc3x1FHHRUrV66MO++8M4YNGxYzZ87s0nv+7d/+bVx66aWx5557xj777BPf+973YsWKFfaxW1Hf2ipSrfWbi1XPCOvu1tS3uPVV23zVttOX+5155pmxdu3aOPTQQ+P888+PT33qU61+jrYtkyZNit/+9rfx1FNPxdFHHx2TJ0+Oiy++OHbZZZeWx8ydOzd22WWXmDp1anzoQx+Kc889N972trd1/hN10JNPPhmf+cxn4oorroixY8dGRMQVV1wRy5cvjy9/+cs1e9/NJkyYENdee2387Gc/i0mTJsWVV14ZX/ziFyMiYsCAATV///YUpc6DBw+OJ598Mk455ZR4xzveEeeee26cf/75cd5557V63DnnnBNNTU2tLheKePPyn89//vMxadKkOOaYY6Jv377xk5/8pN33rVQqccYZZ8TDDz8cM2bM6NHP1F1q+6Yi1jZCfTfLe32LUsfN3vOe98Ree+0VxxxzTJx++ulx0kkntfpJ4jlz5sSXv/zluPTSS2PixInx3ve+N26++eaYMGFCl99z9uzZccYZZ8SZZ54ZRxxxRDQ2NsYJJ5wQAwcO7IFP1D3qW+z6bqkotdZvflNR6rmZdbc19S1ufdU2X7WtpJRSRx987LHHxoEHHhiXXXZZjzeEiK9//evxz//8z/Hcc89l2o4y1nnOnDnx05/+NB555JGsm1JTalts6lsMZaxjb2hubo6JEyfGaaedFnPmzMmsHepbG/VS3y2pdW31dr9ZPWujXtZd9a2Neqiv2tZGLWtbn7PBlsQVV1wRhxxySIwaNSruvPPO+Pa3vx2zZs3KulmlsmrVqliyZElcfvnldTe3EN2jtsWmvrRn6dKlceutt8bUqVNj/fr1cfnll8fixYvjr//6r7NuGj1AfctHv7kYrLvFpr7F1Zu1rcmv+9ExCxcujJNPPjne+c53xpw5c+LCCy9sNUyP2ps1a1YcdNBBceyxx25zuRD5prbFpr60p0+fPjFv3rw45JBD4sgjj4xHH300fvWrX/XKJM/UnvqWj35zMVh3i019i6s3a9upy/0AAAAAoBaMpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpAIAAAAgc0IqAAAAADInpKqBJUuWRKVSiYceeijrpkAunXXWWTF9+vSav88ll1wSBx54YM3fB8rCults6ltcalts6gv5VNZ1N/OQqt4WSE8YO3ZsvPjii7Hffvtl3ZS6UcQ6l1HR6njRRRfF7bffnnUz6lrRal5WRaujdbc19S0utS029S2fotW8rIpWx3pbd/tl3YCiaWpqioaGhth5552zbgo1tmHDhujfv3/WzaAbGhsbo7GxMetm0Musu/ln3S029S0utS029S0n/ar8q7d1t9sjqX75y1/GUUcdFSNGjIhRo0bFX/7lX8YzzzzT6jHPP/98nHHGGTFy5MgYMmRIHHzwwXHvvffGvHnz4qtf/Wo8/PDDUalUolKpxLx587rbpG2sW7cu9t133zj33HNbbnvmmWdi6NCh8R//8R8RETFv3rwYMWJE3HTTTbH33nvH4MGD49RTT401a9bEVVddFePHj48ddtghLrjggti0aVPL64wfPz7mzJkTZ555ZgwbNizOPffcNi/3u/HGG2OvvfaKgQMHxrvf/e646qqrolKpxGuvvdbjn7cW8lDniIg77rgjDj300BgyZEiMGDEijjzyyFi6dGksWbIk+vTpE/fff3+rx1922WUxbty4aG5ujhUrVsSMGTNi9OjRMWjQoNhrr71i7ty5EfHWJZzXXHNNTJ06NQYOHBhXXnllDBo0KG655ZZWr3n99dfH0KFDY82aNTX5jN2Rlzpu9tWvfjVGjx4dw4YNi49//OPR1NTUcl9zc3NceumlMWHChBg0aFAccMABce2117bcf8cdd0SlUonbb789Dj744Bg8eHBMmTIlFixY0PKYrc+CbNy4MS644IKW5TN79uyYOXNmq2G2xx57bFxwwQXx2c9+NkaOHBk777xzXHLJJbVcDN2Sl5pbd6vLSx03s+52jvoWt75qW9zaRqhv0evblrzUXL+qurzUcbPSrbupm6699tp03XXXpYULF6b58+enE088Me2///5p06ZNKaWU3njjjfT2t789HX300en3v/99WrhwYbrmmmvSXXfdldasWZMuvPDCtO+++6YXX3wxvfjii2nNmjVtvs8Pf/jDNGTIkKr/fve73223nfPnz08NDQ3phhtuSBs3bkyHH354+uAHP9hy/9y5c1P//v3TtGnT0oMPPph++9vfplGjRqXjjz8+nXbaaemxxx5LP//5z1NDQ0P6yU9+0vK8cePGpWHDhqXvfOc76emnn05PP/10Wrx4cYqINH/+/JRSSosWLUr9+/dPF110UXryySfTj3/847TrrrumiEgrVqzobgl6RR7qvGHDhjR8+PB00UUXpaeffjo9/vjjad68eWnp0qUppZSmTZuWPvnJT7Z6zqRJk9LFF1+cUkrp/PPPTwceeGC677770uLFi9Ntt92WbrzxxpRSaqnp+PHj03XXXZcWLVqUXnjhhXTqqaemv/mbv2n1mqeccso2t9WLPNQxpZRmzpyZGhsb0+mnn57++Mc/pptuuimNHj06feELX2h5zNe+9rW0zz77pF/+8pfpmWeeSXPnzk0DBgxId9xxR0oppd/85jcpItJhhx2W7rjjjvTYY4+lo48+Ok2ZMqXlNb7yla+kAw44oNVrjhw5Mv3sZz9LTzzxRPr4xz+ehg0blk4++eSWx0ydOjUNGzYsXXLJJempp55KV111VapUKunWW2/tSklqLg81t+62Lw91TMm621XqW9z6qm1xa5uS+ha9vm3JQ831q9qXhzqmVN51t9sh1dZefvnlFBHp0UcfTSml9C//8i9p6NCh6ZVXXmnz8VsvkO15/fXX08KFC6v+296XY7Nvfetbaccdd0yzZs1KY8aMScuXL2+5b+7cuSki0tNPP91y23nnnZcGDx6c3njjjZbbTjjhhHTeeee1/D1u3Lg0ffr0Vu+zdUg1e/bstN9++7V6zBe/+MVchVRbq8c6v/LKKykiWlbIrV1zzTVphx12SOvWrUsppfTAAw+kSqWSFi9enFJK6cQTT0wf+chH2nzu5ppedtllrW6//vrrU2NjY1q9enVKKaWVK1emgQMHpltuuaXdz1oP6rGOKb25QR45cmTLck0ppSuvvDI1NjamTZs2pXXr1qXBgwenu+66q9XzzjnnnHTGGWeklN7aIP/qV79quf/mm29OEZHWrl3b5ufZaaed0re//e2Wvzdu3Jh23333bTbIRx11VKv3PeSQQ9Ls2bPbXS71oB5rbt3tvHqsY0rW3Z6ivsWtr9oWt7YpqW/R69uWeqy5flXn1WMdUyrvutvtOakWLlwYF198cdx7772xfPnyaG5ujoiIZ599Nvbbb7946KGHYvLkyTFy5Mhuvc/QoUNj6NCh3XqNCy+8MG644Ya4/PLL45ZbbolRo0a1un/w4MGxxx57tPy90047xfjx41tdn7nTTjvFsmXLWj3v4IMPrvq+CxYsiEMOOaTVbYceemhXP0Ym8lDnkSNHxllnnRUnnHBCTJs2LY477rg47bTTYsyYMRERMX369Dj//PPj+uuvjw9/+MMxb968ePe73x3jx4+PiIhPfOITccopp8SDDz4Yxx9/fEyfPj2mTJnS6j22rvX73//+6N+/f9x4443x4Q9/OK677roYNmxYHHfccV36DLWWhzpudsABB8TgwYNb/j7iiCNi1apV8dxzz8WqVatizZo1MW3atFbPaWpqismTJ7e6bdKkSS3/3/xdWLZsWey+++6tHrdy5cr485//3Grd7Nu3bxx00EEty6mt19z8ultvF+pFHmpu3W1fHuq4mXW389S3uPVV2+LWNkJ9i17ftuSh5vpV7ctDHTcr47rb7TmpTjzxxHj11VfjX//1X+Pee++Ne++9NyKi5TrJQYMGdfctIiLiRz/6UcuEXtv79/vf/77qayxbtiyeeuqp6Nu3byxcuHCb+7ee8K1SqbR529bFGTJkSBc/VX7kpc5z586Nu+++O6ZMmRLXXHNNvOMd74h77rknIiIaGhrizDPPjLlz50ZTU1NcffXVcfbZZ7c8933ve18sXbo0Pv3pT8cLL7wQ73nPe+Kiiy5q9fpb17qhoSFOPfXUuPrqqyMi4uqrr47TTz89+vWrz98kyEsd27Nq1aqIiLj55pvjoYceavn3+OOPt7oGO6L1el2pVCIitlmHO6sj24V6kZeaW3ery0sd22PdbZv6Fre+alvc2kaob9Hr25a81Fy/qrq81LE9RV13u/WteeWVV2LBggXxr//6r3H00UdHRMT//u//tnrMpEmT4t/+7d/i1VdfbTOJbGhoaDUR+facdNJJcdhhh1V9zK677lr1/rPPPjv233//OOecc+JjH/tYHHfccTFx4sR237u79t577/jFL37R6rb77ruv5u/bU/JW58mTJ8fkyZPj85//fBxxxBFx9dVXx+GHHx4RER/96Edjv/32iyuuuCI2btwYH/rQh1o9d/To0TFz5syYOXNmHH300fGZz3wmvvOd71R9vxkzZsS0adPisccei1//+tfxta99rd3PmYW81fHhhx+OtWvXtuwk7rnnnmhsbIyxY8fGyJEjY8CAAfHss8/G1KlT221PRwwfPjx22mmnuO++++KYY46JiIhNmzbFgw8+mNufmM1bza27bctbHa27naO+1eW5vmpbXZ5rG6G+7cl7fduSt5rrV7Utb3Us47rbrZBqhx12iFGjRsUPfvCDGDNmTDz77LPxuc99rtVjzjjjjPjGN74R06dPj0svvTTGjBkT8+fPj1122SWOOOKIGD9+fCxevDgeeuih2G233WLo0KExYMCAbd6ru0Plvv/978fdd98djzzySIwdOzZuvvnmmDFjRtxzzz3R0NDQ5dftiPPOOy/+6Z/+KWbPnh3nnHNOPPTQQy2/ALA5xaxneanz4sWL4wc/+EGcdNJJscsuu8SCBQti4cKFceaZZ7Y8ZuLEiXH44YfH7Nmz4+yzz26Vkl988cVx0EEHxb777hvr16+Pm266qUMh5jHHHBM777xzzJgxIyZMmNDuhigreanjZk1NTXHOOefEl770pViyZEl85StfiVmzZkWfPn1i6NChcdFFF8WnP/3paG5ujqOOOipWrlwZd955ZwwbNixmzpzZpff827/927j00ktjzz33jH322Se+973vxYoVK3KxnrYlLzW37laXlzpuZt3tHPVtX17rq7bty2ttI9S3I/Jc37bkpeb6VdXlpY6blXLd7e6kVrfddluaOHFiGjBgQJo0aVK64447UkSk66+/vuUxS5YsSaecckoaNmxYGjx4cDr44IPTvffem1JKad26demUU05JI0aMSBGR5s6d290mbeOJJ55IgwYNSldffXXLbStWrEhjx45Nn/3sZ1NKb06cPnz48FbPa2tCtJkzZ7aaMGzcuHHpu9/9bqvHbD1xekop/fd//3fac88904ABA9Kxxx6brrzyylaTldW7PNT5pZdeStOnT09jxoxJDQ0Nady4ceniiy9u+ZWGzf793/89RUT6wx/+0Or2OXPmpIkTJ6ZBgwalkSNHppNPPjktWrQopdR2Tbf02c9+NkVEy69i1Ks81DGlt9aziy++OI0aNSo1Njamj33sYy0TPKaUUnNzc7rsssvS3nvvnfr3759Gjx6dTjjhhPTb3/42pfTWJIFb/jjB/PnzU0S0TAy59Tq+YcOGNGvWrDRs2LC0ww47pNmzZ6e/+qu/Sh/+8IdbHjN16tT0qU99qlV7Tz755DRz5syeXgw9Ig81t+62Lw91TMm621XqW9z6qm1xa5uS+ha9vm3JQ831q9qXhzqmVN51t5JSSjXKv6ji61//evzzP/9zPPfcc1k3pXTmzJkTP/3pT+ORRx7JuinUuebm5pg4cWKcdtppMWfOnKybU3rWXTrKults6ltcalts6ltf9KvoqN5ed+tzJrMCuuKKK+KQQw6JUaNGxZ133hnf/va3Y9asWVk3q1RWrVoVS5Ysicsvv7xur5EmW0uXLo1bb701pk6dGuvXr4/LL788Fi9eHH/913+dddNKzbpLe6y7xaa+xaW2xaa+9Um/ivZkve52+9f96JiFCxfGySefHO985ztjzpw5ceGFF8Yll1ySdbNKZdasWXHQQQfFscce2+oXLGCzPn36xLx58+KQQw6JI488Mh599NH41a9+1Ss/sMD2WXdpj3W32NS3uNS22NS3PulX0Z6s112X+wEAAACQOSOpAAAAAMickAoAAACAzAmpAAAAAMickAoAAACAzAmpAAAAAMickAoAAACAzAmpAAAAAMickAoAAACAzAmpAAAAAMjc/wddtMXEgewMwAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(X_test)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    data = X_test[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i+1)\n",
    "    ax.plot(data)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.2, 'pred = ' + str(preds_single[idx]), fontsize=10, ha='center', transform=ax.transAxes) \n",
    "    ax.text(0.5, -0.4, 'act = ' + str(actual_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.78      0.86       376\n",
      "           1       0.75      0.98      0.85       293\n",
      "           2       0.77      0.50      0.61        60\n",
      "\n",
      "    accuracy                           0.84       729\n",
      "   macro avg       0.83      0.75      0.77       729\n",
      "weighted avg       0.86      0.84      0.84       729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "y_test_classes = tf.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        Benign  Sysrv  Xmrig\n",
      "Benign     293     74      9\n",
      "Sysrv        5    288      0\n",
      "Xmrig        8     22     30\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "class_labels = ['Benign', 'Sysrv', 'Xmrig']\n",
    "\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (NGC 24.01 / TensorFlow 2.14) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
