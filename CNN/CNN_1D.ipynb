{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Flatten, Dense, Conv1D, MaxPooling1D\n",
    "from keras.layers import  BatchNormalization, LeakyReLU, Dropout, Activation\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "syscalls = [\n",
    "    \"sys_enter_setgroups\",\n",
    "    \"sys_enter_sethostname\",\n",
    "    \"sys_enter_accept\",\n",
    "    \"sys_enter_lseek\",\n",
    "    \"sys_enter_setitimer\",\n",
    "    \"sys_enter_accept4\",\n",
    "    \"sys_enter_setns\",\n",
    "    \"sys_enter_acct\",\n",
    "    \"sys_enter_madvise\",\n",
    "    \"sys_enter_setpgid\",\n",
    "    \"sys_enter_add_key\",\n",
    "    \"sys_enter_mbind\",\n",
    "    \"sys_enter_setpriority\",\n",
    "    \"sys_enter_adjtimex\",\n",
    "    \"sys_enter_membarrier\",\n",
    "    \"sys_enter_setregid\",\n",
    "    \"sys_enter_arm64_personality\",\n",
    "    \"sys_enter_memfd_create\",\n",
    "    \"sys_enter_setresgid\",\n",
    "    \"sys_enter_bind\",\n",
    "    \"sys_enter_memfd_secret\",\n",
    "    \"sys_enter_setresuid\",\n",
    "    \"sys_enter_bpf\",\n",
    "    \"sys_enter_setreuid\",\n",
    "    \"sys_enter_brk\",\n",
    "    \"sys_enter_mincore\",\n",
    "    \"sys_enter_setrlimit\",\n",
    "    \"sys_enter_capget\",\n",
    "    \"sys_enter_mkdirat\",\n",
    "    \"sys_enter_setsid\",\n",
    "    \"sys_enter_capset\",\n",
    "    \"sys_enter_mknodat\",\n",
    "    \"sys_enter_setsockopt\",\n",
    "    \"sys_enter_chdir\",\n",
    "    \"sys_enter_mlock\",\n",
    "    \"sys_enter_settimeofday\",\n",
    "    \"sys_enter_chroot\",\n",
    "    \"sys_enter_setuid\",\n",
    "    \"sys_enter_clock_adjtime\",\n",
    "    \"sys_enter_mlockall\",\n",
    "    \"sys_enter_setxattr\",\n",
    "    \"sys_enter_clock_getres\",\n",
    "    \"sys_enter_mmap\",\n",
    "    \"sys_enter_shmat\",\n",
    "    \"sys_enter_clock_gettime\",\n",
    "    \"sys_enter_mount\",\n",
    "    \"sys_enter_shmctl\",\n",
    "    \"sys_enter_clock_nanosleep\",\n",
    "    \"sys_enter_shmdt\",\n",
    "    \"sys_enter_clock_settime\",\n",
    "    \"sys_enter_shmget\",\n",
    "    \"sys_enter_clone\",\n",
    "    \"sys_enter_move_pages\",\n",
    "    \"sys_enter_shutdown\",\n",
    "    \"sys_enter_clone3\",\n",
    "    \"sys_enter_mprotect\",\n",
    "    \"sys_enter_sigaltstack\",\n",
    "    \"sys_enter_close\",\n",
    "    \"sys_enter_mq_getsetattr\",\n",
    "    \"sys_enter_signalfd4\",\n",
    "    \"sys_enter_close_range\",\n",
    "    \"sys_enter_mq_notify\",\n",
    "    \"sys_enter_socket\",\n",
    "    \"sys_enter_connect\",\n",
    "    \"sys_enter_mq_open\",\n",
    "    \"sys_enter_socketpair\",\n",
    "    \"sys_enter_copy_file_range\",\n",
    "    \"sys_enter_mq_timedreceive\",\n",
    "    \"sys_enter_splice\",\n",
    "    \"sys_enter_delete_module\",\n",
    "    \"sys_enter_mq_timedsend\",\n",
    "    \"sys_enter_statfs\",\n",
    "    \"sys_enter_dup\",\n",
    "    \"sys_enter_mq_unlink\",\n",
    "    \"sys_enter_statx\",\n",
    "    \"sys_enter_dup3\",\n",
    "    \"sys_enter_mremap\",\n",
    "    \"sys_enter_swapoff\",\n",
    "    \"sys_enter_epoll_create1\",\n",
    "    \"sys_enter_msgctl\",\n",
    "    \"sys_enter_swapon\",\n",
    "    \"sys_enter_epoll_ctl\",\n",
    "    \"sys_enter_msgget\",\n",
    "    \"sys_enter_symlinkat\",\n",
    "    \"sys_enter_epoll_pwait\",\n",
    "    \"sys_enter_msgrcv\",\n",
    "    \"sys_enter_sync\",\n",
    "    \"sys_enter_epoll_pwait2\",\n",
    "    \"sys_enter_msgsnd\",\n",
    "    \"sys_enter_sync_file_range\",\n",
    "    \"sys_enter_eventfd2\",\n",
    "    \"sys_enter_msync\",\n",
    "    \"sys_enter_syncfs\",\n",
    "    \"sys_enter_execve\",\n",
    "    \"sys_enter_munlock\",\n",
    "    \"sys_enter_sysinfo\",\n",
    "    \"sys_enter_execveat\",\n",
    "    \"sys_enter_munlockall\",\n",
    "    \"sys_enter_syslog\",\n",
    "    \"sys_enter_exit\",\n",
    "    \"sys_enter_munmap\",\n",
    "    \"sys_enter_tee\",\n",
    "    \"sys_enter_exit_group\",\n",
    "    \"sys_enter_tgkill\",\n",
    "    \"sys_enter_faccessat\",\n",
    "    \"sys_enter_nanosleep\",\n",
    "    \"sys_enter_timer_create\",\n",
    "    \"sys_enter_faccessat2\",\n",
    "    \"sys_enter_newfstat\",\n",
    "    \"sys_enter_timer_delete\",\n",
    "    \"sys_enter_fadvise64_64\",\n",
    "    \"sys_enter_newfstatat\",\n",
    "    \"sys_enter_timer_getoverrun\",\n",
    "    \"sys_enter_fallocate\",\n",
    "    \"sys_enter_newuname\",\n",
    "    \"sys_enter_timer_gettime\",\n",
    "    \"sys_enter_fanotify_init\",\n",
    "    \"sys_enter_timer_settime\",\n",
    "    \"sys_enter_fanotify_mark\",\n",
    "    \"sys_enter_timerfd_create\",\n",
    "    \"sys_enter_fchdir\",\n",
    "    \"sys_enter_openat\",\n",
    "    \"sys_enter_timerfd_gettime\",\n",
    "    \"sys_enter_fchmod\",\n",
    "    \"sys_enter_openat2\",\n",
    "    \"sys_enter_timerfd_settime\",\n",
    "    \"sys_enter_fchmodat\",\n",
    "    \"sys_enter_times\",\n",
    "    \"sys_enter_fchown\",\n",
    "    \"sys_enter_tkill\",\n",
    "    \"sys_enter_fchownat\",\n",
    "    \"sys_enter_truncate\",\n",
    "    \"sys_enter_fcntl\",\n",
    "    \"sys_enter_umask\",\n",
    "    \"sys_enter_fdatasync\",\n",
    "    \"sys_enter_pipe2\",\n",
    "    \"sys_enter_umount\",\n",
    "    \"sys_enter_fgetxattr\",\n",
    "    \"sys_enter_unlinkat\",\n",
    "    \"sys_enter_finit_module\",\n",
    "    \"sys_enter_unshare\",\n",
    "    \"sys_enter_flistxattr\",\n",
    "    \"sys_enter_prctl\",\n",
    "    \"sys_enter_flock\",\n",
    "    \"sys_enter_pread64\",\n",
    "    \"sys_enter_utimensat\",\n",
    "    \"sys_enter_fremovexattr\",\n",
    "    \"sys_enter_preadv\",\n",
    "    \"sys_enter_vhangup\",\n",
    "    \"sys_enter_fsconfig\",\n",
    "    \"sys_enter_preadv2\",\n",
    "    \"sys_enter_vmsplice\",\n",
    "    \"sys_enter_fsetxattr\",\n",
    "    \"sys_enter_prlimit64\",\n",
    "    \"sys_enter_wait4\",\n",
    "    \"sys_enter_fsmount\",\n",
    "    \"sys_enter_waitid\",\n",
    "    \"sys_enter_fsopen\",\n",
    "    \"sys_enter_fspick\",\n",
    "    \"sys_enter_writev\",\n",
    "    \"sys_enter_fstatfs\",\n",
    "    \"sys_enter_fsync\",\n",
    "    \"sys_enter_pselect6\",\n",
    "    \"sys_enter_ftruncate\",\n",
    "    \"sys_enter_ptrace\",\n",
    "    \"sys_enter_futex\",\n",
    "    \"sys_enter_pwrite64\",\n",
    "    \"sys_enter_get_mempolicy\",\n",
    "    \"sys_enter_pwritev\",\n",
    "    \"sys_enter_get_robust_list\",\n",
    "    \"sys_enter_pwritev2\",\n",
    "    \"sys_enter_getcpu\",\n",
    "    \"sys_enter_quotactl\",\n",
    "    \"sys_enter_getcwd\",\n",
    "    \"sys_enter_quotactl_fd\",\n",
    "    \"sys_enter_getdents64\",\n",
    "    \"sys_enter_getegid\",\n",
    "    \"sys_enter_readahead\",\n",
    "    \"sys_enter_geteuid\",\n",
    "    \"sys_enter_readlinkat\",\n",
    "    \"sys_enter_getgid\",\n",
    "    \"sys_enter_readv\",\n",
    "    \"sys_enter_getgroups\",\n",
    "    \"sys_enter_reboot\",\n",
    "    \"sys_enter_getitimer\",\n",
    "    \"sys_enter_recvfrom\",\n",
    "    \"sys_enter_getpeername\",\n",
    "    \"sys_enter_recvmmsg\",\n",
    "    \"sys_enter_getpgid\",\n",
    "    \"sys_enter_remap_file_pages\",\n",
    "    \"sys_enter_getppid\",\n",
    "    \"sys_enter_removexattr\",\n",
    "    \"sys_enter_getpriority\",\n",
    "    \"sys_enter_renameat\",\n",
    "    \"sys_enter_getrandom\",\n",
    "    \"sys_enter_renameat2\",\n",
    "    \"sys_enter_getresgid\",\n",
    "    \"sys_enter_request_key\",\n",
    "    \"sys_enter_getresuid\",\n",
    "    \"sys_enter_restart_syscall\",\n",
    "    \"sys_enter_getrlimit\",\n",
    "    \"sys_enter_rseq\",\n",
    "    \"sys_enter_getrusage\",\n",
    "    \"sys_enter_getsid\",\n",
    "    \"sys_enter_rt_sigpending\",\n",
    "    \"sys_enter_getsockname\",\n",
    "    \"sys_enter_getsockopt\",\n",
    "    \"sys_enter_rt_sigqueueinfo\",\n",
    "    \"sys_enter_gettid\",\n",
    "    \"sys_enter_rt_sigreturn\",\n",
    "    \"sys_enter_gettimeofday\",\n",
    "    \"sys_enter_rt_sigsuspend\",\n",
    "    \"sys_enter_getuid\",\n",
    "    \"sys_enter_rt_sigtimedwait\",\n",
    "    \"sys_enter_getxattr\",\n",
    "    \"sys_enter_rt_tgsigqueueinfo\",\n",
    "    \"sys_enter_init_module\",\n",
    "    \"sys_enter_sched_get_priority_max\",\n",
    "    \"sys_enter_inotify_add_watch\",\n",
    "    \"sys_enter_sched_get_priority_min\",\n",
    "    \"sys_enter_inotify_init1\",\n",
    "    \"sys_enter_sched_getaffinity\",\n",
    "    \"sys_enter_inotify_rm_watch\",\n",
    "    \"sys_enter_sched_getattr\",\n",
    "    \"sys_enter_sched_getparam\",\n",
    "    \"sys_enter_sched_getscheduler\",\n",
    "    \"sys_enter_sched_rr_get_interval\",\n",
    "    \"sys_enter_sched_setaffinity\",\n",
    "    \"sys_enter_sched_setattr\",\n",
    "    \"sys_enter_sched_setparam\",\n",
    "    \"sys_enter_sched_setscheduler\",\n",
    "    \"sys_enter_sched_yield\",\n",
    "    \"sys_enter_seccomp\",\n",
    "    \"sys_enter_semctl\",\n",
    "    \"sys_enter_ioprio_get\",\n",
    "    \"sys_enter_semget\",\n",
    "    \"sys_enter_ioprio_set\",\n",
    "    \"sys_enter_semop\",\n",
    "    \"sys_enter_kcmp\",\n",
    "    \"sys_enter_semtimedop\",\n",
    "    \"sys_enter_sendfile64\",\n",
    "    \"sys_enter_sendmmsg\",\n",
    "    \"sys_enter_keyctl\",\n",
    "    \"sys_enter_kill\",\n",
    "    \"sys_enter_sendto\",\n",
    "    \"sys_enter_set_mempolicy\",\n",
    "    \"sys_enter_set_robust_list\",\n",
    "    \"sys_enter_set_tid_address\",\n",
    "    \"sys_enter_setdomainname\",\n",
    "    \"sys_enter_linkat\",\n",
    "    \"sys_enter_setfsgid\",\n",
    "    \"sys_enter_listen\",\n",
    "    \"sys_enter_setfsuid\",\n",
    "    \"sys_enter_listxattr\",\n",
    "    \"sys_enter_setgid\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "CLASSES = np.array(['benign', 'malware'])\n",
    "DATASET_DIR = \"dataset/\"\n",
    "VECTOR_LENGTH = 32 * 32\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(syscalls)\n",
    "\n",
    "def csvToVector(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data_encoded = label_encoder.fit_transform(data['SYSTEM_CALL'])\n",
    "    vector = np.zeros(VECTOR_LENGTH, dtype=np.uint8)\n",
    "    syscall_nums = min(len(data_encoded), VECTOR_LENGTH)\n",
    "    vector[:syscall_nums] = data_encoded[:syscall_nums]\n",
    "\n",
    "    return vector\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    classes = [class_name for class_name in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, class_name))]\n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        for file_name in os.listdir(class_dir):\n",
    "            if file_name.endswith('.csv'):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                vector = csvToVector(file_path)\n",
    "                x.append(vector)\n",
    "                y.append(class_idx)\n",
    "                \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "y_val = to_categorical(y_val, NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245, 1024)\n",
      "(132, 1024)\n",
      "(62, 1024)\n",
      "(245, 2)\n",
      "(132, 2)\n",
      "(62, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(VECTOR_LENGTH, 1))\n",
    "\n",
    "x = Conv1D(filters=32, kernel_size=3, padding='same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Conv1D(filters=64, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Conv1D(filters=128, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(256)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 1024, 1)]         0         \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 1024, 32)          128       \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 1024, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 1024, 32)          0         \n",
      "                                                                 \n",
      " max_pooling1d_21 (MaxPoolin  (None, 512, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 512, 64)           6208      \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 512, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 512, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPoolin  (None, 256, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_24 (Conv1D)          (None, 256, 128)          24704     \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 256, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 256, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPoolin  (None, 128, 128)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               4194560   \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,228,034\n",
      "Trainable params: 4,227,074\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = ModelCheckpoint(\n",
    "    filepath='CNN_1D_CheckPoint.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0487 - accuracy: 0.9777\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54839, saving model to CNN_1D_CheckPoint.h5\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0479 - accuracy: 0.9755 - val_loss: 1.6342 - val_accuracy: 0.5484\n",
      "Epoch 2/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0485 - accuracy: 0.9732\n",
      "Epoch 2: val_accuracy improved from 0.54839 to 0.79032, saving model to CNN_1D_CheckPoint.h5\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0521 - accuracy: 0.9714 - val_loss: 0.5972 - val_accuracy: 0.7903\n",
      "Epoch 3/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0525 - accuracy: 0.9688\n",
      "Epoch 3: val_accuracy improved from 0.79032 to 0.82258, saving model to CNN_1D_CheckPoint.h5\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0543 - accuracy: 0.9673 - val_loss: 0.5604 - val_accuracy: 0.8226\n",
      "Epoch 4/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0529 - accuracy: 0.9821\n",
      "Epoch 4: val_accuracy improved from 0.82258 to 0.88710, saving model to CNN_1D_CheckPoint.h5\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0579 - accuracy: 0.9755 - val_loss: 0.4934 - val_accuracy: 0.8871\n",
      "Epoch 5/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0491 - accuracy: 0.9777\n",
      "Epoch 5: val_accuracy did not improve from 0.88710\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0528 - accuracy: 0.9755 - val_loss: 0.6231 - val_accuracy: 0.8065\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9673\n",
      "Epoch 6: val_accuracy did not improve from 0.88710\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0631 - accuracy: 0.9673 - val_loss: 1.1629 - val_accuracy: 0.7258\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9755\n",
      "Epoch 7: val_accuracy did not improve from 0.88710\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0516 - accuracy: 0.9755 - val_loss: 0.8081 - val_accuracy: 0.7742\n",
      "Epoch 8/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0589 - accuracy: 0.9732\n",
      "Epoch 8: val_accuracy did not improve from 0.88710\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0556 - accuracy: 0.9755 - val_loss: 0.5369 - val_accuracy: 0.7742\n",
      "Epoch 9/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0548 - accuracy: 0.9688\n",
      "Epoch 9: val_accuracy did not improve from 0.88710\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.5661 - val_accuracy: 0.7581\n",
      "Epoch 10/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0461 - accuracy: 0.9821\n",
      "Epoch 10: val_accuracy improved from 0.88710 to 0.90323, saving model to CNN_1D_CheckPoint.h5\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0479 - accuracy: 0.9796 - val_loss: 0.3200 - val_accuracy: 0.9032\n",
      "Epoch 11/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0651 - accuracy: 0.9688\n",
      "Epoch 11: val_accuracy improved from 0.90323 to 0.91935, saving model to CNN_1D_CheckPoint.h5\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0689 - accuracy: 0.9633 - val_loss: 0.1949 - val_accuracy: 0.9194\n",
      "Epoch 12/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0502 - accuracy: 0.9732\n",
      "Epoch 12: val_accuracy did not improve from 0.91935\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0570 - accuracy: 0.9673 - val_loss: 0.2011 - val_accuracy: 0.9032\n",
      "Epoch 13/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0524 - accuracy: 0.9732\n",
      "Epoch 13: val_accuracy did not improve from 0.91935\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0506 - accuracy: 0.9755 - val_loss: 0.2656 - val_accuracy: 0.9032\n",
      "Epoch 14/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0502 - accuracy: 0.9732\n",
      "Epoch 14: val_accuracy did not improve from 0.91935\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0462 - accuracy: 0.9755 - val_loss: 0.2224 - val_accuracy: 0.9032\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9673\n",
      "Epoch 15: val_accuracy did not improve from 0.91935\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0498 - accuracy: 0.9673 - val_loss: 0.1928 - val_accuracy: 0.9032\n",
      "Epoch 16/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0375 - accuracy: 0.9732\n",
      "Epoch 16: val_accuracy did not improve from 0.91935\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0451 - accuracy: 0.9714 - val_loss: 0.2324 - val_accuracy: 0.9032\n",
      "Epoch 17/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0471 - accuracy: 0.9777\n",
      "Epoch 17: val_accuracy did not improve from 0.91935\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0482 - accuracy: 0.9755 - val_loss: 0.2742 - val_accuracy: 0.9032\n",
      "Epoch 18/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0411 - accuracy: 0.9777\n",
      "Epoch 18: val_accuracy did not improve from 0.91935\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0435 - accuracy: 0.9796 - val_loss: 0.2544 - val_accuracy: 0.9032\n",
      "Epoch 19/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0433 - accuracy: 0.9777\n",
      "Epoch 19: val_accuracy did not improve from 0.91935\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0423 - accuracy: 0.9796 - val_loss: 0.2131 - val_accuracy: 0.9194\n",
      "Epoch 20/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0614 - accuracy: 0.9688\n",
      "Epoch 20: val_accuracy improved from 0.91935 to 0.93548, saving model to CNN_1D_CheckPoint.h5\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0649 - accuracy: 0.9673 - val_loss: 0.1646 - val_accuracy: 0.9355\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9633\n",
      "Epoch 21: val_accuracy improved from 0.93548 to 0.95161, saving model to CNN_1D_CheckPoint.h5\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0620 - accuracy: 0.9633 - val_loss: 0.2194 - val_accuracy: 0.9516\n",
      "Epoch 22/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0716 - accuracy: 0.9777\n",
      "Epoch 22: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0672 - accuracy: 0.9796 - val_loss: 0.1773 - val_accuracy: 0.9516\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.9592\n",
      "Epoch 23: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0679 - accuracy: 0.9592 - val_loss: 0.1806 - val_accuracy: 0.9516\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9673\n",
      "Epoch 24: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0558 - accuracy: 0.9673 - val_loss: 0.2133 - val_accuracy: 0.9516\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9755\n",
      "Epoch 25: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0529 - accuracy: 0.9755 - val_loss: 0.2595 - val_accuracy: 0.9032\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9755\n",
      "Epoch 26: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0687 - accuracy: 0.9755 - val_loss: 0.2767 - val_accuracy: 0.8871\n",
      "Epoch 27/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0709 - accuracy: 0.9598\n",
      "Epoch 27: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0703 - accuracy: 0.9633 - val_loss: 0.2832 - val_accuracy: 0.8871\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9755\n",
      "Epoch 28: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0529 - accuracy: 0.9755 - val_loss: 0.2722 - val_accuracy: 0.9032\n",
      "Epoch 29/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0584 - accuracy: 0.9777\n",
      "Epoch 29: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0544 - accuracy: 0.9796 - val_loss: 0.2972 - val_accuracy: 0.8871\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9633\n",
      "Epoch 30: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0731 - accuracy: 0.9633 - val_loss: 0.3949 - val_accuracy: 0.8387\n",
      "Epoch 31/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0527 - accuracy: 0.9643\n",
      "Epoch 31: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0505 - accuracy: 0.9673 - val_loss: 0.3004 - val_accuracy: 0.8387\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9755\n",
      "Epoch 32: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0618 - accuracy: 0.9755 - val_loss: 0.3354 - val_accuracy: 0.8548\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9551\n",
      "Epoch 33: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0699 - accuracy: 0.9551 - val_loss: 0.3458 - val_accuracy: 0.8387\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9633\n",
      "Epoch 34: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0645 - accuracy: 0.9633 - val_loss: 0.2605 - val_accuracy: 0.9032\n",
      "Epoch 35/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0521 - accuracy: 0.9777\n",
      "Epoch 35: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0564 - accuracy: 0.9755 - val_loss: 0.2380 - val_accuracy: 0.9194\n",
      "Epoch 36/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0403 - accuracy: 0.9777\n",
      "Epoch 36: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0453 - accuracy: 0.9755 - val_loss: 0.2471 - val_accuracy: 0.8871\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9796\n",
      "Epoch 37: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.0479 - accuracy: 0.9796 - val_loss: 0.2598 - val_accuracy: 0.8710\n",
      "Epoch 38/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0580 - accuracy: 0.9732\n",
      "Epoch 38: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0541 - accuracy: 0.9755 - val_loss: 0.2623 - val_accuracy: 0.8710\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9673\n",
      "Epoch 39: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0474 - accuracy: 0.9673 - val_loss: 0.2807 - val_accuracy: 0.8871\n",
      "Epoch 40/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0629 - accuracy: 0.9598\n",
      "Epoch 40: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0578 - accuracy: 0.9633 - val_loss: 0.4118 - val_accuracy: 0.8387\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9837\n",
      "Epoch 41: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.0547 - accuracy: 0.9837 - val_loss: 0.6484 - val_accuracy: 0.8065\n",
      "Epoch 42/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0599 - accuracy: 0.9598\n",
      "Epoch 42: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0564 - accuracy: 0.9633 - val_loss: 0.9934 - val_accuracy: 0.7742\n",
      "Epoch 43/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0552 - accuracy: 0.9688\n",
      "Epoch 43: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0506 - accuracy: 0.9714 - val_loss: 1.3139 - val_accuracy: 0.7097\n",
      "Epoch 44/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0540 - accuracy: 0.9643\n",
      "Epoch 44: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.0498 - accuracy: 0.9673 - val_loss: 1.4625 - val_accuracy: 0.7097\n",
      "Epoch 45/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0608 - accuracy: 0.9554\n",
      "Epoch 45: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0590 - accuracy: 0.9551 - val_loss: 1.4748 - val_accuracy: 0.7097\n",
      "Epoch 46/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0506 - accuracy: 0.9777\n",
      "Epoch 46: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0495 - accuracy: 0.9796 - val_loss: 1.6384 - val_accuracy: 0.7097\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9592\n",
      "Epoch 47: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0617 - accuracy: 0.9592 - val_loss: 1.3918 - val_accuracy: 0.7258\n",
      "Epoch 48/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0466 - accuracy: 0.9777\n",
      "Epoch 48: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0491 - accuracy: 0.9755 - val_loss: 1.1542 - val_accuracy: 0.7258\n",
      "Epoch 49/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0471 - accuracy: 0.9821\n",
      "Epoch 49: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0640 - accuracy: 0.9755 - val_loss: 0.6771 - val_accuracy: 0.7742\n",
      "Epoch 50/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0523 - accuracy: 0.9732\n",
      "Epoch 50: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0571 - accuracy: 0.9673 - val_loss: 0.3711 - val_accuracy: 0.8710\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9755\n",
      "Epoch 51: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0510 - accuracy: 0.9755 - val_loss: 0.2700 - val_accuracy: 0.9032\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9755\n",
      "Epoch 52: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0670 - accuracy: 0.9755 - val_loss: 0.1942 - val_accuracy: 0.9194\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9673\n",
      "Epoch 53: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0528 - accuracy: 0.9673 - val_loss: 0.2483 - val_accuracy: 0.9032\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9755\n",
      "Epoch 54: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0532 - accuracy: 0.9755 - val_loss: 0.1883 - val_accuracy: 0.9194\n",
      "Epoch 55/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0811 - accuracy: 0.9643\n",
      "Epoch 55: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0749 - accuracy: 0.9673 - val_loss: 0.2043 - val_accuracy: 0.9355\n",
      "Epoch 56/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0673 - accuracy: 0.9688\n",
      "Epoch 56: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0644 - accuracy: 0.9714 - val_loss: 0.1559 - val_accuracy: 0.9355\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9673\n",
      "Epoch 57: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.0577 - accuracy: 0.9673 - val_loss: 0.1341 - val_accuracy: 0.9355\n",
      "Epoch 58/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0460 - accuracy: 0.9777\n",
      "Epoch 58: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0528 - accuracy: 0.9755 - val_loss: 0.1614 - val_accuracy: 0.9516\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9755\n",
      "Epoch 59: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0523 - accuracy: 0.9755 - val_loss: 0.2085 - val_accuracy: 0.9355\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9714\n",
      "Epoch 60: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0528 - accuracy: 0.9714 - val_loss: 0.2178 - val_accuracy: 0.9355\n",
      "Epoch 61/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0526 - accuracy: 0.9777\n",
      "Epoch 61: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0591 - accuracy: 0.9714 - val_loss: 0.2157 - val_accuracy: 0.9194\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9755\n",
      "Epoch 62: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0495 - accuracy: 0.9755 - val_loss: 0.2566 - val_accuracy: 0.9032\n",
      "Epoch 63/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0492 - accuracy: 0.9688\n",
      "Epoch 63: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0524 - accuracy: 0.9673 - val_loss: 0.2720 - val_accuracy: 0.9032\n",
      "Epoch 64/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0636 - accuracy: 0.9643\n",
      "Epoch 64: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0653 - accuracy: 0.9633 - val_loss: 0.3611 - val_accuracy: 0.9194\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9755\n",
      "Epoch 65: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0564 - accuracy: 0.9755 - val_loss: 0.6230 - val_accuracy: 0.7903\n",
      "Epoch 66/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0559 - accuracy: 0.9732\n",
      "Epoch 66: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0513 - accuracy: 0.9755 - val_loss: 0.9655 - val_accuracy: 0.7419\n",
      "Epoch 67/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0646 - accuracy: 0.9598\n",
      "Epoch 67: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0610 - accuracy: 0.9633 - val_loss: 0.3166 - val_accuracy: 0.9194\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9796\n",
      "Epoch 68: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.0521 - accuracy: 0.9796 - val_loss: 0.2964 - val_accuracy: 0.8871\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9755\n",
      "Epoch 69: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0549 - accuracy: 0.9755 - val_loss: 0.3042 - val_accuracy: 0.9032\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9714\n",
      "Epoch 70: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0590 - accuracy: 0.9714 - val_loss: 0.2805 - val_accuracy: 0.8871\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9592\n",
      "Epoch 71: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0612 - accuracy: 0.9592 - val_loss: 0.2272 - val_accuracy: 0.8871\n",
      "Epoch 72/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0535 - accuracy: 0.9732\n",
      "Epoch 72: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0491 - accuracy: 0.9755 - val_loss: 0.1932 - val_accuracy: 0.9032\n",
      "Epoch 73/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0574 - accuracy: 0.9777\n",
      "Epoch 73: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0589 - accuracy: 0.9755 - val_loss: 0.2010 - val_accuracy: 0.9032\n",
      "Epoch 74/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0599 - accuracy: 0.9688\n",
      "Epoch 74: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.0563 - accuracy: 0.9714 - val_loss: 0.3171 - val_accuracy: 0.8548\n",
      "Epoch 75/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0420 - accuracy: 0.9777\n",
      "Epoch 75: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0490 - accuracy: 0.9714 - val_loss: 0.2628 - val_accuracy: 0.8710\n",
      "Epoch 76/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0610 - accuracy: 0.9732\n",
      "Epoch 76: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0563 - accuracy: 0.9755 - val_loss: 0.2731 - val_accuracy: 0.9032\n",
      "Epoch 77/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0628 - accuracy: 0.9732\n",
      "Epoch 77: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0575 - accuracy: 0.9755 - val_loss: 0.2524 - val_accuracy: 0.9032\n",
      "Epoch 78/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0537 - accuracy: 0.9777\n",
      "Epoch 78: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0547 - accuracy: 0.9796 - val_loss: 0.2996 - val_accuracy: 0.9032\n",
      "Epoch 79/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0558 - accuracy: 0.9732\n",
      "Epoch 79: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0526 - accuracy: 0.9755 - val_loss: 0.6757 - val_accuracy: 0.8548\n",
      "Epoch 80/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0693 - accuracy: 0.9732\n",
      "Epoch 80: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0634 - accuracy: 0.9755 - val_loss: 0.7056 - val_accuracy: 0.8065\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9796\n",
      "Epoch 81: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0539 - accuracy: 0.9796 - val_loss: 0.4277 - val_accuracy: 0.8226\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9796\n",
      "Epoch 82: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0500 - accuracy: 0.9796 - val_loss: 0.2833 - val_accuracy: 0.8871\n",
      "Epoch 83/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0482 - accuracy: 0.9821\n",
      "Epoch 83: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0535 - accuracy: 0.9796 - val_loss: 0.4425 - val_accuracy: 0.8710\n",
      "Epoch 84/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0497 - accuracy: 0.9688\n",
      "Epoch 84: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0495 - accuracy: 0.9673 - val_loss: 0.5311 - val_accuracy: 0.8387\n",
      "Epoch 85/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0440 - accuracy: 0.9866\n",
      "Epoch 85: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0474 - accuracy: 0.9837 - val_loss: 0.4722 - val_accuracy: 0.8710\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9714\n",
      "Epoch 86: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0553 - accuracy: 0.9714 - val_loss: 0.4355 - val_accuracy: 0.8710\n",
      "Epoch 87/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0544 - accuracy: 0.9732\n",
      "Epoch 87: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0498 - accuracy: 0.9755 - val_loss: 0.4298 - val_accuracy: 0.8710\n",
      "Epoch 88/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0505 - accuracy: 0.9688\n",
      "Epoch 88: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0480 - accuracy: 0.9714 - val_loss: 0.5067 - val_accuracy: 0.8548\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9755\n",
      "Epoch 89: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0592 - accuracy: 0.9755 - val_loss: 0.4999 - val_accuracy: 0.8710\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9755\n",
      "Epoch 90: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0546 - accuracy: 0.9755 - val_loss: 0.2438 - val_accuracy: 0.9032\n",
      "Epoch 91/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0614 - accuracy: 0.9598\n",
      "Epoch 91: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0562 - accuracy: 0.9633 - val_loss: 0.2012 - val_accuracy: 0.9194\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9796\n",
      "Epoch 92: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0603 - accuracy: 0.9796 - val_loss: 0.2960 - val_accuracy: 0.9032\n",
      "Epoch 93/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0532 - accuracy: 0.9643\n",
      "Epoch 93: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0585 - accuracy: 0.9633 - val_loss: 0.2414 - val_accuracy: 0.8871\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9755\n",
      "Epoch 94: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0516 - accuracy: 0.9755 - val_loss: 0.2259 - val_accuracy: 0.8871\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9714\n",
      "Epoch 95: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0527 - accuracy: 0.9714 - val_loss: 0.2207 - val_accuracy: 0.9032\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9714\n",
      "Epoch 96: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0540 - accuracy: 0.9714 - val_loss: 0.4275 - val_accuracy: 0.8065\n",
      "Epoch 97/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0518 - accuracy: 0.9821\n",
      "Epoch 97: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0540 - accuracy: 0.9796 - val_loss: 1.3503 - val_accuracy: 0.6452\n",
      "Epoch 98/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0583 - accuracy: 0.9732\n",
      "Epoch 98: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0616 - accuracy: 0.9714 - val_loss: 1.7568 - val_accuracy: 0.6129\n",
      "Epoch 99/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0665 - accuracy: 0.9554\n",
      "Epoch 99: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0626 - accuracy: 0.9592 - val_loss: 1.7634 - val_accuracy: 0.6129\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9755\n",
      "Epoch 100: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0508 - accuracy: 0.9755 - val_loss: 0.5999 - val_accuracy: 0.7903\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9714\n",
      "Epoch 101: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0504 - accuracy: 0.9714 - val_loss: 0.1949 - val_accuracy: 0.9032\n",
      "Epoch 102/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0486 - accuracy: 0.9732\n",
      "Epoch 102: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0516 - accuracy: 0.9714 - val_loss: 0.6206 - val_accuracy: 0.8387\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9755\n",
      "Epoch 103: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0515 - accuracy: 0.9755 - val_loss: 1.0232 - val_accuracy: 0.7903\n",
      "Epoch 104/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0553 - accuracy: 0.9732\n",
      "Epoch 104: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0507 - accuracy: 0.9755 - val_loss: 0.8500 - val_accuracy: 0.7742\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9714\n",
      "Epoch 105: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0588 - accuracy: 0.9714 - val_loss: 1.0880 - val_accuracy: 0.7742\n",
      "Epoch 106/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0467 - accuracy: 0.9821\n",
      "Epoch 106: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0498 - accuracy: 0.9796 - val_loss: 1.1254 - val_accuracy: 0.7742\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9755\n",
      "Epoch 107: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0543 - accuracy: 0.9755 - val_loss: 0.7844 - val_accuracy: 0.8065\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9714\n",
      "Epoch 108: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0524 - accuracy: 0.9714 - val_loss: 0.7175 - val_accuracy: 0.8226\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9714\n",
      "Epoch 109: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0700 - accuracy: 0.9714 - val_loss: 0.8629 - val_accuracy: 0.7742\n",
      "Epoch 110/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0678 - accuracy: 0.9554\n",
      "Epoch 110: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0709 - accuracy: 0.9510 - val_loss: 0.6455 - val_accuracy: 0.7903\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9837\n",
      "Epoch 111: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0481 - accuracy: 0.9837 - val_loss: 0.8813 - val_accuracy: 0.7581\n",
      "Epoch 112/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0474 - accuracy: 0.9777\n",
      "Epoch 112: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0467 - accuracy: 0.9755 - val_loss: 0.9987 - val_accuracy: 0.7581\n",
      "Epoch 113/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0568 - accuracy: 0.9598\n",
      "Epoch 113: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0544 - accuracy: 0.9633 - val_loss: 0.8578 - val_accuracy: 0.8065\n",
      "Epoch 114/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0670 - accuracy: 0.9643\n",
      "Epoch 114: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0623 - accuracy: 0.9673 - val_loss: 0.9053 - val_accuracy: 0.7581\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9714\n",
      "Epoch 115: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0474 - accuracy: 0.9714 - val_loss: 0.9695 - val_accuracy: 0.7581\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9714\n",
      "Epoch 116: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0531 - accuracy: 0.9714 - val_loss: 0.8869 - val_accuracy: 0.7581\n",
      "Epoch 117/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0444 - accuracy: 0.9732\n",
      "Epoch 117: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0580 - accuracy: 0.9673 - val_loss: 0.7465 - val_accuracy: 0.7742\n",
      "Epoch 118/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0450 - accuracy: 0.9777\n",
      "Epoch 118: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0488 - accuracy: 0.9755 - val_loss: 0.6635 - val_accuracy: 0.8226\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9796\n",
      "Epoch 119: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0501 - accuracy: 0.9796 - val_loss: 0.5726 - val_accuracy: 0.8226\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9755\n",
      "Epoch 120: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0491 - accuracy: 0.9755 - val_loss: 0.4133 - val_accuracy: 0.8871\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9755\n",
      "Epoch 121: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0503 - accuracy: 0.9755 - val_loss: 0.3895 - val_accuracy: 0.9032\n",
      "Epoch 122/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0672 - accuracy: 0.9688\n",
      "Epoch 122: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0624 - accuracy: 0.9714 - val_loss: 0.3560 - val_accuracy: 0.9032\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9714\n",
      "Epoch 123: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.0474 - accuracy: 0.9714 - val_loss: 0.2708 - val_accuracy: 0.9032\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9633\n",
      "Epoch 124: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0594 - accuracy: 0.9633 - val_loss: 0.2953 - val_accuracy: 0.8871\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9755\n",
      "Epoch 125: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0513 - accuracy: 0.9755 - val_loss: 0.3393 - val_accuracy: 0.8871\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9714\n",
      "Epoch 126: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0463 - accuracy: 0.9714 - val_loss: 0.4163 - val_accuracy: 0.8871\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9796\n",
      "Epoch 127: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0515 - accuracy: 0.9796 - val_loss: 0.4104 - val_accuracy: 0.8871\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9714\n",
      "Epoch 128: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0533 - accuracy: 0.9714 - val_loss: 0.3727 - val_accuracy: 0.8871\n",
      "Epoch 129/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0654 - accuracy: 0.9732\n",
      "Epoch 129: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0708 - accuracy: 0.9714 - val_loss: 0.4616 - val_accuracy: 0.8226\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9755\n",
      "Epoch 130: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0528 - accuracy: 0.9755 - val_loss: 0.7070 - val_accuracy: 0.7742\n",
      "Epoch 131/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0594 - accuracy: 0.9688\n",
      "Epoch 131: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0545 - accuracy: 0.9714 - val_loss: 0.7098 - val_accuracy: 0.7742\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9755\n",
      "Epoch 132: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0511 - accuracy: 0.9755 - val_loss: 0.6668 - val_accuracy: 0.8065\n",
      "Epoch 133/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0522 - accuracy: 0.9777\n",
      "Epoch 133: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0556 - accuracy: 0.9755 - val_loss: 0.6104 - val_accuracy: 0.8065\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9796\n",
      "Epoch 134: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0380 - accuracy: 0.9796 - val_loss: 0.4197 - val_accuracy: 0.8387\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9633\n",
      "Epoch 135: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.0544 - accuracy: 0.9633 - val_loss: 0.4122 - val_accuracy: 0.8226\n",
      "Epoch 136/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0539 - accuracy: 0.9777\n",
      "Epoch 136: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0530 - accuracy: 0.9796 - val_loss: 0.3264 - val_accuracy: 0.8871\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9714\n",
      "Epoch 137: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0529 - accuracy: 0.9714 - val_loss: 0.2032 - val_accuracy: 0.9032\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9755\n",
      "Epoch 138: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0505 - accuracy: 0.9755 - val_loss: 0.1908 - val_accuracy: 0.9194\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9714\n",
      "Epoch 139: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0611 - accuracy: 0.9714 - val_loss: 0.2439 - val_accuracy: 0.9194\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9592\n",
      "Epoch 140: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0569 - accuracy: 0.9592 - val_loss: 0.2065 - val_accuracy: 0.9194\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9714\n",
      "Epoch 141: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0651 - accuracy: 0.9714 - val_loss: 0.2323 - val_accuracy: 0.9194\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9714\n",
      "Epoch 142: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0598 - accuracy: 0.9714 - val_loss: 0.2227 - val_accuracy: 0.9516\n",
      "Epoch 143/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0496 - accuracy: 0.9732\n",
      "Epoch 143: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0482 - accuracy: 0.9755 - val_loss: 0.1696 - val_accuracy: 0.9516\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9714\n",
      "Epoch 144: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0587 - accuracy: 0.9714 - val_loss: 0.3966 - val_accuracy: 0.8871\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9796\n",
      "Epoch 145: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0544 - accuracy: 0.9796 - val_loss: 0.7566 - val_accuracy: 0.8226\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9755\n",
      "Epoch 146: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0451 - accuracy: 0.9755 - val_loss: 0.8742 - val_accuracy: 0.7903\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9714\n",
      "Epoch 147: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 60ms/step - loss: 0.0558 - accuracy: 0.9714 - val_loss: 0.7351 - val_accuracy: 0.8226\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9755\n",
      "Epoch 148: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0622 - accuracy: 0.9755 - val_loss: 0.7091 - val_accuracy: 0.8226\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9673\n",
      "Epoch 149: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0653 - accuracy: 0.9673 - val_loss: 0.3253 - val_accuracy: 0.9194\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9755\n",
      "Epoch 150: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0499 - accuracy: 0.9755 - val_loss: 0.2877 - val_accuracy: 0.9355\n",
      "Epoch 151/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0560 - accuracy: 0.9732\n",
      "Epoch 151: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0519 - accuracy: 0.9755 - val_loss: 0.2817 - val_accuracy: 0.9194\n",
      "Epoch 152/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0723 - accuracy: 0.9688\n",
      "Epoch 152: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0694 - accuracy: 0.9673 - val_loss: 0.3416 - val_accuracy: 0.9032\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9755\n",
      "Epoch 153: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0525 - accuracy: 0.9755 - val_loss: 0.5108 - val_accuracy: 0.8548\n",
      "Epoch 154/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0555 - accuracy: 0.9777\n",
      "Epoch 154: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0536 - accuracy: 0.9796 - val_loss: 0.4357 - val_accuracy: 0.8548\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9714\n",
      "Epoch 155: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0538 - accuracy: 0.9714 - val_loss: 0.3817 - val_accuracy: 0.8710\n",
      "Epoch 156/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0454 - accuracy: 0.9777\n",
      "Epoch 156: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0459 - accuracy: 0.9796 - val_loss: 0.3141 - val_accuracy: 0.8710\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9714\n",
      "Epoch 157: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0544 - accuracy: 0.9714 - val_loss: 0.2771 - val_accuracy: 0.8710\n",
      "Epoch 158/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0468 - accuracy: 0.9821\n",
      "Epoch 158: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0516 - accuracy: 0.9837 - val_loss: 0.2893 - val_accuracy: 0.8871\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9796\n",
      "Epoch 159: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0506 - accuracy: 0.9796 - val_loss: 0.3521 - val_accuracy: 0.8387\n",
      "Epoch 160/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0633 - accuracy: 0.9732\n",
      "Epoch 160: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.0600 - accuracy: 0.9755 - val_loss: 0.3756 - val_accuracy: 0.8548\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9755\n",
      "Epoch 161: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0632 - accuracy: 0.9755 - val_loss: 0.4909 - val_accuracy: 0.8065\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9714\n",
      "Epoch 162: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0558 - accuracy: 0.9714 - val_loss: 0.3296 - val_accuracy: 0.8387\n",
      "Epoch 163/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0485 - accuracy: 0.9688\n",
      "Epoch 163: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0521 - accuracy: 0.9633 - val_loss: 0.3369 - val_accuracy: 0.8548\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9755\n",
      "Epoch 164: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.0640 - accuracy: 0.9755 - val_loss: 0.4585 - val_accuracy: 0.8387\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9673\n",
      "Epoch 165: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.0551 - accuracy: 0.9673 - val_loss: 0.4153 - val_accuracy: 0.9032\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9551\n",
      "Epoch 166: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0740 - accuracy: 0.9551 - val_loss: 0.3703 - val_accuracy: 0.9032\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9755\n",
      "Epoch 167: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0494 - accuracy: 0.9755 - val_loss: 0.3564 - val_accuracy: 0.8871\n",
      "Epoch 168/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0738 - accuracy: 0.9509\n",
      "Epoch 168: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0703 - accuracy: 0.9551 - val_loss: 1.1414 - val_accuracy: 0.7581\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9673\n",
      "Epoch 169: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0621 - accuracy: 0.9673 - val_loss: 1.9953 - val_accuracy: 0.7419\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9714\n",
      "Epoch 170: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0522 - accuracy: 0.9714 - val_loss: 1.4650 - val_accuracy: 0.7419\n",
      "Epoch 171/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0425 - accuracy: 0.9821\n",
      "Epoch 171: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0443 - accuracy: 0.9796 - val_loss: 1.0932 - val_accuracy: 0.7419\n",
      "Epoch 172/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0511 - accuracy: 0.9777\n",
      "Epoch 172: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0506 - accuracy: 0.9755 - val_loss: 1.0522 - val_accuracy: 0.7419\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9755\n",
      "Epoch 173: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0466 - accuracy: 0.9755 - val_loss: 0.9770 - val_accuracy: 0.7419\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9755\n",
      "Epoch 174: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0545 - accuracy: 0.9755 - val_loss: 0.9549 - val_accuracy: 0.7419\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9714\n",
      "Epoch 175: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0486 - accuracy: 0.9714 - val_loss: 0.7864 - val_accuracy: 0.7419\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9633\n",
      "Epoch 176: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0598 - accuracy: 0.9633 - val_loss: 0.9895 - val_accuracy: 0.7258\n",
      "Epoch 177/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0485 - accuracy: 0.9777\n",
      "Epoch 177: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0548 - accuracy: 0.9755 - val_loss: 0.7417 - val_accuracy: 0.7581\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9755\n",
      "Epoch 178: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0577 - accuracy: 0.9755 - val_loss: 0.6050 - val_accuracy: 0.7742\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9673\n",
      "Epoch 179: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0552 - accuracy: 0.9673 - val_loss: 0.3670 - val_accuracy: 0.8387\n",
      "Epoch 180/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0556 - accuracy: 0.9643\n",
      "Epoch 180: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0999 - accuracy: 0.9592 - val_loss: 0.3956 - val_accuracy: 0.8226\n",
      "Epoch 181/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0509 - accuracy: 0.9688\n",
      "Epoch 181: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0467 - accuracy: 0.9714 - val_loss: 0.2709 - val_accuracy: 0.8871\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9714\n",
      "Epoch 182: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0510 - accuracy: 0.9714 - val_loss: 0.3837 - val_accuracy: 0.9032\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.9633\n",
      "Epoch 183: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0664 - accuracy: 0.9633 - val_loss: 0.2761 - val_accuracy: 0.8871\n",
      "Epoch 184/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0805 - accuracy: 0.9643\n",
      "Epoch 184: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0820 - accuracy: 0.9592 - val_loss: 0.7803 - val_accuracy: 0.7742\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9673\n",
      "Epoch 185: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0753 - accuracy: 0.9673 - val_loss: 0.4159 - val_accuracy: 0.8548\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9592\n",
      "Epoch 186: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0859 - accuracy: 0.9592 - val_loss: 0.6836 - val_accuracy: 0.8065\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9673\n",
      "Epoch 187: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0548 - accuracy: 0.9673 - val_loss: 0.6796 - val_accuracy: 0.8065\n",
      "Epoch 188/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0678 - accuracy: 0.9732\n",
      "Epoch 188: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0623 - accuracy: 0.9755 - val_loss: 0.4029 - val_accuracy: 0.8710\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9551\n",
      "Epoch 189: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.0836 - accuracy: 0.9551 - val_loss: 0.3421 - val_accuracy: 0.9194\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9714\n",
      "Epoch 190: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0808 - accuracy: 0.9714 - val_loss: 0.4098 - val_accuracy: 0.9194\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9755\n",
      "Epoch 191: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.0646 - accuracy: 0.9755 - val_loss: 0.2307 - val_accuracy: 0.9355\n",
      "Epoch 192/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0732 - accuracy: 0.9554\n",
      "Epoch 192: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0671 - accuracy: 0.9592 - val_loss: 0.1704 - val_accuracy: 0.9516\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9633\n",
      "Epoch 193: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0696 - accuracy: 0.9633 - val_loss: 0.1748 - val_accuracy: 0.9516\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9755\n",
      "Epoch 194: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0562 - accuracy: 0.9755 - val_loss: 0.2056 - val_accuracy: 0.9194\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9673\n",
      "Epoch 195: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0591 - accuracy: 0.9673 - val_loss: 0.2350 - val_accuracy: 0.9194\n",
      "Epoch 196/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0601 - accuracy: 0.9643\n",
      "Epoch 196: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0565 - accuracy: 0.9673 - val_loss: 0.2140 - val_accuracy: 0.9194\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9755\n",
      "Epoch 197: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0472 - accuracy: 0.9755 - val_loss: 0.2294 - val_accuracy: 0.9194\n",
      "Epoch 198/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0620 - accuracy: 0.9732\n",
      "Epoch 198: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0584 - accuracy: 0.9755 - val_loss: 0.3135 - val_accuracy: 0.9194\n",
      "Epoch 199/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0643 - accuracy: 0.9732\n",
      "Epoch 199: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0634 - accuracy: 0.9714 - val_loss: 0.4423 - val_accuracy: 0.9032\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9755\n",
      "Epoch 200: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0512 - accuracy: 0.9755 - val_loss: 0.4671 - val_accuracy: 0.9032\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9755\n",
      "Epoch 201: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0607 - accuracy: 0.9755 - val_loss: 0.4421 - val_accuracy: 0.9032\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9755\n",
      "Epoch 202: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0509 - accuracy: 0.9755 - val_loss: 0.4666 - val_accuracy: 0.9032\n",
      "Epoch 203/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0599 - accuracy: 0.9643\n",
      "Epoch 203: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0551 - accuracy: 0.9673 - val_loss: 0.4371 - val_accuracy: 0.9194\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9755\n",
      "Epoch 204: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0547 - accuracy: 0.9755 - val_loss: 0.4486 - val_accuracy: 0.8710\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9714\n",
      "Epoch 205: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.0510 - accuracy: 0.9714 - val_loss: 0.4410 - val_accuracy: 0.8710\n",
      "Epoch 206/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0503 - accuracy: 0.9732\n",
      "Epoch 206: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0480 - accuracy: 0.9755 - val_loss: 0.3941 - val_accuracy: 0.8710\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9714\n",
      "Epoch 207: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0489 - accuracy: 0.9714 - val_loss: 0.3218 - val_accuracy: 0.9032\n",
      "Epoch 208/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0720 - accuracy: 0.9554\n",
      "Epoch 208: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0676 - accuracy: 0.9592 - val_loss: 0.3591 - val_accuracy: 0.9032\n",
      "Epoch 209/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0478 - accuracy: 0.9732\n",
      "Epoch 209: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0466 - accuracy: 0.9755 - val_loss: 0.3772 - val_accuracy: 0.9032\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9755\n",
      "Epoch 210: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 126ms/step - loss: 0.0510 - accuracy: 0.9755 - val_loss: 0.3912 - val_accuracy: 0.9032\n",
      "Epoch 211/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0761 - accuracy: 0.9688\n",
      "Epoch 211: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0783 - accuracy: 0.9673 - val_loss: 0.4289 - val_accuracy: 0.9032\n",
      "Epoch 212/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0558 - accuracy: 0.9688\n",
      "Epoch 212: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0531 - accuracy: 0.9714 - val_loss: 0.3809 - val_accuracy: 0.9032\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9755\n",
      "Epoch 213: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0495 - accuracy: 0.9755 - val_loss: 0.3650 - val_accuracy: 0.9032\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9673\n",
      "Epoch 214: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0696 - accuracy: 0.9673 - val_loss: 0.2987 - val_accuracy: 0.9032\n",
      "Epoch 215/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0452 - accuracy: 0.9732\n",
      "Epoch 215: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 61ms/step - loss: 0.0467 - accuracy: 0.9755 - val_loss: 0.2175 - val_accuracy: 0.9194\n",
      "Epoch 216/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0559 - accuracy: 0.9732\n",
      "Epoch 216: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0523 - accuracy: 0.9755 - val_loss: 0.2159 - val_accuracy: 0.9355\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9714\n",
      "Epoch 217: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0560 - accuracy: 0.9714 - val_loss: 0.2169 - val_accuracy: 0.9355\n",
      "Epoch 218/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0462 - accuracy: 0.9777\n",
      "Epoch 218: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0503 - accuracy: 0.9755 - val_loss: 0.1828 - val_accuracy: 0.9355\n",
      "Epoch 219/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0491 - accuracy: 0.9777\n",
      "Epoch 219: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0523 - accuracy: 0.9796 - val_loss: 0.2471 - val_accuracy: 0.9194\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9755\n",
      "Epoch 220: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0587 - accuracy: 0.9755 - val_loss: 0.2898 - val_accuracy: 0.9194\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9714\n",
      "Epoch 221: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0543 - accuracy: 0.9714 - val_loss: 0.3116 - val_accuracy: 0.9194\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9796\n",
      "Epoch 222: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0452 - accuracy: 0.9796 - val_loss: 0.3050 - val_accuracy: 0.9194\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9510\n",
      "Epoch 223: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0715 - accuracy: 0.9510 - val_loss: 0.2989 - val_accuracy: 0.9194\n",
      "Epoch 224/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0454 - accuracy: 0.9821\n",
      "Epoch 224: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0565 - accuracy: 0.9755 - val_loss: 0.3150 - val_accuracy: 0.9194\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9755\n",
      "Epoch 225: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0502 - accuracy: 0.9755 - val_loss: 0.2897 - val_accuracy: 0.9355\n",
      "Epoch 226/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0535 - accuracy: 0.9643\n",
      "Epoch 226: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0537 - accuracy: 0.9633 - val_loss: 0.3664 - val_accuracy: 0.9032\n",
      "Epoch 227/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0463 - accuracy: 0.9821\n",
      "Epoch 227: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0510 - accuracy: 0.9796 - val_loss: 0.4435 - val_accuracy: 0.8226\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9755\n",
      "Epoch 228: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0513 - accuracy: 0.9755 - val_loss: 0.6445 - val_accuracy: 0.7742\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9673\n",
      "Epoch 229: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0647 - accuracy: 0.9673 - val_loss: 0.6714 - val_accuracy: 0.7742\n",
      "Epoch 230/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0488 - accuracy: 0.9777\n",
      "Epoch 230: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0474 - accuracy: 0.9796 - val_loss: 0.8689 - val_accuracy: 0.7258\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9592\n",
      "Epoch 231: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0612 - accuracy: 0.9592 - val_loss: 0.8193 - val_accuracy: 0.7419\n",
      "Epoch 232/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0566 - accuracy: 0.9598\n",
      "Epoch 232: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0592 - accuracy: 0.9592 - val_loss: 0.8392 - val_accuracy: 0.6935\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9755\n",
      "Epoch 233: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0592 - accuracy: 0.9755 - val_loss: 0.9017 - val_accuracy: 0.6935\n",
      "Epoch 234/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0542 - accuracy: 0.9732\n",
      "Epoch 234: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0552 - accuracy: 0.9714 - val_loss: 0.5744 - val_accuracy: 0.7742\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9592\n",
      "Epoch 235: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0694 - accuracy: 0.9592 - val_loss: 0.4274 - val_accuracy: 0.8226\n",
      "Epoch 236/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0681 - accuracy: 0.9688\n",
      "Epoch 236: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0655 - accuracy: 0.9673 - val_loss: 0.5893 - val_accuracy: 0.7903\n",
      "Epoch 237/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0598 - accuracy: 0.9688\n",
      "Epoch 237: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0548 - accuracy: 0.9714 - val_loss: 0.5703 - val_accuracy: 0.8065\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9796\n",
      "Epoch 238: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0563 - accuracy: 0.9796 - val_loss: 0.5018 - val_accuracy: 0.8065\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9714\n",
      "Epoch 239: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 139ms/step - loss: 0.0601 - accuracy: 0.9714 - val_loss: 0.5378 - val_accuracy: 0.8065\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9673\n",
      "Epoch 240: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0560 - accuracy: 0.9673 - val_loss: 0.5621 - val_accuracy: 0.8065\n",
      "Epoch 241/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0531 - accuracy: 0.9688\n",
      "Epoch 241: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0519 - accuracy: 0.9714 - val_loss: 0.3941 - val_accuracy: 0.8387\n",
      "Epoch 242/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0489 - accuracy: 0.9821\n",
      "Epoch 242: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0513 - accuracy: 0.9796 - val_loss: 0.3047 - val_accuracy: 0.9194\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9673\n",
      "Epoch 243: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0553 - accuracy: 0.9673 - val_loss: 0.2885 - val_accuracy: 0.9194\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9755\n",
      "Epoch 244: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0464 - accuracy: 0.9755 - val_loss: 0.3175 - val_accuracy: 0.9194\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9796\n",
      "Epoch 245: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0509 - accuracy: 0.9796 - val_loss: 0.3313 - val_accuracy: 0.9194\n",
      "Epoch 246/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0580 - accuracy: 0.9688\n",
      "Epoch 246: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0540 - accuracy: 0.9714 - val_loss: 0.3346 - val_accuracy: 0.9194\n",
      "Epoch 247/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0465 - accuracy: 0.9732\n",
      "Epoch 247: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0534 - accuracy: 0.9714 - val_loss: 0.3285 - val_accuracy: 0.8387\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9673\n",
      "Epoch 248: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0591 - accuracy: 0.9673 - val_loss: 0.2518 - val_accuracy: 0.8548\n",
      "Epoch 249/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0528 - accuracy: 0.9777\n",
      "Epoch 249: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0524 - accuracy: 0.9755 - val_loss: 0.1375 - val_accuracy: 0.9516\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9714\n",
      "Epoch 250: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0548 - accuracy: 0.9714 - val_loss: 0.1615 - val_accuracy: 0.9355\n",
      "Epoch 251/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0568 - accuracy: 0.9732\n",
      "Epoch 251: val_accuracy did not improve from 0.95161\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0633 - accuracy: 0.9714 - val_loss: 0.1529 - val_accuracy: 0.9355\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9714\n",
      "Epoch 252: val_accuracy improved from 0.95161 to 0.96774, saving model to CNN_1D_CheckPoint.h5\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0569 - accuracy: 0.9714 - val_loss: 0.1232 - val_accuracy: 0.9677\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9796\n",
      "Epoch 253: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0426 - accuracy: 0.9796 - val_loss: 0.1278 - val_accuracy: 0.9355\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9755\n",
      "Epoch 254: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0459 - accuracy: 0.9755 - val_loss: 0.1259 - val_accuracy: 0.9355\n",
      "Epoch 255/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0568 - accuracy: 0.9777\n",
      "Epoch 255: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0604 - accuracy: 0.9755 - val_loss: 0.1323 - val_accuracy: 0.9516\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9714\n",
      "Epoch 256: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0513 - accuracy: 0.9714 - val_loss: 0.1473 - val_accuracy: 0.9516\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9714\n",
      "Epoch 257: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0633 - accuracy: 0.9714 - val_loss: 0.1389 - val_accuracy: 0.9516\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9837\n",
      "Epoch 258: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0490 - accuracy: 0.9837 - val_loss: 0.1341 - val_accuracy: 0.9516\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9796\n",
      "Epoch 259: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.0452 - accuracy: 0.9796 - val_loss: 0.1549 - val_accuracy: 0.9355\n",
      "Epoch 260/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0492 - accuracy: 0.9732\n",
      "Epoch 260: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0535 - accuracy: 0.9714 - val_loss: 0.1778 - val_accuracy: 0.9516\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9714\n",
      "Epoch 261: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0658 - accuracy: 0.9714 - val_loss: 0.2370 - val_accuracy: 0.9194\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9633\n",
      "Epoch 262: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0553 - accuracy: 0.9633 - val_loss: 0.2470 - val_accuracy: 0.9194\n",
      "Epoch 263/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0488 - accuracy: 0.9732\n",
      "Epoch 263: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0533 - accuracy: 0.9714 - val_loss: 0.4975 - val_accuracy: 0.8548\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9755\n",
      "Epoch 264: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0587 - accuracy: 0.9755 - val_loss: 0.4262 - val_accuracy: 0.8548\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9755\n",
      "Epoch 265: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.0609 - accuracy: 0.9755 - val_loss: 0.3164 - val_accuracy: 0.8710\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9714\n",
      "Epoch 266: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0583 - accuracy: 0.9714 - val_loss: 0.1784 - val_accuracy: 0.9355\n",
      "Epoch 267/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0509 - accuracy: 0.9732\n",
      "Epoch 267: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0524 - accuracy: 0.9714 - val_loss: 0.1843 - val_accuracy: 0.9355\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9714\n",
      "Epoch 268: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0608 - accuracy: 0.9714 - val_loss: 0.2248 - val_accuracy: 0.9032\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9755\n",
      "Epoch 269: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0512 - accuracy: 0.9755 - val_loss: 0.2219 - val_accuracy: 0.9032\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9673\n",
      "Epoch 270: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0537 - accuracy: 0.9673 - val_loss: 0.2250 - val_accuracy: 0.9032\n",
      "Epoch 271/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0505 - accuracy: 0.9777\n",
      "Epoch 271: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0546 - accuracy: 0.9755 - val_loss: 0.2306 - val_accuracy: 0.9032\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9755\n",
      "Epoch 272: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0487 - accuracy: 0.9755 - val_loss: 0.2788 - val_accuracy: 0.8871\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9714\n",
      "Epoch 273: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0509 - accuracy: 0.9714 - val_loss: 0.2613 - val_accuracy: 0.8871\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9714\n",
      "Epoch 274: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0582 - accuracy: 0.9714 - val_loss: 0.2907 - val_accuracy: 0.8548\n",
      "Epoch 275/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9755\n",
      "Epoch 275: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0467 - accuracy: 0.9755 - val_loss: 0.2630 - val_accuracy: 0.8710\n",
      "Epoch 276/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0466 - accuracy: 0.9821\n",
      "Epoch 276: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0511 - accuracy: 0.9796 - val_loss: 0.2598 - val_accuracy: 0.9032\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9714\n",
      "Epoch 277: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0484 - accuracy: 0.9714 - val_loss: 0.2797 - val_accuracy: 0.8871\n",
      "Epoch 278/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0538 - accuracy: 0.9643\n",
      "Epoch 278: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0519 - accuracy: 0.9673 - val_loss: 0.3388 - val_accuracy: 0.8710\n",
      "Epoch 279/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0562 - accuracy: 0.9732\n",
      "Epoch 279: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0515 - accuracy: 0.9755 - val_loss: 0.4207 - val_accuracy: 0.8548\n",
      "Epoch 280/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0466 - accuracy: 0.9777\n",
      "Epoch 280: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0452 - accuracy: 0.9796 - val_loss: 0.4702 - val_accuracy: 0.8548\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9673\n",
      "Epoch 281: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0581 - accuracy: 0.9673 - val_loss: 0.3979 - val_accuracy: 0.8710\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9551\n",
      "Epoch 282: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0596 - accuracy: 0.9551 - val_loss: 0.3347 - val_accuracy: 0.9032\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9755\n",
      "Epoch 283: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0489 - accuracy: 0.9755 - val_loss: 0.3648 - val_accuracy: 0.9032\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9714\n",
      "Epoch 284: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0527 - accuracy: 0.9714 - val_loss: 0.4564 - val_accuracy: 0.8548\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9796\n",
      "Epoch 285: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0483 - accuracy: 0.9796 - val_loss: 0.6368 - val_accuracy: 0.7742\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9633\n",
      "Epoch 286: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0566 - accuracy: 0.9633 - val_loss: 1.0098 - val_accuracy: 0.7742\n",
      "Epoch 287/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9755\n",
      "Epoch 287: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0492 - accuracy: 0.9755 - val_loss: 0.9930 - val_accuracy: 0.7742\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9592\n",
      "Epoch 288: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0555 - accuracy: 0.9592 - val_loss: 0.7628 - val_accuracy: 0.7742\n",
      "Epoch 289/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0793 - accuracy: 0.9688\n",
      "Epoch 289: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0735 - accuracy: 0.9714 - val_loss: 0.7119 - val_accuracy: 0.7742\n",
      "Epoch 290/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0452 - accuracy: 0.9732\n",
      "Epoch 290: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0417 - accuracy: 0.9755 - val_loss: 0.6136 - val_accuracy: 0.7903\n",
      "Epoch 291/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0632 - accuracy: 0.9643\n",
      "Epoch 291: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0579 - accuracy: 0.9673 - val_loss: 0.6572 - val_accuracy: 0.7903\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9714\n",
      "Epoch 292: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0580 - accuracy: 0.9714 - val_loss: 0.7063 - val_accuracy: 0.7581\n",
      "Epoch 293/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0551 - accuracy: 0.9688\n",
      "Epoch 293: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0504 - accuracy: 0.9714 - val_loss: 0.7300 - val_accuracy: 0.7742\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9714\n",
      "Epoch 294: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0544 - accuracy: 0.9714 - val_loss: 0.8120 - val_accuracy: 0.7419\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9755\n",
      "Epoch 295: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0529 - accuracy: 0.9755 - val_loss: 0.6664 - val_accuracy: 0.7581\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9755\n",
      "Epoch 296: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0493 - accuracy: 0.9755 - val_loss: 0.5273 - val_accuracy: 0.8226\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9714\n",
      "Epoch 297: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0555 - accuracy: 0.9714 - val_loss: 0.4133 - val_accuracy: 0.8548\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9673\n",
      "Epoch 298: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0556 - accuracy: 0.9673 - val_loss: 0.3388 - val_accuracy: 0.8710\n",
      "Epoch 299/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9714\n",
      "Epoch 299: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0499 - accuracy: 0.9714 - val_loss: 0.2543 - val_accuracy: 0.9194\n",
      "Epoch 300/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9714\n",
      "Epoch 300: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0553 - accuracy: 0.9714 - val_loss: 0.2181 - val_accuracy: 0.9355\n",
      "Epoch 301/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0447 - accuracy: 0.9777\n",
      "Epoch 301: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0451 - accuracy: 0.9755 - val_loss: 0.2341 - val_accuracy: 0.9355\n",
      "Epoch 302/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9755\n",
      "Epoch 302: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0501 - accuracy: 0.9755 - val_loss: 0.2455 - val_accuracy: 0.8871\n",
      "Epoch 303/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0623 - accuracy: 0.9509\n",
      "Epoch 303: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0623 - accuracy: 0.9510 - val_loss: 0.2462 - val_accuracy: 0.9355\n",
      "Epoch 304/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0509 - accuracy: 0.9777\n",
      "Epoch 304: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0562 - accuracy: 0.9755 - val_loss: 0.2286 - val_accuracy: 0.9194\n",
      "Epoch 305/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9755\n",
      "Epoch 305: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0496 - accuracy: 0.9755 - val_loss: 0.2074 - val_accuracy: 0.9355\n",
      "Epoch 306/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9755\n",
      "Epoch 306: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0591 - accuracy: 0.9755 - val_loss: 0.2119 - val_accuracy: 0.9355\n",
      "Epoch 307/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9633\n",
      "Epoch 307: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0588 - accuracy: 0.9633 - val_loss: 0.2510 - val_accuracy: 0.9516\n",
      "Epoch 308/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9673\n",
      "Epoch 308: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0610 - accuracy: 0.9673 - val_loss: 0.2309 - val_accuracy: 0.9516\n",
      "Epoch 309/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0561 - accuracy: 0.9688\n",
      "Epoch 309: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0589 - accuracy: 0.9673 - val_loss: 0.2000 - val_accuracy: 0.9516\n",
      "Epoch 310/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9714\n",
      "Epoch 310: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0534 - accuracy: 0.9714 - val_loss: 0.2040 - val_accuracy: 0.9355\n",
      "Epoch 311/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9714\n",
      "Epoch 311: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0521 - accuracy: 0.9714 - val_loss: 0.2516 - val_accuracy: 0.9355\n",
      "Epoch 312/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9755\n",
      "Epoch 312: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0506 - accuracy: 0.9755 - val_loss: 0.2442 - val_accuracy: 0.9355\n",
      "Epoch 313/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9714\n",
      "Epoch 313: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0554 - accuracy: 0.9714 - val_loss: 0.2008 - val_accuracy: 0.9194\n",
      "Epoch 314/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9714\n",
      "Epoch 314: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0639 - accuracy: 0.9714 - val_loss: 0.2091 - val_accuracy: 0.9032\n",
      "Epoch 315/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9755\n",
      "Epoch 315: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0540 - accuracy: 0.9755 - val_loss: 0.2404 - val_accuracy: 0.8871\n",
      "Epoch 316/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0454 - accuracy: 0.9821\n",
      "Epoch 316: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0476 - accuracy: 0.9796 - val_loss: 0.2696 - val_accuracy: 0.9032\n",
      "Epoch 317/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0503 - accuracy: 0.9688\n",
      "Epoch 317: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0491 - accuracy: 0.9714 - val_loss: 0.3514 - val_accuracy: 0.8548\n",
      "Epoch 318/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0487 - accuracy: 0.9732\n",
      "Epoch 318: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0487 - accuracy: 0.9714 - val_loss: 0.3396 - val_accuracy: 0.8710\n",
      "Epoch 319/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9755\n",
      "Epoch 319: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0444 - accuracy: 0.9755 - val_loss: 0.2760 - val_accuracy: 0.9194\n",
      "Epoch 320/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0494 - accuracy: 0.9821\n",
      "Epoch 320: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0553 - accuracy: 0.9755 - val_loss: 0.2608 - val_accuracy: 0.9194\n",
      "Epoch 321/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9755\n",
      "Epoch 321: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0532 - accuracy: 0.9755 - val_loss: 0.2317 - val_accuracy: 0.9194\n",
      "Epoch 322/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0507 - accuracy: 0.9777\n",
      "Epoch 322: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0465 - accuracy: 0.9796 - val_loss: 0.2009 - val_accuracy: 0.9032\n",
      "Epoch 323/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9714\n",
      "Epoch 323: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0470 - accuracy: 0.9714 - val_loss: 0.1910 - val_accuracy: 0.9032\n",
      "Epoch 324/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9755\n",
      "Epoch 324: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0523 - accuracy: 0.9755 - val_loss: 0.2484 - val_accuracy: 0.9194\n",
      "Epoch 325/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9755\n",
      "Epoch 325: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.0532 - accuracy: 0.9755 - val_loss: 0.2250 - val_accuracy: 0.9032\n",
      "Epoch 326/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9755\n",
      "Epoch 326: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.0588 - accuracy: 0.9755 - val_loss: 0.2049 - val_accuracy: 0.9032\n",
      "Epoch 327/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0509 - accuracy: 0.9643\n",
      "Epoch 327: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0498 - accuracy: 0.9673 - val_loss: 0.2090 - val_accuracy: 0.9032\n",
      "Epoch 328/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9755\n",
      "Epoch 328: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0556 - accuracy: 0.9755 - val_loss: 0.2358 - val_accuracy: 0.9194\n",
      "Epoch 329/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9755\n",
      "Epoch 329: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0469 - accuracy: 0.9755 - val_loss: 0.3415 - val_accuracy: 0.8548\n",
      "Epoch 330/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9673\n",
      "Epoch 330: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 0.0482 - accuracy: 0.9673 - val_loss: 0.3785 - val_accuracy: 0.8548\n",
      "Epoch 331/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0498 - accuracy: 0.9777\n",
      "Epoch 331: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0476 - accuracy: 0.9796 - val_loss: 0.3448 - val_accuracy: 0.8548\n",
      "Epoch 332/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9714\n",
      "Epoch 332: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0509 - accuracy: 0.9714 - val_loss: 0.3506 - val_accuracy: 0.8548\n",
      "Epoch 333/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9633\n",
      "Epoch 333: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0555 - accuracy: 0.9633 - val_loss: 0.3975 - val_accuracy: 0.8226\n",
      "Epoch 334/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0673 - accuracy: 0.9732\n",
      "Epoch 334: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0616 - accuracy: 0.9755 - val_loss: 0.4377 - val_accuracy: 0.8548\n",
      "Epoch 335/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0558 - accuracy: 0.9732\n",
      "Epoch 335: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0514 - accuracy: 0.9755 - val_loss: 0.4021 - val_accuracy: 0.9032\n",
      "Epoch 336/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0557 - accuracy: 0.9643\n",
      "Epoch 336: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0511 - accuracy: 0.9673 - val_loss: 0.4547 - val_accuracy: 0.9032\n",
      "Epoch 337/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9755\n",
      "Epoch 337: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0545 - accuracy: 0.9755 - val_loss: 0.4822 - val_accuracy: 0.8871\n",
      "Epoch 338/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0478 - accuracy: 0.9732\n",
      "Epoch 338: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0503 - accuracy: 0.9673 - val_loss: 0.3880 - val_accuracy: 0.9194\n",
      "Epoch 339/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9796\n",
      "Epoch 339: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0443 - accuracy: 0.9796 - val_loss: 0.3058 - val_accuracy: 0.9032\n",
      "Epoch 340/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9755\n",
      "Epoch 340: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0507 - accuracy: 0.9755 - val_loss: 0.2468 - val_accuracy: 0.9194\n",
      "Epoch 341/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9714\n",
      "Epoch 341: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0524 - accuracy: 0.9714 - val_loss: 0.2246 - val_accuracy: 0.9355\n",
      "Epoch 342/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9714\n",
      "Epoch 342: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0536 - accuracy: 0.9714 - val_loss: 0.1781 - val_accuracy: 0.9516\n",
      "Epoch 343/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0618 - accuracy: 0.9643\n",
      "Epoch 343: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0596 - accuracy: 0.9633 - val_loss: 0.1947 - val_accuracy: 0.9194\n",
      "Epoch 344/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9755\n",
      "Epoch 344: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0605 - accuracy: 0.9755 - val_loss: 0.2628 - val_accuracy: 0.9032\n",
      "Epoch 345/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9796\n",
      "Epoch 345: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0489 - accuracy: 0.9796 - val_loss: 0.2823 - val_accuracy: 0.9032\n",
      "Epoch 346/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0456 - accuracy: 0.9821\n",
      "Epoch 346: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0461 - accuracy: 0.9796 - val_loss: 0.2490 - val_accuracy: 0.9032\n",
      "Epoch 347/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0409 - accuracy: 0.9777\n",
      "Epoch 347: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0409 - accuracy: 0.9796 - val_loss: 0.2859 - val_accuracy: 0.9194\n",
      "Epoch 348/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9714\n",
      "Epoch 348: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0511 - accuracy: 0.9714 - val_loss: 0.5531 - val_accuracy: 0.8065\n",
      "Epoch 349/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9714\n",
      "Epoch 349: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0523 - accuracy: 0.9714 - val_loss: 1.2145 - val_accuracy: 0.5968\n",
      "Epoch 350/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9633\n",
      "Epoch 350: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0578 - accuracy: 0.9633 - val_loss: 1.6462 - val_accuracy: 0.5323\n",
      "Epoch 351/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9673\n",
      "Epoch 351: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0573 - accuracy: 0.9673 - val_loss: 1.5671 - val_accuracy: 0.5323\n",
      "Epoch 352/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0557 - accuracy: 0.9643\n",
      "Epoch 352: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0543 - accuracy: 0.9633 - val_loss: 1.2545 - val_accuracy: 0.5645\n",
      "Epoch 353/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9755\n",
      "Epoch 353: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0592 - accuracy: 0.9755 - val_loss: 0.9793 - val_accuracy: 0.6129\n",
      "Epoch 354/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9592\n",
      "Epoch 354: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0637 - accuracy: 0.9592 - val_loss: 0.9119 - val_accuracy: 0.6452\n",
      "Epoch 355/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0534 - accuracy: 0.9643\n",
      "Epoch 355: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0570 - accuracy: 0.9633 - val_loss: 0.5467 - val_accuracy: 0.7903\n",
      "Epoch 356/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0574 - accuracy: 0.9732\n",
      "Epoch 356: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0525 - accuracy: 0.9755 - val_loss: 0.3368 - val_accuracy: 0.9194\n",
      "Epoch 357/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9755\n",
      "Epoch 357: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0526 - accuracy: 0.9755 - val_loss: 0.7592 - val_accuracy: 0.6774\n",
      "Epoch 358/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0538 - accuracy: 0.9732\n",
      "Epoch 358: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0493 - accuracy: 0.9755 - val_loss: 1.4411 - val_accuracy: 0.5000\n",
      "Epoch 359/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9714\n",
      "Epoch 359: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0633 - accuracy: 0.9714 - val_loss: 1.7280 - val_accuracy: 0.5000\n",
      "Epoch 360/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9673\n",
      "Epoch 360: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0548 - accuracy: 0.9673 - val_loss: 1.4193 - val_accuracy: 0.5000\n",
      "Epoch 361/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9714\n",
      "Epoch 361: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0490 - accuracy: 0.9714 - val_loss: 1.6868 - val_accuracy: 0.5000\n",
      "Epoch 362/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0482 - accuracy: 0.9732\n",
      "Epoch 362: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0443 - accuracy: 0.9755 - val_loss: 1.8623 - val_accuracy: 0.5000\n",
      "Epoch 363/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0622 - accuracy: 0.9598\n",
      "Epoch 363: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0607 - accuracy: 0.9592 - val_loss: 1.8599 - val_accuracy: 0.5000\n",
      "Epoch 364/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9796\n",
      "Epoch 364: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0451 - accuracy: 0.9796 - val_loss: 1.3341 - val_accuracy: 0.5484\n",
      "Epoch 365/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9755\n",
      "Epoch 365: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0582 - accuracy: 0.9755 - val_loss: 0.7183 - val_accuracy: 0.7581\n",
      "Epoch 366/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9755\n",
      "Epoch 366: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0556 - accuracy: 0.9755 - val_loss: 0.5826 - val_accuracy: 0.8065\n",
      "Epoch 367/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9796\n",
      "Epoch 367: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0504 - accuracy: 0.9796 - val_loss: 0.3243 - val_accuracy: 0.9194\n",
      "Epoch 368/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9714\n",
      "Epoch 368: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0461 - accuracy: 0.9714 - val_loss: 0.2638 - val_accuracy: 0.9194\n",
      "Epoch 369/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0628 - accuracy: 0.9688\n",
      "Epoch 369: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0616 - accuracy: 0.9714 - val_loss: 0.2790 - val_accuracy: 0.9355\n",
      "Epoch 370/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9755\n",
      "Epoch 370: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0519 - accuracy: 0.9755 - val_loss: 0.3466 - val_accuracy: 0.8387\n",
      "Epoch 371/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0507 - accuracy: 0.9732\n",
      "Epoch 371: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0464 - accuracy: 0.9755 - val_loss: 0.2820 - val_accuracy: 0.8548\n",
      "Epoch 372/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0518 - accuracy: 0.9688\n",
      "Epoch 372: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0508 - accuracy: 0.9714 - val_loss: 0.2214 - val_accuracy: 0.9355\n",
      "Epoch 373/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9796\n",
      "Epoch 373: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.0529 - accuracy: 0.9796 - val_loss: 0.2233 - val_accuracy: 0.9355\n",
      "Epoch 374/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9714\n",
      "Epoch 374: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0474 - accuracy: 0.9714 - val_loss: 0.2828 - val_accuracy: 0.8548\n",
      "Epoch 375/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0610 - accuracy: 0.9554\n",
      "Epoch 375: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0625 - accuracy: 0.9551 - val_loss: 0.4288 - val_accuracy: 0.8226\n",
      "Epoch 376/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9755\n",
      "Epoch 376: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0498 - accuracy: 0.9755 - val_loss: 0.6364 - val_accuracy: 0.7742\n",
      "Epoch 377/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0698 - accuracy: 0.9598\n",
      "Epoch 377: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0658 - accuracy: 0.9633 - val_loss: 0.1913 - val_accuracy: 0.9677\n",
      "Epoch 378/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0529 - accuracy: 0.9688\n",
      "Epoch 378: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0495 - accuracy: 0.9714 - val_loss: 0.2239 - val_accuracy: 0.9355\n",
      "Epoch 379/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9633\n",
      "Epoch 379: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0629 - accuracy: 0.9633 - val_loss: 0.1986 - val_accuracy: 0.9516\n",
      "Epoch 380/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9714\n",
      "Epoch 380: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0526 - accuracy: 0.9714 - val_loss: 0.2013 - val_accuracy: 0.9355\n",
      "Epoch 381/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0524 - accuracy: 0.9777\n",
      "Epoch 381: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0519 - accuracy: 0.9755 - val_loss: 0.1966 - val_accuracy: 0.9355\n",
      "Epoch 382/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9755\n",
      "Epoch 382: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0476 - accuracy: 0.9755 - val_loss: 0.1636 - val_accuracy: 0.9677\n",
      "Epoch 383/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0613 - accuracy: 0.9643\n",
      "Epoch 383: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0589 - accuracy: 0.9673 - val_loss: 0.1721 - val_accuracy: 0.9516\n",
      "Epoch 384/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9796\n",
      "Epoch 384: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0524 - accuracy: 0.9796 - val_loss: 0.1889 - val_accuracy: 0.9677\n",
      "Epoch 385/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0533 - accuracy: 0.9732\n",
      "Epoch 385: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0508 - accuracy: 0.9755 - val_loss: 0.1865 - val_accuracy: 0.9677\n",
      "Epoch 386/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9755\n",
      "Epoch 386: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0450 - accuracy: 0.9755 - val_loss: 0.1804 - val_accuracy: 0.9355\n",
      "Epoch 387/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0562 - accuracy: 0.9643\n",
      "Epoch 387: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0564 - accuracy: 0.9633 - val_loss: 0.1990 - val_accuracy: 0.9355\n",
      "Epoch 388/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0730 - accuracy: 0.9688\n",
      "Epoch 388: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0668 - accuracy: 0.9714 - val_loss: 0.1821 - val_accuracy: 0.9516\n",
      "Epoch 389/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0631 - accuracy: 0.9643\n",
      "Epoch 389: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0640 - accuracy: 0.9633 - val_loss: 0.1942 - val_accuracy: 0.9355\n",
      "Epoch 390/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0507 - accuracy: 0.9732\n",
      "Epoch 390: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0561 - accuracy: 0.9673 - val_loss: 0.2027 - val_accuracy: 0.9194\n",
      "Epoch 391/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9755\n",
      "Epoch 391: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0477 - accuracy: 0.9755 - val_loss: 0.2179 - val_accuracy: 0.8871\n",
      "Epoch 392/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0560 - accuracy: 0.9732\n",
      "Epoch 392: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0514 - accuracy: 0.9755 - val_loss: 0.2184 - val_accuracy: 0.8871\n",
      "Epoch 393/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9714\n",
      "Epoch 393: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0557 - accuracy: 0.9714 - val_loss: 0.2080 - val_accuracy: 0.9194\n",
      "Epoch 394/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0550 - accuracy: 0.9688\n",
      "Epoch 394: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0550 - accuracy: 0.9673 - val_loss: 0.2035 - val_accuracy: 0.9194\n",
      "Epoch 395/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9755\n",
      "Epoch 395: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0587 - accuracy: 0.9755 - val_loss: 0.2240 - val_accuracy: 0.9194\n",
      "Epoch 396/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0582 - accuracy: 0.9777\n",
      "Epoch 396: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0645 - accuracy: 0.9714 - val_loss: 0.2028 - val_accuracy: 0.9032\n",
      "Epoch 397/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0485 - accuracy: 0.9688\n",
      "Epoch 397: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0513 - accuracy: 0.9673 - val_loss: 0.2071 - val_accuracy: 0.9032\n",
      "Epoch 398/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0425 - accuracy: 0.9821\n",
      "Epoch 398: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0407 - accuracy: 0.9837 - val_loss: 0.2243 - val_accuracy: 0.9194\n",
      "Epoch 399/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9714\n",
      "Epoch 399: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0579 - accuracy: 0.9714 - val_loss: 0.2446 - val_accuracy: 0.9032\n",
      "Epoch 400/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0571 - accuracy: 0.9732\n",
      "Epoch 400: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0531 - accuracy: 0.9755 - val_loss: 0.2601 - val_accuracy: 0.9032\n",
      "Epoch 401/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9633\n",
      "Epoch 401: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0592 - accuracy: 0.9633 - val_loss: 0.2675 - val_accuracy: 0.9032\n",
      "Epoch 402/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0502 - accuracy: 0.9777\n",
      "Epoch 402: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0484 - accuracy: 0.9796 - val_loss: 0.3105 - val_accuracy: 0.9355\n",
      "Epoch 403/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0457 - accuracy: 0.9777\n",
      "Epoch 403: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0485 - accuracy: 0.9755 - val_loss: 0.5338 - val_accuracy: 0.8387\n",
      "Epoch 404/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9755\n",
      "Epoch 404: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0569 - accuracy: 0.9755 - val_loss: 0.6732 - val_accuracy: 0.7903\n",
      "Epoch 405/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9755\n",
      "Epoch 405: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0547 - accuracy: 0.9755 - val_loss: 0.8700 - val_accuracy: 0.6613\n",
      "Epoch 406/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9633\n",
      "Epoch 406: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0633 - accuracy: 0.9633 - val_loss: 0.4064 - val_accuracy: 0.9194\n",
      "Epoch 407/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9755\n",
      "Epoch 407: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0552 - accuracy: 0.9755 - val_loss: 0.3147 - val_accuracy: 0.9355\n",
      "Epoch 408/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0619 - accuracy: 0.9732\n",
      "Epoch 408: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0566 - accuracy: 0.9755 - val_loss: 0.2208 - val_accuracy: 0.9194\n",
      "Epoch 409/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0520 - accuracy: 0.9688\n",
      "Epoch 409: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0559 - accuracy: 0.9673 - val_loss: 0.2035 - val_accuracy: 0.9194\n",
      "Epoch 410/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9673\n",
      "Epoch 410: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.0547 - accuracy: 0.9673 - val_loss: 0.2185 - val_accuracy: 0.9355\n",
      "Epoch 411/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9755\n",
      "Epoch 411: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0479 - accuracy: 0.9755 - val_loss: 0.2119 - val_accuracy: 0.9032\n",
      "Epoch 412/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9755\n",
      "Epoch 412: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0462 - accuracy: 0.9755 - val_loss: 0.2493 - val_accuracy: 0.9355\n",
      "Epoch 413/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9837\n",
      "Epoch 413: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0463 - accuracy: 0.9837 - val_loss: 0.2926 - val_accuracy: 0.9194\n",
      "Epoch 414/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9633\n",
      "Epoch 414: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0586 - accuracy: 0.9633 - val_loss: 0.2553 - val_accuracy: 0.9194\n",
      "Epoch 415/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0482 - accuracy: 0.9777\n",
      "Epoch 415: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0508 - accuracy: 0.9755 - val_loss: 0.3255 - val_accuracy: 0.8548\n",
      "Epoch 416/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0581 - accuracy: 0.9777\n",
      "Epoch 416: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0561 - accuracy: 0.9796 - val_loss: 0.6260 - val_accuracy: 0.7903\n",
      "Epoch 417/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0453 - accuracy: 0.9777\n",
      "Epoch 417: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0464 - accuracy: 0.9755 - val_loss: 1.1918 - val_accuracy: 0.6290\n",
      "Epoch 418/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9755\n",
      "Epoch 418: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0520 - accuracy: 0.9755 - val_loss: 1.7831 - val_accuracy: 0.5645\n",
      "Epoch 419/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0531 - accuracy: 0.9688\n",
      "Epoch 419: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0486 - accuracy: 0.9714 - val_loss: 1.3217 - val_accuracy: 0.5806\n",
      "Epoch 420/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9837\n",
      "Epoch 420: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0415 - accuracy: 0.9837 - val_loss: 0.5531 - val_accuracy: 0.7903\n",
      "Epoch 421/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0491 - accuracy: 0.9732\n",
      "Epoch 421: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0452 - accuracy: 0.9755 - val_loss: 0.2810 - val_accuracy: 0.9194\n",
      "Epoch 422/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.9673\n",
      "Epoch 422: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0669 - accuracy: 0.9673 - val_loss: 0.4120 - val_accuracy: 0.8065\n",
      "Epoch 423/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0665 - accuracy: 0.9643\n",
      "Epoch 423: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0636 - accuracy: 0.9673 - val_loss: 0.2781 - val_accuracy: 0.9355\n",
      "Epoch 424/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0551 - accuracy: 0.9732\n",
      "Epoch 424: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0506 - accuracy: 0.9755 - val_loss: 0.5358 - val_accuracy: 0.8548\n",
      "Epoch 425/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.9714\n",
      "Epoch 425: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0550 - accuracy: 0.9714 - val_loss: 0.6230 - val_accuracy: 0.8710\n",
      "Epoch 426/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9796\n",
      "Epoch 426: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0489 - accuracy: 0.9796 - val_loss: 0.5087 - val_accuracy: 0.8871\n",
      "Epoch 427/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0480 - accuracy: 0.9777\n",
      "Epoch 427: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0530 - accuracy: 0.9755 - val_loss: 0.6200 - val_accuracy: 0.8548\n",
      "Epoch 428/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9755\n",
      "Epoch 428: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0528 - accuracy: 0.9755 - val_loss: 0.7581 - val_accuracy: 0.8226\n",
      "Epoch 429/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9755\n",
      "Epoch 429: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0578 - accuracy: 0.9755 - val_loss: 0.9648 - val_accuracy: 0.8065\n",
      "Epoch 430/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0487 - accuracy: 0.9732\n",
      "Epoch 430: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0556 - accuracy: 0.9673 - val_loss: 0.7728 - val_accuracy: 0.8226\n",
      "Epoch 431/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0558 - accuracy: 0.9688\n",
      "Epoch 431: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0586 - accuracy: 0.9673 - val_loss: 0.6435 - val_accuracy: 0.8226\n",
      "Epoch 432/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0467 - accuracy: 0.9732\n",
      "Epoch 432: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0514 - accuracy: 0.9714 - val_loss: 0.5471 - val_accuracy: 0.8548\n",
      "Epoch 433/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9755\n",
      "Epoch 433: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0535 - accuracy: 0.9755 - val_loss: 0.4843 - val_accuracy: 0.8387\n",
      "Epoch 434/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0635 - accuracy: 0.9688\n",
      "Epoch 434: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0598 - accuracy: 0.9714 - val_loss: 0.4665 - val_accuracy: 0.8065\n",
      "Epoch 435/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9755\n",
      "Epoch 435: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0501 - accuracy: 0.9755 - val_loss: 0.4324 - val_accuracy: 0.8226\n",
      "Epoch 436/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9755\n",
      "Epoch 436: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0467 - accuracy: 0.9755 - val_loss: 0.3257 - val_accuracy: 0.8871\n",
      "Epoch 437/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0549 - accuracy: 0.9598\n",
      "Epoch 437: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0574 - accuracy: 0.9633 - val_loss: 0.2895 - val_accuracy: 0.9032\n",
      "Epoch 438/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0442 - accuracy: 0.9821\n",
      "Epoch 438: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0580 - accuracy: 0.9755 - val_loss: 0.2187 - val_accuracy: 0.9194\n",
      "Epoch 439/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9796\n",
      "Epoch 439: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0457 - accuracy: 0.9796 - val_loss: 0.2074 - val_accuracy: 0.9194\n",
      "Epoch 440/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9714\n",
      "Epoch 440: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0534 - accuracy: 0.9714 - val_loss: 0.3035 - val_accuracy: 0.9032\n",
      "Epoch 441/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9592\n",
      "Epoch 441: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0595 - accuracy: 0.9592 - val_loss: 0.4306 - val_accuracy: 0.8226\n",
      "Epoch 442/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9796\n",
      "Epoch 442: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0463 - accuracy: 0.9796 - val_loss: 0.3943 - val_accuracy: 0.8226\n",
      "Epoch 443/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0511 - accuracy: 0.9732\n",
      "Epoch 443: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0538 - accuracy: 0.9714 - val_loss: 0.3604 - val_accuracy: 0.7903\n",
      "Epoch 444/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0642 - accuracy: 0.9643\n",
      "Epoch 444: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0619 - accuracy: 0.9633 - val_loss: 0.3408 - val_accuracy: 0.8710\n",
      "Epoch 445/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9755\n",
      "Epoch 445: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0528 - accuracy: 0.9755 - val_loss: 0.4199 - val_accuracy: 0.8226\n",
      "Epoch 446/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9673\n",
      "Epoch 446: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0598 - accuracy: 0.9673 - val_loss: 0.4280 - val_accuracy: 0.8226\n",
      "Epoch 447/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9673\n",
      "Epoch 447: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0580 - accuracy: 0.9673 - val_loss: 0.4329 - val_accuracy: 0.8226\n",
      "Epoch 448/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0403 - accuracy: 0.9821\n",
      "Epoch 448: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0529 - accuracy: 0.9755 - val_loss: 0.3051 - val_accuracy: 0.8387\n",
      "Epoch 449/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0484 - accuracy: 0.9777\n",
      "Epoch 449: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0499 - accuracy: 0.9755 - val_loss: 0.2994 - val_accuracy: 0.8548\n",
      "Epoch 450/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0569 - accuracy: 0.9688\n",
      "Epoch 450: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0534 - accuracy: 0.9714 - val_loss: 0.2336 - val_accuracy: 0.9194\n",
      "Epoch 451/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0463 - accuracy: 0.9732\n",
      "Epoch 451: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0501 - accuracy: 0.9673 - val_loss: 0.2070 - val_accuracy: 0.9355\n",
      "Epoch 452/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0713 - accuracy: 0.9643\n",
      "Epoch 452: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0666 - accuracy: 0.9673 - val_loss: 0.2023 - val_accuracy: 0.9194\n",
      "Epoch 453/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9796\n",
      "Epoch 453: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0503 - accuracy: 0.9796 - val_loss: 0.2469 - val_accuracy: 0.8548\n",
      "Epoch 454/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9796\n",
      "Epoch 454: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0506 - accuracy: 0.9796 - val_loss: 0.3460 - val_accuracy: 0.8226\n",
      "Epoch 455/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0486 - accuracy: 0.9777\n",
      "Epoch 455: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0508 - accuracy: 0.9755 - val_loss: 0.3900 - val_accuracy: 0.8226\n",
      "Epoch 456/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0596 - accuracy: 0.9688\n",
      "Epoch 456: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0659 - accuracy: 0.9673 - val_loss: 0.4551 - val_accuracy: 0.8226\n",
      "Epoch 457/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0475 - accuracy: 0.9688\n",
      "Epoch 457: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0454 - accuracy: 0.9714 - val_loss: 0.6286 - val_accuracy: 0.7581\n",
      "Epoch 458/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0621 - accuracy: 0.9732\n",
      "Epoch 458: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0606 - accuracy: 0.9755 - val_loss: 1.0201 - val_accuracy: 0.5806\n",
      "Epoch 459/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9755\n",
      "Epoch 459: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0569 - accuracy: 0.9755 - val_loss: 1.0401 - val_accuracy: 0.6129\n",
      "Epoch 460/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9755\n",
      "Epoch 460: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0519 - accuracy: 0.9755 - val_loss: 0.6571 - val_accuracy: 0.7581\n",
      "Epoch 461/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0532 - accuracy: 0.9732\n",
      "Epoch 461: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0522 - accuracy: 0.9755 - val_loss: 1.2906 - val_accuracy: 0.5645\n",
      "Epoch 462/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0551 - accuracy: 0.9732\n",
      "Epoch 462: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0519 - accuracy: 0.9755 - val_loss: 1.7020 - val_accuracy: 0.5000\n",
      "Epoch 463/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0521 - accuracy: 0.9777\n",
      "Epoch 463: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0545 - accuracy: 0.9755 - val_loss: 2.0168 - val_accuracy: 0.5000\n",
      "Epoch 464/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9714\n",
      "Epoch 464: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0497 - accuracy: 0.9714 - val_loss: 1.6070 - val_accuracy: 0.5161\n",
      "Epoch 465/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0445 - accuracy: 0.9732\n",
      "Epoch 465: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0524 - accuracy: 0.9633 - val_loss: 1.0504 - val_accuracy: 0.5645\n",
      "Epoch 466/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9714\n",
      "Epoch 466: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0517 - accuracy: 0.9714 - val_loss: 0.2943 - val_accuracy: 0.8548\n",
      "Epoch 467/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9633\n",
      "Epoch 467: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0514 - accuracy: 0.9633 - val_loss: 0.2102 - val_accuracy: 0.9355\n",
      "Epoch 468/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0553 - accuracy: 0.9777\n",
      "Epoch 468: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0534 - accuracy: 0.9796 - val_loss: 0.2180 - val_accuracy: 0.9194\n",
      "Epoch 469/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0627 - accuracy: 0.9732\n",
      "Epoch 469: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0577 - accuracy: 0.9755 - val_loss: 0.2474 - val_accuracy: 0.9194\n",
      "Epoch 470/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0516 - accuracy: 0.9777\n",
      "Epoch 470: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0530 - accuracy: 0.9755 - val_loss: 0.3174 - val_accuracy: 0.9194\n",
      "Epoch 471/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9796\n",
      "Epoch 471: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0541 - accuracy: 0.9796 - val_loss: 0.2640 - val_accuracy: 0.9194\n",
      "Epoch 472/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9714\n",
      "Epoch 472: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0510 - accuracy: 0.9714 - val_loss: 0.2815 - val_accuracy: 0.9194\n",
      "Epoch 473/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9714\n",
      "Epoch 473: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0595 - accuracy: 0.9714 - val_loss: 0.2230 - val_accuracy: 0.9194\n",
      "Epoch 474/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0517 - accuracy: 0.9732\n",
      "Epoch 474: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0474 - accuracy: 0.9755 - val_loss: 0.2505 - val_accuracy: 0.9194\n",
      "Epoch 475/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0583 - accuracy: 0.9598\n",
      "Epoch 475: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0567 - accuracy: 0.9592 - val_loss: 0.2177 - val_accuracy: 0.9194\n",
      "Epoch 476/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0530 - accuracy: 0.9732\n",
      "Epoch 476: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0577 - accuracy: 0.9714 - val_loss: 0.2030 - val_accuracy: 0.9355\n",
      "Epoch 477/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0550 - accuracy: 0.9732\n",
      "Epoch 477: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0519 - accuracy: 0.9755 - val_loss: 0.2134 - val_accuracy: 0.9355\n",
      "Epoch 478/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9755\n",
      "Epoch 478: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0517 - accuracy: 0.9755 - val_loss: 0.2344 - val_accuracy: 0.9355\n",
      "Epoch 479/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0561 - accuracy: 0.9732\n",
      "Epoch 479: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0569 - accuracy: 0.9714 - val_loss: 1.3092 - val_accuracy: 0.5000\n",
      "Epoch 480/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9755\n",
      "Epoch 480: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0496 - accuracy: 0.9755 - val_loss: 1.2008 - val_accuracy: 0.5161\n",
      "Epoch 481/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9714\n",
      "Epoch 481: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0587 - accuracy: 0.9714 - val_loss: 0.3943 - val_accuracy: 0.8871\n",
      "Epoch 482/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0496 - accuracy: 0.9732\n",
      "Epoch 482: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0465 - accuracy: 0.9755 - val_loss: 0.1635 - val_accuracy: 0.9194\n",
      "Epoch 483/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0503 - accuracy: 0.9777\n",
      "Epoch 483: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0510 - accuracy: 0.9755 - val_loss: 0.1710 - val_accuracy: 0.9032\n",
      "Epoch 484/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9837\n",
      "Epoch 484: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0446 - accuracy: 0.9837 - val_loss: 0.1801 - val_accuracy: 0.9355\n",
      "Epoch 485/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9633\n",
      "Epoch 485: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0638 - accuracy: 0.9633 - val_loss: 0.1977 - val_accuracy: 0.9194\n",
      "Epoch 486/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0444 - accuracy: 0.9777\n",
      "Epoch 486: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0464 - accuracy: 0.9755 - val_loss: 0.2207 - val_accuracy: 0.9194\n",
      "Epoch 487/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9714\n",
      "Epoch 487: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0565 - accuracy: 0.9714 - val_loss: 0.2237 - val_accuracy: 0.9194\n",
      "Epoch 488/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9714\n",
      "Epoch 488: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0512 - accuracy: 0.9714 - val_loss: 0.2372 - val_accuracy: 0.9194\n",
      "Epoch 489/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9755\n",
      "Epoch 489: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0483 - accuracy: 0.9755 - val_loss: 0.2116 - val_accuracy: 0.9194\n",
      "Epoch 490/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9633\n",
      "Epoch 490: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0536 - accuracy: 0.9633 - val_loss: 0.2092 - val_accuracy: 0.9194\n",
      "Epoch 491/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0458 - accuracy: 0.9777\n",
      "Epoch 491: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0505 - accuracy: 0.9714 - val_loss: 0.1926 - val_accuracy: 0.9355\n",
      "Epoch 492/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0400 - accuracy: 0.9821\n",
      "Epoch 492: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0512 - accuracy: 0.9755 - val_loss: 0.2362 - val_accuracy: 0.9032\n",
      "Epoch 493/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9673\n",
      "Epoch 493: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0598 - accuracy: 0.9673 - val_loss: 0.2850 - val_accuracy: 0.9032\n",
      "Epoch 494/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0546 - accuracy: 0.9688\n",
      "Epoch 494: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0500 - accuracy: 0.9714 - val_loss: 0.4637 - val_accuracy: 0.8226\n",
      "Epoch 495/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0492 - accuracy: 0.9821\n",
      "Epoch 495: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0500 - accuracy: 0.9837 - val_loss: 0.8053 - val_accuracy: 0.7581\n",
      "Epoch 496/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9714\n",
      "Epoch 496: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0560 - accuracy: 0.9714 - val_loss: 1.2398 - val_accuracy: 0.7258\n",
      "Epoch 497/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0541 - accuracy: 0.9732\n",
      "Epoch 497: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0511 - accuracy: 0.9755 - val_loss: 1.3595 - val_accuracy: 0.7097\n",
      "Epoch 498/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0558 - accuracy: 0.9688\n",
      "Epoch 498: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0514 - accuracy: 0.9714 - val_loss: 1.2198 - val_accuracy: 0.7419\n",
      "Epoch 499/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9714\n",
      "Epoch 499: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0524 - accuracy: 0.9714 - val_loss: 0.9169 - val_accuracy: 0.7742\n",
      "Epoch 500/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9673\n",
      "Epoch 500: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0653 - accuracy: 0.9673 - val_loss: 0.4506 - val_accuracy: 0.8871\n",
      "Epoch 501/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9755\n",
      "Epoch 501: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0487 - accuracy: 0.9755 - val_loss: 0.3738 - val_accuracy: 0.9032\n",
      "Epoch 502/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0543 - accuracy: 0.9777\n",
      "Epoch 502: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0549 - accuracy: 0.9796 - val_loss: 0.3471 - val_accuracy: 0.9032\n",
      "Epoch 503/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9755\n",
      "Epoch 503: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0513 - accuracy: 0.9755 - val_loss: 0.4274 - val_accuracy: 0.8871\n",
      "Epoch 504/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9633\n",
      "Epoch 504: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0568 - accuracy: 0.9633 - val_loss: 0.3408 - val_accuracy: 0.9032\n",
      "Epoch 505/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9673\n",
      "Epoch 505: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0562 - accuracy: 0.9673 - val_loss: 0.3129 - val_accuracy: 0.9032\n",
      "Epoch 506/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0450 - accuracy: 0.9688\n",
      "Epoch 506: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0471 - accuracy: 0.9673 - val_loss: 0.2951 - val_accuracy: 0.9194\n",
      "Epoch 507/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0562 - accuracy: 0.9732\n",
      "Epoch 507: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0536 - accuracy: 0.9755 - val_loss: 0.3241 - val_accuracy: 0.9194\n",
      "Epoch 508/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9755\n",
      "Epoch 508: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0508 - accuracy: 0.9755 - val_loss: 0.3516 - val_accuracy: 0.9032\n",
      "Epoch 509/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0513 - accuracy: 0.9777\n",
      "Epoch 509: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0481 - accuracy: 0.9796 - val_loss: 0.3817 - val_accuracy: 0.9032\n",
      "Epoch 510/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0497 - accuracy: 0.9821\n",
      "Epoch 510: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0455 - accuracy: 0.9837 - val_loss: 0.3365 - val_accuracy: 0.9032\n",
      "Epoch 511/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9673\n",
      "Epoch 511: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.0579 - accuracy: 0.9673 - val_loss: 0.3560 - val_accuracy: 0.9032\n",
      "Epoch 512/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9714\n",
      "Epoch 512: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0584 - accuracy: 0.9714 - val_loss: 0.4072 - val_accuracy: 0.9032\n",
      "Epoch 513/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0519 - accuracy: 0.9643\n",
      "Epoch 513: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.0490 - accuracy: 0.9673 - val_loss: 0.4208 - val_accuracy: 0.8871\n",
      "Epoch 514/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0523 - accuracy: 0.9688\n",
      "Epoch 514: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0557 - accuracy: 0.9673 - val_loss: 0.4320 - val_accuracy: 0.9032\n",
      "Epoch 515/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0490 - accuracy: 0.9688\n",
      "Epoch 515: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0494 - accuracy: 0.9714 - val_loss: 0.4297 - val_accuracy: 0.9194\n",
      "Epoch 516/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9755\n",
      "Epoch 516: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0511 - accuracy: 0.9755 - val_loss: 0.3378 - val_accuracy: 0.9194\n",
      "Epoch 517/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0524 - accuracy: 0.9732\n",
      "Epoch 517: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0521 - accuracy: 0.9755 - val_loss: 0.3902 - val_accuracy: 0.8710\n",
      "Epoch 518/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9673\n",
      "Epoch 518: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0543 - accuracy: 0.9673 - val_loss: 0.4837 - val_accuracy: 0.8548\n",
      "Epoch 519/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9714\n",
      "Epoch 519: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0506 - accuracy: 0.9714 - val_loss: 0.4808 - val_accuracy: 0.8548\n",
      "Epoch 520/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9714\n",
      "Epoch 520: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0615 - accuracy: 0.9714 - val_loss: 0.7623 - val_accuracy: 0.7742\n",
      "Epoch 521/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9633\n",
      "Epoch 521: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0572 - accuracy: 0.9633 - val_loss: 0.4633 - val_accuracy: 0.8226\n",
      "Epoch 522/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9714\n",
      "Epoch 522: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0565 - accuracy: 0.9714 - val_loss: 0.3072 - val_accuracy: 0.9355\n",
      "Epoch 523/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0525 - accuracy: 0.9821\n",
      "Epoch 523: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0495 - accuracy: 0.9837 - val_loss: 0.3250 - val_accuracy: 0.9355\n",
      "Epoch 524/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0474 - accuracy: 0.9777\n",
      "Epoch 524: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0477 - accuracy: 0.9755 - val_loss: 0.4308 - val_accuracy: 0.8226\n",
      "Epoch 525/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9714\n",
      "Epoch 525: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.0487 - accuracy: 0.9714 - val_loss: 0.8578 - val_accuracy: 0.7581\n",
      "Epoch 526/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9633\n",
      "Epoch 526: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.0486 - accuracy: 0.9633 - val_loss: 0.8305 - val_accuracy: 0.7742\n",
      "Epoch 527/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9755\n",
      "Epoch 527: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.0482 - accuracy: 0.9755 - val_loss: 0.8808 - val_accuracy: 0.7742\n",
      "Epoch 528/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0572 - accuracy: 0.9732\n",
      "Epoch 528: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0550 - accuracy: 0.9755 - val_loss: 0.8164 - val_accuracy: 0.7903\n",
      "Epoch 529/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0571 - accuracy: 0.9688\n",
      "Epoch 529: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0538 - accuracy: 0.9714 - val_loss: 0.5030 - val_accuracy: 0.8226\n",
      "Epoch 530/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9796\n",
      "Epoch 530: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0513 - accuracy: 0.9796 - val_loss: 0.3381 - val_accuracy: 0.9355\n",
      "Epoch 531/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0483 - accuracy: 0.9732\n",
      "Epoch 531: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0478 - accuracy: 0.9714 - val_loss: 0.3546 - val_accuracy: 0.8710\n",
      "Epoch 532/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9837\n",
      "Epoch 532: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0497 - accuracy: 0.9837 - val_loss: 0.2318 - val_accuracy: 0.9355\n",
      "Epoch 533/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0488 - accuracy: 0.9777\n",
      "Epoch 533: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0448 - accuracy: 0.9796 - val_loss: 0.2322 - val_accuracy: 0.8871\n",
      "Epoch 534/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9633\n",
      "Epoch 534: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0582 - accuracy: 0.9633 - val_loss: 0.3183 - val_accuracy: 0.9032\n",
      "Epoch 535/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0474 - accuracy: 0.9732\n",
      "Epoch 535: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0469 - accuracy: 0.9755 - val_loss: 0.3047 - val_accuracy: 0.9032\n",
      "Epoch 536/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0533 - accuracy: 0.9732\n",
      "Epoch 536: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0487 - accuracy: 0.9755 - val_loss: 0.2248 - val_accuracy: 0.8871\n",
      "Epoch 537/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9837\n",
      "Epoch 537: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0485 - accuracy: 0.9837 - val_loss: 0.2607 - val_accuracy: 0.9032\n",
      "Epoch 538/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9796\n",
      "Epoch 538: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0518 - accuracy: 0.9796 - val_loss: 0.2628 - val_accuracy: 0.9194\n",
      "Epoch 539/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0539 - accuracy: 0.9688\n",
      "Epoch 539: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0555 - accuracy: 0.9673 - val_loss: 0.2267 - val_accuracy: 0.9194\n",
      "Epoch 540/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0478 - accuracy: 0.9777\n",
      "Epoch 540: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0490 - accuracy: 0.9755 - val_loss: 0.2155 - val_accuracy: 0.9032\n",
      "Epoch 541/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9673\n",
      "Epoch 541: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0586 - accuracy: 0.9673 - val_loss: 0.2027 - val_accuracy: 0.8871\n",
      "Epoch 542/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0624 - accuracy: 0.9554\n",
      "Epoch 542: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0573 - accuracy: 0.9592 - val_loss: 0.1830 - val_accuracy: 0.9194\n",
      "Epoch 543/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9755\n",
      "Epoch 543: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0564 - accuracy: 0.9755 - val_loss: 0.1730 - val_accuracy: 0.9355\n",
      "Epoch 544/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9796\n",
      "Epoch 544: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0534 - accuracy: 0.9796 - val_loss: 0.1818 - val_accuracy: 0.9194\n",
      "Epoch 545/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0491 - accuracy: 0.9688\n",
      "Epoch 545: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0463 - accuracy: 0.9714 - val_loss: 0.1989 - val_accuracy: 0.9194\n",
      "Epoch 546/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9633\n",
      "Epoch 546: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0600 - accuracy: 0.9633 - val_loss: 0.1918 - val_accuracy: 0.9194\n",
      "Epoch 547/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0483 - accuracy: 0.9732\n",
      "Epoch 547: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0513 - accuracy: 0.9755 - val_loss: 0.1924 - val_accuracy: 0.9194\n",
      "Epoch 548/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9755\n",
      "Epoch 548: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0460 - accuracy: 0.9755 - val_loss: 0.1821 - val_accuracy: 0.9355\n",
      "Epoch 549/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0556 - accuracy: 0.9688\n",
      "Epoch 549: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0551 - accuracy: 0.9714 - val_loss: 0.1601 - val_accuracy: 0.9355\n",
      "Epoch 550/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9755\n",
      "Epoch 550: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0545 - accuracy: 0.9755 - val_loss: 0.1479 - val_accuracy: 0.9355\n",
      "Epoch 551/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9755\n",
      "Epoch 551: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0507 - accuracy: 0.9755 - val_loss: 0.1791 - val_accuracy: 0.9355\n",
      "Epoch 552/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0464 - accuracy: 0.9777\n",
      "Epoch 552: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0507 - accuracy: 0.9755 - val_loss: 0.2345 - val_accuracy: 0.9032\n",
      "Epoch 553/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9755\n",
      "Epoch 553: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0491 - accuracy: 0.9755 - val_loss: 0.2511 - val_accuracy: 0.9032\n",
      "Epoch 554/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0497 - accuracy: 0.9688\n",
      "Epoch 554: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0483 - accuracy: 0.9714 - val_loss: 0.2429 - val_accuracy: 0.9194\n",
      "Epoch 555/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9714\n",
      "Epoch 555: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0552 - accuracy: 0.9714 - val_loss: 0.3111 - val_accuracy: 0.8548\n",
      "Epoch 556/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0437 - accuracy: 0.9732\n",
      "Epoch 556: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0433 - accuracy: 0.9714 - val_loss: 0.3620 - val_accuracy: 0.8226\n",
      "Epoch 557/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9755\n",
      "Epoch 557: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0623 - accuracy: 0.9755 - val_loss: 0.3910 - val_accuracy: 0.8387\n",
      "Epoch 558/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9714\n",
      "Epoch 558: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0615 - accuracy: 0.9714 - val_loss: 0.4100 - val_accuracy: 0.8548\n",
      "Epoch 559/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9714\n",
      "Epoch 559: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0544 - accuracy: 0.9714 - val_loss: 0.3501 - val_accuracy: 0.8871\n",
      "Epoch 560/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9796\n",
      "Epoch 560: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0469 - accuracy: 0.9796 - val_loss: 0.3483 - val_accuracy: 0.9032\n",
      "Epoch 561/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0552 - accuracy: 0.9732\n",
      "Epoch 561: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0526 - accuracy: 0.9755 - val_loss: 0.5380 - val_accuracy: 0.8065\n",
      "Epoch 562/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0723 - accuracy: 0.9554\n",
      "Epoch 562: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0663 - accuracy: 0.9592 - val_loss: 0.8316 - val_accuracy: 0.7742\n",
      "Epoch 563/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0510 - accuracy: 0.9777\n",
      "Epoch 563: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0538 - accuracy: 0.9755 - val_loss: 0.8288 - val_accuracy: 0.7742\n",
      "Epoch 564/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9755\n",
      "Epoch 564: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0507 - accuracy: 0.9755 - val_loss: 0.5400 - val_accuracy: 0.8065\n",
      "Epoch 565/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9755\n",
      "Epoch 565: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0442 - accuracy: 0.9755 - val_loss: 0.4329 - val_accuracy: 0.8871\n",
      "Epoch 566/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9714\n",
      "Epoch 566: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0506 - accuracy: 0.9714 - val_loss: 0.3603 - val_accuracy: 0.9194\n",
      "Epoch 567/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9755\n",
      "Epoch 567: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0520 - accuracy: 0.9755 - val_loss: 0.3033 - val_accuracy: 0.9194\n",
      "Epoch 568/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9755\n",
      "Epoch 568: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0563 - accuracy: 0.9755 - val_loss: 0.2304 - val_accuracy: 0.9355\n",
      "Epoch 569/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0661 - accuracy: 0.9688\n",
      "Epoch 569: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0605 - accuracy: 0.9714 - val_loss: 0.2146 - val_accuracy: 0.9355\n",
      "Epoch 570/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0600 - accuracy: 0.9643\n",
      "Epoch 570: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0549 - accuracy: 0.9673 - val_loss: 0.1696 - val_accuracy: 0.9355\n",
      "Epoch 571/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9755\n",
      "Epoch 571: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0483 - accuracy: 0.9755 - val_loss: 0.1885 - val_accuracy: 0.9355\n",
      "Epoch 572/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9714\n",
      "Epoch 572: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0527 - accuracy: 0.9714 - val_loss: 0.2061 - val_accuracy: 0.9355\n",
      "Epoch 573/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0410 - accuracy: 0.9777\n",
      "Epoch 573: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0532 - accuracy: 0.9714 - val_loss: 0.1836 - val_accuracy: 0.9516\n",
      "Epoch 574/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9673\n",
      "Epoch 574: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0544 - accuracy: 0.9673 - val_loss: 0.1926 - val_accuracy: 0.9355\n",
      "Epoch 575/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9510\n",
      "Epoch 575: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0718 - accuracy: 0.9510 - val_loss: 0.1952 - val_accuracy: 0.9194\n",
      "Epoch 576/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9796\n",
      "Epoch 576: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0434 - accuracy: 0.9796 - val_loss: 0.2089 - val_accuracy: 0.9355\n",
      "Epoch 577/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9714\n",
      "Epoch 577: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0540 - accuracy: 0.9714 - val_loss: 0.2238 - val_accuracy: 0.9355\n",
      "Epoch 578/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0547 - accuracy: 0.9688\n",
      "Epoch 578: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0503 - accuracy: 0.9714 - val_loss: 0.3755 - val_accuracy: 0.8710\n",
      "Epoch 579/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0500 - accuracy: 0.9777\n",
      "Epoch 579: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0510 - accuracy: 0.9755 - val_loss: 0.5611 - val_accuracy: 0.8226\n",
      "Epoch 580/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0624 - accuracy: 0.9643\n",
      "Epoch 580: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0591 - accuracy: 0.9673 - val_loss: 0.5714 - val_accuracy: 0.7903\n",
      "Epoch 581/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0496 - accuracy: 0.9777\n",
      "Epoch 581: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0517 - accuracy: 0.9755 - val_loss: 0.5530 - val_accuracy: 0.8065\n",
      "Epoch 582/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9673\n",
      "Epoch 582: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0506 - accuracy: 0.9673 - val_loss: 0.4648 - val_accuracy: 0.8226\n",
      "Epoch 583/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0584 - accuracy: 0.9732\n",
      "Epoch 583: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0543 - accuracy: 0.9755 - val_loss: 0.6591 - val_accuracy: 0.7903\n",
      "Epoch 584/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0550 - accuracy: 0.9732\n",
      "Epoch 584: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0519 - accuracy: 0.9755 - val_loss: 0.4928 - val_accuracy: 0.8548\n",
      "Epoch 585/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0388 - accuracy: 0.9866\n",
      "Epoch 585: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0413 - accuracy: 0.9837 - val_loss: 0.4057 - val_accuracy: 0.8710\n",
      "Epoch 586/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0493 - accuracy: 0.9777\n",
      "Epoch 586: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0524 - accuracy: 0.9714 - val_loss: 0.3510 - val_accuracy: 0.8871\n",
      "Epoch 587/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0530 - accuracy: 0.9732\n",
      "Epoch 587: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0485 - accuracy: 0.9755 - val_loss: 0.2940 - val_accuracy: 0.8710\n",
      "Epoch 588/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9633\n",
      "Epoch 588: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0600 - accuracy: 0.9633 - val_loss: 0.4319 - val_accuracy: 0.8387\n",
      "Epoch 589/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.9633\n",
      "Epoch 589: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0664 - accuracy: 0.9633 - val_loss: 0.3099 - val_accuracy: 0.8871\n",
      "Epoch 590/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0672 - accuracy: 0.9554\n",
      "Epoch 590: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0634 - accuracy: 0.9592 - val_loss: 0.3764 - val_accuracy: 0.8226\n",
      "Epoch 591/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0643 - accuracy: 0.9554\n",
      "Epoch 591: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0601 - accuracy: 0.9592 - val_loss: 0.2706 - val_accuracy: 0.9194\n",
      "Epoch 592/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9755\n",
      "Epoch 592: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0541 - accuracy: 0.9755 - val_loss: 0.2694 - val_accuracy: 0.9194\n",
      "Epoch 593/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9755\n",
      "Epoch 593: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0513 - accuracy: 0.9755 - val_loss: 0.2603 - val_accuracy: 0.9194\n",
      "Epoch 594/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9755\n",
      "Epoch 594: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0499 - accuracy: 0.9755 - val_loss: 0.1893 - val_accuracy: 0.9516\n",
      "Epoch 595/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9796\n",
      "Epoch 595: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0583 - accuracy: 0.9796 - val_loss: 0.2306 - val_accuracy: 0.9194\n",
      "Epoch 596/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0452 - accuracy: 0.9732\n",
      "Epoch 596: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0466 - accuracy: 0.9714 - val_loss: 0.2352 - val_accuracy: 0.9194\n",
      "Epoch 597/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9837\n",
      "Epoch 597: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0383 - accuracy: 0.9837 - val_loss: 0.2387 - val_accuracy: 0.9194\n",
      "Epoch 598/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0493 - accuracy: 0.9777\n",
      "Epoch 598: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0544 - accuracy: 0.9755 - val_loss: 0.2259 - val_accuracy: 0.9194\n",
      "Epoch 599/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9837\n",
      "Epoch 599: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0459 - accuracy: 0.9837 - val_loss: 0.2636 - val_accuracy: 0.9032\n",
      "Epoch 600/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9714\n",
      "Epoch 600: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0658 - accuracy: 0.9714 - val_loss: 0.2253 - val_accuracy: 0.9355\n",
      "Epoch 601/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9673\n",
      "Epoch 601: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0518 - accuracy: 0.9673 - val_loss: 0.2424 - val_accuracy: 0.9194\n",
      "Epoch 602/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9755\n",
      "Epoch 602: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0517 - accuracy: 0.9755 - val_loss: 0.2030 - val_accuracy: 0.9355\n",
      "Epoch 603/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9633\n",
      "Epoch 603: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0524 - accuracy: 0.9633 - val_loss: 0.1790 - val_accuracy: 0.9355\n",
      "Epoch 604/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9673\n",
      "Epoch 604: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0630 - accuracy: 0.9673 - val_loss: 0.1797 - val_accuracy: 0.9355\n",
      "Epoch 605/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9796\n",
      "Epoch 605: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0537 - accuracy: 0.9796 - val_loss: 0.3131 - val_accuracy: 0.8710\n",
      "Epoch 606/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0455 - accuracy: 0.9777\n",
      "Epoch 606: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0527 - accuracy: 0.9755 - val_loss: 0.2958 - val_accuracy: 0.8710\n",
      "Epoch 607/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9755\n",
      "Epoch 607: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0503 - accuracy: 0.9755 - val_loss: 0.3138 - val_accuracy: 0.8710\n",
      "Epoch 608/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9755\n",
      "Epoch 608: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0526 - accuracy: 0.9755 - val_loss: 0.2697 - val_accuracy: 0.8710\n",
      "Epoch 609/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9755\n",
      "Epoch 609: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0409 - accuracy: 0.9755 - val_loss: 0.2653 - val_accuracy: 0.9032\n",
      "Epoch 610/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0517 - accuracy: 0.9732\n",
      "Epoch 610: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0517 - accuracy: 0.9714 - val_loss: 0.2735 - val_accuracy: 0.9032\n",
      "Epoch 611/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0521 - accuracy: 0.9643\n",
      "Epoch 611: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0504 - accuracy: 0.9673 - val_loss: 0.2505 - val_accuracy: 0.9194\n",
      "Epoch 612/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9755\n",
      "Epoch 612: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0488 - accuracy: 0.9755 - val_loss: 0.2792 - val_accuracy: 0.9032\n",
      "Epoch 613/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9714\n",
      "Epoch 613: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0523 - accuracy: 0.9714 - val_loss: 0.2497 - val_accuracy: 0.9032\n",
      "Epoch 614/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9714\n",
      "Epoch 614: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.0535 - accuracy: 0.9714 - val_loss: 0.2455 - val_accuracy: 0.9032\n",
      "Epoch 615/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9673\n",
      "Epoch 615: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.0637 - accuracy: 0.9673 - val_loss: 0.2691 - val_accuracy: 0.8871\n",
      "Epoch 616/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0519 - accuracy: 0.9732\n",
      "Epoch 616: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0544 - accuracy: 0.9673 - val_loss: 0.3066 - val_accuracy: 0.8710\n",
      "Epoch 617/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0384 - accuracy: 0.9821\n",
      "Epoch 617: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.0529 - accuracy: 0.9755 - val_loss: 0.3433 - val_accuracy: 0.8710\n",
      "Epoch 618/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0370 - accuracy: 0.9866\n",
      "Epoch 618: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0411 - accuracy: 0.9837 - val_loss: 0.2546 - val_accuracy: 0.8871\n",
      "Epoch 619/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9633\n",
      "Epoch 619: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0573 - accuracy: 0.9633 - val_loss: 0.2301 - val_accuracy: 0.8871\n",
      "Epoch 620/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9673\n",
      "Epoch 620: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0613 - accuracy: 0.9673 - val_loss: 0.2802 - val_accuracy: 0.9194\n",
      "Epoch 621/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9755\n",
      "Epoch 621: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0598 - accuracy: 0.9755 - val_loss: 0.2828 - val_accuracy: 0.9194\n",
      "Epoch 622/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9755\n",
      "Epoch 622: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.0539 - accuracy: 0.9755 - val_loss: 0.2597 - val_accuracy: 0.9194\n",
      "Epoch 623/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9592\n",
      "Epoch 623: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0576 - accuracy: 0.9592 - val_loss: 0.1947 - val_accuracy: 0.9355\n",
      "Epoch 624/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9633\n",
      "Epoch 624: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0661 - accuracy: 0.9633 - val_loss: 0.2223 - val_accuracy: 0.9032\n",
      "Epoch 625/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9755\n",
      "Epoch 625: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0442 - accuracy: 0.9755 - val_loss: 0.2859 - val_accuracy: 0.9355\n",
      "Epoch 626/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9714\n",
      "Epoch 626: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0527 - accuracy: 0.9714 - val_loss: 0.3614 - val_accuracy: 0.8710\n",
      "Epoch 627/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0554 - accuracy: 0.9688\n",
      "Epoch 627: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0524 - accuracy: 0.9714 - val_loss: 0.3022 - val_accuracy: 0.9355\n",
      "Epoch 628/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9755\n",
      "Epoch 628: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0475 - accuracy: 0.9755 - val_loss: 0.2295 - val_accuracy: 0.9194\n",
      "Epoch 629/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9673\n",
      "Epoch 629: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0481 - accuracy: 0.9673 - val_loss: 0.2185 - val_accuracy: 0.9355\n",
      "Epoch 630/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9592\n",
      "Epoch 630: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0707 - accuracy: 0.9592 - val_loss: 0.2988 - val_accuracy: 0.9194\n",
      "Epoch 631/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9714\n",
      "Epoch 631: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0541 - accuracy: 0.9714 - val_loss: 0.3760 - val_accuracy: 0.8387\n",
      "Epoch 632/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9633\n",
      "Epoch 632: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 61ms/step - loss: 0.0553 - accuracy: 0.9633 - val_loss: 0.3967 - val_accuracy: 0.9194\n",
      "Epoch 633/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9714\n",
      "Epoch 633: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0525 - accuracy: 0.9714 - val_loss: 0.3649 - val_accuracy: 0.9032\n",
      "Epoch 634/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9755\n",
      "Epoch 634: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0543 - accuracy: 0.9755 - val_loss: 0.4085 - val_accuracy: 0.8387\n",
      "Epoch 635/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9755\n",
      "Epoch 635: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0445 - accuracy: 0.9755 - val_loss: 0.4069 - val_accuracy: 0.9032\n",
      "Epoch 636/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9755\n",
      "Epoch 636: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0555 - accuracy: 0.9755 - val_loss: 0.3485 - val_accuracy: 0.9194\n",
      "Epoch 637/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9755\n",
      "Epoch 637: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0533 - accuracy: 0.9755 - val_loss: 0.2767 - val_accuracy: 0.9194\n",
      "Epoch 638/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0501 - accuracy: 0.9732\n",
      "Epoch 638: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0585 - accuracy: 0.9714 - val_loss: 0.2234 - val_accuracy: 0.9194\n",
      "Epoch 639/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9714\n",
      "Epoch 639: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0426 - accuracy: 0.9714 - val_loss: 0.2071 - val_accuracy: 0.9355\n",
      "Epoch 640/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9714\n",
      "Epoch 640: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0495 - accuracy: 0.9714 - val_loss: 0.2418 - val_accuracy: 0.9194\n",
      "Epoch 641/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9755\n",
      "Epoch 641: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0470 - accuracy: 0.9755 - val_loss: 0.3770 - val_accuracy: 0.8871\n",
      "Epoch 642/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9796\n",
      "Epoch 642: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0431 - accuracy: 0.9796 - val_loss: 0.3392 - val_accuracy: 0.8871\n",
      "Epoch 643/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0460 - accuracy: 0.9777\n",
      "Epoch 643: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0536 - accuracy: 0.9755 - val_loss: 0.2486 - val_accuracy: 0.9194\n",
      "Epoch 644/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9592\n",
      "Epoch 644: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0642 - accuracy: 0.9592 - val_loss: 0.2566 - val_accuracy: 0.9194\n",
      "Epoch 645/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9796\n",
      "Epoch 645: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0517 - accuracy: 0.9796 - val_loss: 0.2256 - val_accuracy: 0.9355\n",
      "Epoch 646/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9714\n",
      "Epoch 646: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0686 - accuracy: 0.9714 - val_loss: 0.2451 - val_accuracy: 0.9194\n",
      "Epoch 647/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9633\n",
      "Epoch 647: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0652 - accuracy: 0.9633 - val_loss: 0.2828 - val_accuracy: 0.8226\n",
      "Epoch 648/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0585 - accuracy: 0.9688\n",
      "Epoch 648: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0588 - accuracy: 0.9673 - val_loss: 0.2307 - val_accuracy: 0.9355\n",
      "Epoch 649/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0693 - accuracy: 0.9688\n",
      "Epoch 649: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0648 - accuracy: 0.9714 - val_loss: 0.2400 - val_accuracy: 0.9194\n",
      "Epoch 650/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0500 - accuracy: 0.9777\n",
      "Epoch 650: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0518 - accuracy: 0.9755 - val_loss: 0.3146 - val_accuracy: 0.8548\n",
      "Epoch 651/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9673\n",
      "Epoch 651: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0552 - accuracy: 0.9673 - val_loss: 0.3781 - val_accuracy: 0.8226\n",
      "Epoch 652/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0516 - accuracy: 0.9777\n",
      "Epoch 652: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0521 - accuracy: 0.9755 - val_loss: 0.5297 - val_accuracy: 0.7742\n",
      "Epoch 653/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9633\n",
      "Epoch 653: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0547 - accuracy: 0.9633 - val_loss: 0.6007 - val_accuracy: 0.7419\n",
      "Epoch 654/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9796\n",
      "Epoch 654: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0546 - accuracy: 0.9796 - val_loss: 0.4880 - val_accuracy: 0.8065\n",
      "Epoch 655/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0517 - accuracy: 0.9777\n",
      "Epoch 655: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0539 - accuracy: 0.9714 - val_loss: 0.5263 - val_accuracy: 0.7742\n",
      "Epoch 656/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9714\n",
      "Epoch 656: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0502 - accuracy: 0.9714 - val_loss: 0.4387 - val_accuracy: 0.8387\n",
      "Epoch 657/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0424 - accuracy: 0.9732\n",
      "Epoch 657: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0467 - accuracy: 0.9673 - val_loss: 0.3921 - val_accuracy: 0.8387\n",
      "Epoch 658/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9714\n",
      "Epoch 658: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0633 - accuracy: 0.9714 - val_loss: 0.4097 - val_accuracy: 0.8387\n",
      "Epoch 659/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0444 - accuracy: 0.9777\n",
      "Epoch 659: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0462 - accuracy: 0.9755 - val_loss: 0.3785 - val_accuracy: 0.8548\n",
      "Epoch 660/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9673\n",
      "Epoch 660: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0623 - accuracy: 0.9673 - val_loss: 0.4201 - val_accuracy: 0.8387\n",
      "Epoch 661/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0395 - accuracy: 0.9821\n",
      "Epoch 661: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0491 - accuracy: 0.9714 - val_loss: 0.5239 - val_accuracy: 0.8226\n",
      "Epoch 662/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9714\n",
      "Epoch 662: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0571 - accuracy: 0.9714 - val_loss: 0.8279 - val_accuracy: 0.7742\n",
      "Epoch 663/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9755\n",
      "Epoch 663: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0479 - accuracy: 0.9755 - val_loss: 0.5194 - val_accuracy: 0.8226\n",
      "Epoch 664/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0517 - accuracy: 0.9732\n",
      "Epoch 664: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0625 - accuracy: 0.9714 - val_loss: 0.3886 - val_accuracy: 0.8226\n",
      "Epoch 665/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0529 - accuracy: 0.9732\n",
      "Epoch 665: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.0486 - accuracy: 0.9755 - val_loss: 0.3098 - val_accuracy: 0.9032\n",
      "Epoch 666/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0576 - accuracy: 0.9598\n",
      "Epoch 666: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0594 - accuracy: 0.9551 - val_loss: 0.2522 - val_accuracy: 0.8871\n",
      "Epoch 667/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0527 - accuracy: 0.9732\n",
      "Epoch 667: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0598 - accuracy: 0.9714 - val_loss: 0.2577 - val_accuracy: 0.8871\n",
      "Epoch 668/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0499 - accuracy: 0.9732\n",
      "Epoch 668: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0473 - accuracy: 0.9755 - val_loss: 0.2730 - val_accuracy: 0.8871\n",
      "Epoch 669/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9755\n",
      "Epoch 669: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0482 - accuracy: 0.9755 - val_loss: 0.2977 - val_accuracy: 0.8226\n",
      "Epoch 670/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0423 - accuracy: 0.9866\n",
      "Epoch 670: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0507 - accuracy: 0.9796 - val_loss: 0.3340 - val_accuracy: 0.8226\n",
      "Epoch 671/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9673\n",
      "Epoch 671: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0545 - accuracy: 0.9673 - val_loss: 0.4444 - val_accuracy: 0.7903\n",
      "Epoch 672/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9755\n",
      "Epoch 672: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0485 - accuracy: 0.9755 - val_loss: 0.3755 - val_accuracy: 0.8226\n",
      "Epoch 673/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0694 - accuracy: 0.9598\n",
      "Epoch 673: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0635 - accuracy: 0.9633 - val_loss: 0.3036 - val_accuracy: 0.8226\n",
      "Epoch 674/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9796\n",
      "Epoch 674: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0449 - accuracy: 0.9796 - val_loss: 0.2425 - val_accuracy: 0.8387\n",
      "Epoch 675/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9673\n",
      "Epoch 675: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.0630 - accuracy: 0.9673 - val_loss: 0.1996 - val_accuracy: 0.9032\n",
      "Epoch 676/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9714\n",
      "Epoch 676: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0557 - accuracy: 0.9714 - val_loss: 0.2034 - val_accuracy: 0.9032\n",
      "Epoch 677/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9714\n",
      "Epoch 677: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0549 - accuracy: 0.9714 - val_loss: 0.2223 - val_accuracy: 0.9355\n",
      "Epoch 678/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9755\n",
      "Epoch 678: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0518 - accuracy: 0.9755 - val_loss: 0.1961 - val_accuracy: 0.9194\n",
      "Epoch 679/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9714\n",
      "Epoch 679: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0599 - accuracy: 0.9714 - val_loss: 0.2152 - val_accuracy: 0.9032\n",
      "Epoch 680/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9755\n",
      "Epoch 680: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0556 - accuracy: 0.9755 - val_loss: 0.2852 - val_accuracy: 0.8871\n",
      "Epoch 681/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0387 - accuracy: 0.9777\n",
      "Epoch 681: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0499 - accuracy: 0.9714 - val_loss: 0.3368 - val_accuracy: 0.9032\n",
      "Epoch 682/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0525 - accuracy: 0.9821\n",
      "Epoch 682: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0580 - accuracy: 0.9796 - val_loss: 0.3184 - val_accuracy: 0.9194\n",
      "Epoch 683/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9633\n",
      "Epoch 683: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0503 - accuracy: 0.9633 - val_loss: 0.4147 - val_accuracy: 0.8065\n",
      "Epoch 684/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0652 - accuracy: 0.9598\n",
      "Epoch 684: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0612 - accuracy: 0.9633 - val_loss: 0.6089 - val_accuracy: 0.7742\n",
      "Epoch 685/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0564 - accuracy: 0.9732\n",
      "Epoch 685: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0596 - accuracy: 0.9714 - val_loss: 0.6063 - val_accuracy: 0.7742\n",
      "Epoch 686/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0563 - accuracy: 0.9777\n",
      "Epoch 686: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0555 - accuracy: 0.9755 - val_loss: 0.4426 - val_accuracy: 0.8065\n",
      "Epoch 687/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9796\n",
      "Epoch 687: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0438 - accuracy: 0.9796 - val_loss: 0.3938 - val_accuracy: 0.8387\n",
      "Epoch 688/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0542 - accuracy: 0.9643\n",
      "Epoch 688: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0516 - accuracy: 0.9673 - val_loss: 0.3348 - val_accuracy: 0.9194\n",
      "Epoch 689/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9673\n",
      "Epoch 689: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0631 - accuracy: 0.9673 - val_loss: 0.2616 - val_accuracy: 0.9032\n",
      "Epoch 690/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0460 - accuracy: 0.9777\n",
      "Epoch 690: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0476 - accuracy: 0.9755 - val_loss: 0.2926 - val_accuracy: 0.9194\n",
      "Epoch 691/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9673\n",
      "Epoch 691: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0477 - accuracy: 0.9673 - val_loss: 0.2845 - val_accuracy: 0.9194\n",
      "Epoch 692/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0541 - accuracy: 0.9643\n",
      "Epoch 692: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0525 - accuracy: 0.9633 - val_loss: 0.2551 - val_accuracy: 0.9194\n",
      "Epoch 693/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0554 - accuracy: 0.9688\n",
      "Epoch 693: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0509 - accuracy: 0.9714 - val_loss: 0.2785 - val_accuracy: 0.9194\n",
      "Epoch 694/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0459 - accuracy: 0.9821\n",
      "Epoch 694: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0515 - accuracy: 0.9796 - val_loss: 0.2919 - val_accuracy: 0.9194\n",
      "Epoch 695/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9796\n",
      "Epoch 695: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0485 - accuracy: 0.9796 - val_loss: 0.2024 - val_accuracy: 0.9032\n",
      "Epoch 696/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0642 - accuracy: 0.9732\n",
      "Epoch 696: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0591 - accuracy: 0.9755 - val_loss: 0.1757 - val_accuracy: 0.9194\n",
      "Epoch 697/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0692 - accuracy: 0.9509\n",
      "Epoch 697: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0637 - accuracy: 0.9551 - val_loss: 0.1644 - val_accuracy: 0.9355\n",
      "Epoch 698/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0498 - accuracy: 0.9732\n",
      "Epoch 698: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0520 - accuracy: 0.9755 - val_loss: 0.1497 - val_accuracy: 0.9355\n",
      "Epoch 699/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9673\n",
      "Epoch 699: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0587 - accuracy: 0.9673 - val_loss: 0.1432 - val_accuracy: 0.9194\n",
      "Epoch 700/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9714\n",
      "Epoch 700: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0533 - accuracy: 0.9714 - val_loss: 0.1532 - val_accuracy: 0.9032\n",
      "Epoch 701/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9755\n",
      "Epoch 701: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0531 - accuracy: 0.9755 - val_loss: 0.1761 - val_accuracy: 0.9194\n",
      "Epoch 702/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9796\n",
      "Epoch 702: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0431 - accuracy: 0.9796 - val_loss: 0.2116 - val_accuracy: 0.9194\n",
      "Epoch 703/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9755\n",
      "Epoch 703: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0461 - accuracy: 0.9755 - val_loss: 0.1872 - val_accuracy: 0.9355\n",
      "Epoch 704/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9633\n",
      "Epoch 704: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0620 - accuracy: 0.9633 - val_loss: 0.1743 - val_accuracy: 0.9194\n",
      "Epoch 705/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9714\n",
      "Epoch 705: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 61ms/step - loss: 0.0551 - accuracy: 0.9714 - val_loss: 0.1726 - val_accuracy: 0.9194\n",
      "Epoch 706/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9714\n",
      "Epoch 706: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0524 - accuracy: 0.9714 - val_loss: 0.1801 - val_accuracy: 0.9194\n",
      "Epoch 707/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0526 - accuracy: 0.9598\n",
      "Epoch 707: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0541 - accuracy: 0.9592 - val_loss: 0.1625 - val_accuracy: 0.9516\n",
      "Epoch 708/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0493 - accuracy: 0.9821\n",
      "Epoch 708: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0622 - accuracy: 0.9755 - val_loss: 0.1692 - val_accuracy: 0.9516\n",
      "Epoch 709/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9673\n",
      "Epoch 709: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0572 - accuracy: 0.9673 - val_loss: 0.1992 - val_accuracy: 0.9194\n",
      "Epoch 710/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9714\n",
      "Epoch 710: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0506 - accuracy: 0.9714 - val_loss: 0.1953 - val_accuracy: 0.9194\n",
      "Epoch 711/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9714\n",
      "Epoch 711: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0467 - accuracy: 0.9714 - val_loss: 0.1949 - val_accuracy: 0.9516\n",
      "Epoch 712/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9755\n",
      "Epoch 712: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0540 - accuracy: 0.9755 - val_loss: 0.1950 - val_accuracy: 0.9516\n",
      "Epoch 713/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0440 - accuracy: 0.9777\n",
      "Epoch 713: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0481 - accuracy: 0.9755 - val_loss: 0.1902 - val_accuracy: 0.9516\n",
      "Epoch 714/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9796\n",
      "Epoch 714: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0452 - accuracy: 0.9796 - val_loss: 0.1836 - val_accuracy: 0.9355\n",
      "Epoch 715/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9673\n",
      "Epoch 715: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0565 - accuracy: 0.9673 - val_loss: 0.1640 - val_accuracy: 0.9355\n",
      "Epoch 716/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0506 - accuracy: 0.9732\n",
      "Epoch 716: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0505 - accuracy: 0.9755 - val_loss: 0.1530 - val_accuracy: 0.9516\n",
      "Epoch 717/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9755\n",
      "Epoch 717: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.0492 - accuracy: 0.9755 - val_loss: 0.1582 - val_accuracy: 0.9355\n",
      "Epoch 718/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0564 - accuracy: 0.9688\n",
      "Epoch 718: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0515 - accuracy: 0.9714 - val_loss: 0.1663 - val_accuracy: 0.9516\n",
      "Epoch 719/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9673\n",
      "Epoch 719: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0560 - accuracy: 0.9673 - val_loss: 0.1742 - val_accuracy: 0.9516\n",
      "Epoch 720/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0431 - accuracy: 0.9777\n",
      "Epoch 720: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0481 - accuracy: 0.9755 - val_loss: 0.1593 - val_accuracy: 0.9677\n",
      "Epoch 721/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0369 - accuracy: 0.9866\n",
      "Epoch 721: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 61ms/step - loss: 0.0445 - accuracy: 0.9796 - val_loss: 0.1595 - val_accuracy: 0.9355\n",
      "Epoch 722/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9592\n",
      "Epoch 722: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0556 - accuracy: 0.9592 - val_loss: 0.1770 - val_accuracy: 0.9516\n",
      "Epoch 723/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9510\n",
      "Epoch 723: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0638 - accuracy: 0.9510 - val_loss: 0.1798 - val_accuracy: 0.9677\n",
      "Epoch 724/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9714\n",
      "Epoch 724: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0490 - accuracy: 0.9714 - val_loss: 0.1912 - val_accuracy: 0.9516\n",
      "Epoch 725/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9796\n",
      "Epoch 725: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0497 - accuracy: 0.9796 - val_loss: 0.1912 - val_accuracy: 0.9355\n",
      "Epoch 726/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9714\n",
      "Epoch 726: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0545 - accuracy: 0.9714 - val_loss: 0.1556 - val_accuracy: 0.9355\n",
      "Epoch 727/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9592\n",
      "Epoch 727: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0541 - accuracy: 0.9592 - val_loss: 0.1350 - val_accuracy: 0.9677\n",
      "Epoch 728/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9837\n",
      "Epoch 728: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0486 - accuracy: 0.9837 - val_loss: 0.1233 - val_accuracy: 0.9355\n",
      "Epoch 729/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9755\n",
      "Epoch 729: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0529 - accuracy: 0.9755 - val_loss: 0.1304 - val_accuracy: 0.9355\n",
      "Epoch 730/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9755\n",
      "Epoch 730: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0537 - accuracy: 0.9755 - val_loss: 0.1370 - val_accuracy: 0.9355\n",
      "Epoch 731/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0529 - accuracy: 0.9688\n",
      "Epoch 731: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0528 - accuracy: 0.9673 - val_loss: 0.1836 - val_accuracy: 0.9355\n",
      "Epoch 732/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9755\n",
      "Epoch 732: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0487 - accuracy: 0.9755 - val_loss: 0.1699 - val_accuracy: 0.9355\n",
      "Epoch 733/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9755\n",
      "Epoch 733: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0526 - accuracy: 0.9755 - val_loss: 0.1400 - val_accuracy: 0.9194\n",
      "Epoch 734/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0532 - accuracy: 0.9732\n",
      "Epoch 734: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 61ms/step - loss: 0.0517 - accuracy: 0.9755 - val_loss: 0.1342 - val_accuracy: 0.9194\n",
      "Epoch 735/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9755\n",
      "Epoch 735: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0512 - accuracy: 0.9755 - val_loss: 0.1536 - val_accuracy: 0.9355\n",
      "Epoch 736/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9673\n",
      "Epoch 736: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0469 - accuracy: 0.9673 - val_loss: 0.1530 - val_accuracy: 0.9355\n",
      "Epoch 737/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9755\n",
      "Epoch 737: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0557 - accuracy: 0.9755 - val_loss: 0.1500 - val_accuracy: 0.9355\n",
      "Epoch 738/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0593 - accuracy: 0.9643\n",
      "Epoch 738: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0544 - accuracy: 0.9673 - val_loss: 0.2162 - val_accuracy: 0.9032\n",
      "Epoch 739/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9796\n",
      "Epoch 739: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0512 - accuracy: 0.9796 - val_loss: 0.1772 - val_accuracy: 0.9194\n",
      "Epoch 740/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9714\n",
      "Epoch 740: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0472 - accuracy: 0.9714 - val_loss: 0.2334 - val_accuracy: 0.9194\n",
      "Epoch 741/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9796\n",
      "Epoch 741: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0534 - accuracy: 0.9796 - val_loss: 0.2264 - val_accuracy: 0.9194\n",
      "Epoch 742/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9755\n",
      "Epoch 742: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0519 - accuracy: 0.9755 - val_loss: 0.2195 - val_accuracy: 0.9194\n",
      "Epoch 743/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9714\n",
      "Epoch 743: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0527 - accuracy: 0.9714 - val_loss: 0.2056 - val_accuracy: 0.9032\n",
      "Epoch 744/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9673\n",
      "Epoch 744: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 60ms/step - loss: 0.0547 - accuracy: 0.9673 - val_loss: 0.2140 - val_accuracy: 0.9032\n",
      "Epoch 745/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9714\n",
      "Epoch 745: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0496 - accuracy: 0.9714 - val_loss: 0.2186 - val_accuracy: 0.9032\n",
      "Epoch 746/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9755\n",
      "Epoch 746: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0482 - accuracy: 0.9755 - val_loss: 0.2528 - val_accuracy: 0.9032\n",
      "Epoch 747/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0409 - accuracy: 0.9777\n",
      "Epoch 747: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0465 - accuracy: 0.9755 - val_loss: 0.1864 - val_accuracy: 0.9032\n",
      "Epoch 748/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9755\n",
      "Epoch 748: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0491 - accuracy: 0.9755 - val_loss: 0.1982 - val_accuracy: 0.8871\n",
      "Epoch 749/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9633\n",
      "Epoch 749: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0604 - accuracy: 0.9633 - val_loss: 0.2396 - val_accuracy: 0.9194\n",
      "Epoch 750/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0509 - accuracy: 0.9777\n",
      "Epoch 750: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0533 - accuracy: 0.9755 - val_loss: 0.3185 - val_accuracy: 0.9194\n",
      "Epoch 751/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9796\n",
      "Epoch 751: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0487 - accuracy: 0.9796 - val_loss: 0.2254 - val_accuracy: 0.9194\n",
      "Epoch 752/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9755\n",
      "Epoch 752: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0553 - accuracy: 0.9755 - val_loss: 0.2267 - val_accuracy: 0.8871\n",
      "Epoch 753/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.9714\n",
      "Epoch 753: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0550 - accuracy: 0.9714 - val_loss: 0.2534 - val_accuracy: 0.8871\n",
      "Epoch 754/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9633\n",
      "Epoch 754: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0526 - accuracy: 0.9633 - val_loss: 0.2745 - val_accuracy: 0.8871\n",
      "Epoch 755/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9714\n",
      "Epoch 755: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0537 - accuracy: 0.9714 - val_loss: 0.2752 - val_accuracy: 0.8871\n",
      "Epoch 756/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0417 - accuracy: 0.9777\n",
      "Epoch 756: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0465 - accuracy: 0.9755 - val_loss: 0.2551 - val_accuracy: 0.8871\n",
      "Epoch 757/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0570 - accuracy: 0.9688\n",
      "Epoch 757: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0569 - accuracy: 0.9673 - val_loss: 0.2399 - val_accuracy: 0.9194\n",
      "Epoch 758/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9673\n",
      "Epoch 758: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0623 - accuracy: 0.9673 - val_loss: 0.2835 - val_accuracy: 0.9194\n",
      "Epoch 759/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9755\n",
      "Epoch 759: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0496 - accuracy: 0.9755 - val_loss: 0.2487 - val_accuracy: 0.9194\n",
      "Epoch 760/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0512 - accuracy: 0.9732\n",
      "Epoch 760: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0514 - accuracy: 0.9755 - val_loss: 0.2591 - val_accuracy: 0.9194\n",
      "Epoch 761/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0474 - accuracy: 0.9866\n",
      "Epoch 761: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0452 - accuracy: 0.9878 - val_loss: 0.2320 - val_accuracy: 0.9194\n",
      "Epoch 762/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9755\n",
      "Epoch 762: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0495 - accuracy: 0.9755 - val_loss: 0.2242 - val_accuracy: 0.9194\n",
      "Epoch 763/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9755\n",
      "Epoch 763: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0432 - accuracy: 0.9755 - val_loss: 0.2140 - val_accuracy: 0.9194\n",
      "Epoch 764/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9673\n",
      "Epoch 764: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0551 - accuracy: 0.9673 - val_loss: 0.2275 - val_accuracy: 0.9194\n",
      "Epoch 765/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0699 - accuracy: 0.9598\n",
      "Epoch 765: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0643 - accuracy: 0.9633 - val_loss: 0.2215 - val_accuracy: 0.9194\n",
      "Epoch 766/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0489 - accuracy: 0.9688\n",
      "Epoch 766: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0474 - accuracy: 0.9714 - val_loss: 0.2297 - val_accuracy: 0.9194\n",
      "Epoch 767/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0635 - accuracy: 0.9643\n",
      "Epoch 767: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0603 - accuracy: 0.9673 - val_loss: 0.2304 - val_accuracy: 0.9194\n",
      "Epoch 768/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0466 - accuracy: 0.9777\n",
      "Epoch 768: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0592 - accuracy: 0.9714 - val_loss: 0.2344 - val_accuracy: 0.9194\n",
      "Epoch 769/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0487 - accuracy: 0.9777\n",
      "Epoch 769: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0573 - accuracy: 0.9755 - val_loss: 0.1933 - val_accuracy: 0.9194\n",
      "Epoch 770/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0615 - accuracy: 0.9732\n",
      "Epoch 770: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0590 - accuracy: 0.9755 - val_loss: 0.1595 - val_accuracy: 0.9194\n",
      "Epoch 771/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0479 - accuracy: 0.9688\n",
      "Epoch 771: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0458 - accuracy: 0.9714 - val_loss: 0.1541 - val_accuracy: 0.9032\n",
      "Epoch 772/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0492 - accuracy: 0.9732\n",
      "Epoch 772: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0480 - accuracy: 0.9755 - val_loss: 0.1814 - val_accuracy: 0.9194\n",
      "Epoch 773/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0448 - accuracy: 0.9821\n",
      "Epoch 773: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0588 - accuracy: 0.9755 - val_loss: 0.1753 - val_accuracy: 0.9194\n",
      "Epoch 774/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9673\n",
      "Epoch 774: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.0464 - accuracy: 0.9673 - val_loss: 0.1398 - val_accuracy: 0.9355\n",
      "Epoch 775/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0534 - accuracy: 0.9732\n",
      "Epoch 775: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0492 - accuracy: 0.9755 - val_loss: 0.1223 - val_accuracy: 0.9355\n",
      "Epoch 776/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0558 - accuracy: 0.9554\n",
      "Epoch 776: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0511 - accuracy: 0.9592 - val_loss: 0.1209 - val_accuracy: 0.9355\n",
      "Epoch 777/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9714\n",
      "Epoch 777: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0583 - accuracy: 0.9714 - val_loss: 0.1165 - val_accuracy: 0.9516\n",
      "Epoch 778/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0404 - accuracy: 0.9777\n",
      "Epoch 778: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.0449 - accuracy: 0.9755 - val_loss: 0.1179 - val_accuracy: 0.9516\n",
      "Epoch 779/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9755\n",
      "Epoch 779: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0480 - accuracy: 0.9755 - val_loss: 0.1881 - val_accuracy: 0.9355\n",
      "Epoch 780/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0489 - accuracy: 0.9688\n",
      "Epoch 780: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0501 - accuracy: 0.9673 - val_loss: 0.2727 - val_accuracy: 0.8226\n",
      "Epoch 781/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9673\n",
      "Epoch 781: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0566 - accuracy: 0.9673 - val_loss: 0.2277 - val_accuracy: 0.8387\n",
      "Epoch 782/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0504 - accuracy: 0.9732\n",
      "Epoch 782: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0482 - accuracy: 0.9755 - val_loss: 0.2136 - val_accuracy: 0.9355\n",
      "Epoch 783/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9755\n",
      "Epoch 783: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0585 - accuracy: 0.9755 - val_loss: 0.3082 - val_accuracy: 0.8387\n",
      "Epoch 784/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9592\n",
      "Epoch 784: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0599 - accuracy: 0.9592 - val_loss: 0.3115 - val_accuracy: 0.8548\n",
      "Epoch 785/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0521 - accuracy: 0.9732\n",
      "Epoch 785: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0513 - accuracy: 0.9755 - val_loss: 0.2215 - val_accuracy: 0.9194\n",
      "Epoch 786/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9755\n",
      "Epoch 786: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0525 - accuracy: 0.9755 - val_loss: 0.2635 - val_accuracy: 0.9194\n",
      "Epoch 787/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9714\n",
      "Epoch 787: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0489 - accuracy: 0.9714 - val_loss: 0.2586 - val_accuracy: 0.9355\n",
      "Epoch 788/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9755\n",
      "Epoch 788: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0480 - accuracy: 0.9755 - val_loss: 0.2300 - val_accuracy: 0.9355\n",
      "Epoch 789/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9755\n",
      "Epoch 789: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0472 - accuracy: 0.9755 - val_loss: 0.1964 - val_accuracy: 0.9355\n",
      "Epoch 790/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9755\n",
      "Epoch 790: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0434 - accuracy: 0.9755 - val_loss: 0.2206 - val_accuracy: 0.9355\n",
      "Epoch 791/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0468 - accuracy: 0.9777\n",
      "Epoch 791: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0464 - accuracy: 0.9796 - val_loss: 0.2669 - val_accuracy: 0.9194\n",
      "Epoch 792/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9714\n",
      "Epoch 792: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0502 - accuracy: 0.9714 - val_loss: 0.3668 - val_accuracy: 0.9194\n",
      "Epoch 793/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9755\n",
      "Epoch 793: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0502 - accuracy: 0.9755 - val_loss: 0.5024 - val_accuracy: 0.7903\n",
      "Epoch 794/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9592\n",
      "Epoch 794: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0507 - accuracy: 0.9592 - val_loss: 0.4617 - val_accuracy: 0.8226\n",
      "Epoch 795/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0488 - accuracy: 0.9732\n",
      "Epoch 795: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0620 - accuracy: 0.9673 - val_loss: 0.3789 - val_accuracy: 0.8387\n",
      "Epoch 796/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9633\n",
      "Epoch 796: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0547 - accuracy: 0.9633 - val_loss: 0.1856 - val_accuracy: 0.9677\n",
      "Epoch 797/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9755\n",
      "Epoch 797: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0531 - accuracy: 0.9755 - val_loss: 0.1953 - val_accuracy: 0.9516\n",
      "Epoch 798/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0573 - accuracy: 0.9643\n",
      "Epoch 798: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.0568 - accuracy: 0.9633 - val_loss: 0.1845 - val_accuracy: 0.9516\n",
      "Epoch 799/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0536 - accuracy: 0.9732\n",
      "Epoch 799: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0496 - accuracy: 0.9755 - val_loss: 0.2213 - val_accuracy: 0.9355\n",
      "Epoch 800/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9714\n",
      "Epoch 800: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0562 - accuracy: 0.9714 - val_loss: 0.2797 - val_accuracy: 0.9032\n",
      "Epoch 801/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9755\n",
      "Epoch 801: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0460 - accuracy: 0.9755 - val_loss: 0.3065 - val_accuracy: 0.9032\n",
      "Epoch 802/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9714\n",
      "Epoch 802: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0461 - accuracy: 0.9714 - val_loss: 0.3348 - val_accuracy: 0.8387\n",
      "Epoch 803/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0473 - accuracy: 0.9777\n",
      "Epoch 803: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 60ms/step - loss: 0.0459 - accuracy: 0.9796 - val_loss: 0.3117 - val_accuracy: 0.8548\n",
      "Epoch 804/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0609 - accuracy: 0.9688\n",
      "Epoch 804: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0558 - accuracy: 0.9714 - val_loss: 0.2916 - val_accuracy: 0.8548\n",
      "Epoch 805/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9673\n",
      "Epoch 805: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0506 - accuracy: 0.9673 - val_loss: 0.2804 - val_accuracy: 0.9194\n",
      "Epoch 806/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0538 - accuracy: 0.9688\n",
      "Epoch 806: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0494 - accuracy: 0.9714 - val_loss: 0.3021 - val_accuracy: 0.9194\n",
      "Epoch 807/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0683 - accuracy: 0.9732\n",
      "Epoch 807: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0625 - accuracy: 0.9755 - val_loss: 0.3550 - val_accuracy: 0.9032\n",
      "Epoch 808/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0511 - accuracy: 0.9777\n",
      "Epoch 808: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.0504 - accuracy: 0.9755 - val_loss: 0.3556 - val_accuracy: 0.9194\n",
      "Epoch 809/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9510\n",
      "Epoch 809: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0658 - accuracy: 0.9510 - val_loss: 0.3701 - val_accuracy: 0.8548\n",
      "Epoch 810/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0528 - accuracy: 0.9732\n",
      "Epoch 810: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0490 - accuracy: 0.9755 - val_loss: 0.4550 - val_accuracy: 0.8226\n",
      "Epoch 811/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9796\n",
      "Epoch 811: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0566 - accuracy: 0.9796 - val_loss: 0.4052 - val_accuracy: 0.8226\n",
      "Epoch 812/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9755\n",
      "Epoch 812: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0518 - accuracy: 0.9755 - val_loss: 0.2925 - val_accuracy: 0.9032\n",
      "Epoch 813/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9714\n",
      "Epoch 813: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0504 - accuracy: 0.9714 - val_loss: 0.2572 - val_accuracy: 0.9032\n",
      "Epoch 814/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0466 - accuracy: 0.9732\n",
      "Epoch 814: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0617 - accuracy: 0.9673 - val_loss: 0.2782 - val_accuracy: 0.9194\n",
      "Epoch 815/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0565 - accuracy: 0.9688\n",
      "Epoch 815: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0610 - accuracy: 0.9633 - val_loss: 0.3079 - val_accuracy: 0.9194\n",
      "Epoch 816/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9633\n",
      "Epoch 816: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0535 - accuracy: 0.9633 - val_loss: 0.2601 - val_accuracy: 0.9355\n",
      "Epoch 817/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0518 - accuracy: 0.9777\n",
      "Epoch 817: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0555 - accuracy: 0.9755 - val_loss: 0.2831 - val_accuracy: 0.9194\n",
      "Epoch 818/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0521 - accuracy: 0.9777\n",
      "Epoch 818: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0538 - accuracy: 0.9755 - val_loss: 0.2782 - val_accuracy: 0.9194\n",
      "Epoch 819/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9714\n",
      "Epoch 819: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0516 - accuracy: 0.9714 - val_loss: 0.3082 - val_accuracy: 0.9194\n",
      "Epoch 820/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9714\n",
      "Epoch 820: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0494 - accuracy: 0.9714 - val_loss: 0.3705 - val_accuracy: 0.9032\n",
      "Epoch 821/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9714\n",
      "Epoch 821: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0595 - accuracy: 0.9714 - val_loss: 0.5058 - val_accuracy: 0.9032\n",
      "Epoch 822/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9755\n",
      "Epoch 822: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0498 - accuracy: 0.9755 - val_loss: 0.4504 - val_accuracy: 0.9032\n",
      "Epoch 823/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0472 - accuracy: 0.9732\n",
      "Epoch 823: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0472 - accuracy: 0.9714 - val_loss: 0.4268 - val_accuracy: 0.9032\n",
      "Epoch 824/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0565 - accuracy: 0.9732\n",
      "Epoch 824: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0549 - accuracy: 0.9714 - val_loss: 0.4342 - val_accuracy: 0.9032\n",
      "Epoch 825/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0455 - accuracy: 0.9688\n",
      "Epoch 825: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0514 - accuracy: 0.9673 - val_loss: 0.4418 - val_accuracy: 0.9032\n",
      "Epoch 826/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9755\n",
      "Epoch 826: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0488 - accuracy: 0.9755 - val_loss: 0.4544 - val_accuracy: 0.8871\n",
      "Epoch 827/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9755\n",
      "Epoch 827: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0480 - accuracy: 0.9755 - val_loss: 0.2219 - val_accuracy: 0.9194\n",
      "Epoch 828/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9714\n",
      "Epoch 828: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0519 - accuracy: 0.9714 - val_loss: 0.1574 - val_accuracy: 0.9194\n",
      "Epoch 829/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0469 - accuracy: 0.9821\n",
      "Epoch 829: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0471 - accuracy: 0.9796 - val_loss: 0.1736 - val_accuracy: 0.9355\n",
      "Epoch 830/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9673\n",
      "Epoch 830: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0611 - accuracy: 0.9673 - val_loss: 0.2047 - val_accuracy: 0.9355\n",
      "Epoch 831/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0560 - accuracy: 0.9732\n",
      "Epoch 831: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0549 - accuracy: 0.9755 - val_loss: 0.2613 - val_accuracy: 0.9194\n",
      "Epoch 832/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0475 - accuracy: 0.9732\n",
      "Epoch 832: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0435 - accuracy: 0.9755 - val_loss: 0.3520 - val_accuracy: 0.8871\n",
      "Epoch 833/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9755\n",
      "Epoch 833: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0480 - accuracy: 0.9755 - val_loss: 0.4545 - val_accuracy: 0.8710\n",
      "Epoch 834/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9633\n",
      "Epoch 834: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.0616 - accuracy: 0.9633 - val_loss: 0.5822 - val_accuracy: 0.8387\n",
      "Epoch 835/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0458 - accuracy: 0.9821\n",
      "Epoch 835: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0508 - accuracy: 0.9796 - val_loss: 0.3841 - val_accuracy: 0.8710\n",
      "Epoch 836/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9755\n",
      "Epoch 836: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0626 - accuracy: 0.9755 - val_loss: 0.3753 - val_accuracy: 0.8710\n",
      "Epoch 837/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9673\n",
      "Epoch 837: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0531 - accuracy: 0.9673 - val_loss: 0.4336 - val_accuracy: 0.8548\n",
      "Epoch 838/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0548 - accuracy: 0.9688\n",
      "Epoch 838: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0647 - accuracy: 0.9673 - val_loss: 0.7296 - val_accuracy: 0.7903\n",
      "Epoch 839/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0519 - accuracy: 0.9732\n",
      "Epoch 839: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0490 - accuracy: 0.9755 - val_loss: 1.0444 - val_accuracy: 0.7581\n",
      "Epoch 840/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9796\n",
      "Epoch 840: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0524 - accuracy: 0.9796 - val_loss: 1.1355 - val_accuracy: 0.7581\n",
      "Epoch 841/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9714\n",
      "Epoch 841: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0561 - accuracy: 0.9714 - val_loss: 1.0159 - val_accuracy: 0.7903\n",
      "Epoch 842/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0534 - accuracy: 0.9732\n",
      "Epoch 842: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0514 - accuracy: 0.9755 - val_loss: 1.1205 - val_accuracy: 0.7581\n",
      "Epoch 843/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0647 - accuracy: 0.9732\n",
      "Epoch 843: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0612 - accuracy: 0.9755 - val_loss: 1.0476 - val_accuracy: 0.7581\n",
      "Epoch 844/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0414 - accuracy: 0.9821\n",
      "Epoch 844: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0716 - accuracy: 0.9714 - val_loss: 1.0978 - val_accuracy: 0.7258\n",
      "Epoch 845/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9551\n",
      "Epoch 845: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0604 - accuracy: 0.9551 - val_loss: 0.9238 - val_accuracy: 0.7419\n",
      "Epoch 846/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9673\n",
      "Epoch 846: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0521 - accuracy: 0.9673 - val_loss: 0.7187 - val_accuracy: 0.7903\n",
      "Epoch 847/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9755\n",
      "Epoch 847: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0566 - accuracy: 0.9755 - val_loss: 0.5290 - val_accuracy: 0.8065\n",
      "Epoch 848/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9755\n",
      "Epoch 848: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0527 - accuracy: 0.9755 - val_loss: 0.4514 - val_accuracy: 0.8387\n",
      "Epoch 849/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0587 - accuracy: 0.9688\n",
      "Epoch 849: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0556 - accuracy: 0.9714 - val_loss: 0.3641 - val_accuracy: 0.8548\n",
      "Epoch 850/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0528 - accuracy: 0.9688\n",
      "Epoch 850: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0535 - accuracy: 0.9673 - val_loss: 0.3859 - val_accuracy: 0.8548\n",
      "Epoch 851/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9755\n",
      "Epoch 851: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0543 - accuracy: 0.9755 - val_loss: 0.3418 - val_accuracy: 0.8548\n",
      "Epoch 852/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9755\n",
      "Epoch 852: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0432 - accuracy: 0.9755 - val_loss: 0.3235 - val_accuracy: 0.8710\n",
      "Epoch 853/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0565 - accuracy: 0.9732\n",
      "Epoch 853: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0572 - accuracy: 0.9755 - val_loss: 0.3380 - val_accuracy: 0.8548\n",
      "Epoch 854/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9796\n",
      "Epoch 854: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0442 - accuracy: 0.9796 - val_loss: 0.3380 - val_accuracy: 0.8871\n",
      "Epoch 855/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0457 - accuracy: 0.9777\n",
      "Epoch 855: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0527 - accuracy: 0.9755 - val_loss: 0.3232 - val_accuracy: 0.9032\n",
      "Epoch 856/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9592\n",
      "Epoch 856: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0691 - accuracy: 0.9592 - val_loss: 0.6153 - val_accuracy: 0.7742\n",
      "Epoch 857/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9673\n",
      "Epoch 857: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0577 - accuracy: 0.9673 - val_loss: 0.6537 - val_accuracy: 0.8387\n",
      "Epoch 858/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9714\n",
      "Epoch 858: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0537 - accuracy: 0.9714 - val_loss: 0.5978 - val_accuracy: 0.7903\n",
      "Epoch 859/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9796\n",
      "Epoch 859: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0538 - accuracy: 0.9796 - val_loss: 0.5401 - val_accuracy: 0.7903\n",
      "Epoch 860/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9755\n",
      "Epoch 860: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0479 - accuracy: 0.9755 - val_loss: 0.4733 - val_accuracy: 0.7903\n",
      "Epoch 861/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0629 - accuracy: 0.9509\n",
      "Epoch 861: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0597 - accuracy: 0.9551 - val_loss: 0.5757 - val_accuracy: 0.7903\n",
      "Epoch 862/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9633\n",
      "Epoch 862: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0558 - accuracy: 0.9633 - val_loss: 0.2472 - val_accuracy: 0.9194\n",
      "Epoch 863/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9755\n",
      "Epoch 863: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0597 - accuracy: 0.9755 - val_loss: 0.2774 - val_accuracy: 0.9032\n",
      "Epoch 864/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0512 - accuracy: 0.9688\n",
      "Epoch 864: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.0518 - accuracy: 0.9673 - val_loss: 0.3790 - val_accuracy: 0.8226\n",
      "Epoch 865/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9714\n",
      "Epoch 865: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0590 - accuracy: 0.9714 - val_loss: 0.2839 - val_accuracy: 0.9032\n",
      "Epoch 866/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9755\n",
      "Epoch 866: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0513 - accuracy: 0.9755 - val_loss: 0.2862 - val_accuracy: 0.8871\n",
      "Epoch 867/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0434 - accuracy: 0.9821\n",
      "Epoch 867: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0558 - accuracy: 0.9755 - val_loss: 0.3217 - val_accuracy: 0.9194\n",
      "Epoch 868/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9755\n",
      "Epoch 868: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0464 - accuracy: 0.9755 - val_loss: 0.5197 - val_accuracy: 0.8065\n",
      "Epoch 869/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9673\n",
      "Epoch 869: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0606 - accuracy: 0.9673 - val_loss: 0.4722 - val_accuracy: 0.7903\n",
      "Epoch 870/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9755\n",
      "Epoch 870: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0511 - accuracy: 0.9755 - val_loss: 0.3427 - val_accuracy: 0.8871\n",
      "Epoch 871/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9673\n",
      "Epoch 871: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0552 - accuracy: 0.9673 - val_loss: 0.3412 - val_accuracy: 0.8871\n",
      "Epoch 872/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9796\n",
      "Epoch 872: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0471 - accuracy: 0.9796 - val_loss: 0.2834 - val_accuracy: 0.9194\n",
      "Epoch 873/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9755\n",
      "Epoch 873: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0528 - accuracy: 0.9755 - val_loss: 0.2405 - val_accuracy: 0.9355\n",
      "Epoch 874/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0408 - accuracy: 0.9777\n",
      "Epoch 874: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0424 - accuracy: 0.9755 - val_loss: 0.2258 - val_accuracy: 0.9355\n",
      "Epoch 875/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9714\n",
      "Epoch 875: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0570 - accuracy: 0.9714 - val_loss: 0.2794 - val_accuracy: 0.9194\n",
      "Epoch 876/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9796\n",
      "Epoch 876: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0417 - accuracy: 0.9796 - val_loss: 0.2162 - val_accuracy: 0.9355\n",
      "Epoch 877/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9837\n",
      "Epoch 877: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0469 - accuracy: 0.9837 - val_loss: 0.2851 - val_accuracy: 0.9032\n",
      "Epoch 878/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9796\n",
      "Epoch 878: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0486 - accuracy: 0.9796 - val_loss: 0.3321 - val_accuracy: 0.8871\n",
      "Epoch 879/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0506 - accuracy: 0.9777\n",
      "Epoch 879: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0551 - accuracy: 0.9755 - val_loss: 0.2847 - val_accuracy: 0.9032\n",
      "Epoch 880/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9714\n",
      "Epoch 880: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0533 - accuracy: 0.9714 - val_loss: 0.2184 - val_accuracy: 0.8871\n",
      "Epoch 881/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9755\n",
      "Epoch 881: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0511 - accuracy: 0.9755 - val_loss: 0.2387 - val_accuracy: 0.9032\n",
      "Epoch 882/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0463 - accuracy: 0.9777\n",
      "Epoch 882: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0473 - accuracy: 0.9755 - val_loss: 0.2691 - val_accuracy: 0.9032\n",
      "Epoch 883/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9755\n",
      "Epoch 883: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0500 - accuracy: 0.9755 - val_loss: 0.3348 - val_accuracy: 0.8710\n",
      "Epoch 884/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9796\n",
      "Epoch 884: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0506 - accuracy: 0.9796 - val_loss: 0.4467 - val_accuracy: 0.8226\n",
      "Epoch 885/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0660 - accuracy: 0.9643\n",
      "Epoch 885: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0609 - accuracy: 0.9673 - val_loss: 0.4989 - val_accuracy: 0.8226\n",
      "Epoch 886/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9714\n",
      "Epoch 886: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0555 - accuracy: 0.9714 - val_loss: 0.3981 - val_accuracy: 0.8226\n",
      "Epoch 887/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9592\n",
      "Epoch 887: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0609 - accuracy: 0.9592 - val_loss: 0.3213 - val_accuracy: 0.8548\n",
      "Epoch 888/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9714\n",
      "Epoch 888: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0492 - accuracy: 0.9714 - val_loss: 0.2402 - val_accuracy: 0.9032\n",
      "Epoch 889/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0423 - accuracy: 0.9821\n",
      "Epoch 889: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0458 - accuracy: 0.9796 - val_loss: 0.2314 - val_accuracy: 0.9032\n",
      "Epoch 890/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9673\n",
      "Epoch 890: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0503 - accuracy: 0.9673 - val_loss: 0.2445 - val_accuracy: 0.9194\n",
      "Epoch 891/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9592\n",
      "Epoch 891: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0667 - accuracy: 0.9592 - val_loss: 0.2720 - val_accuracy: 0.9194\n",
      "Epoch 892/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0617 - accuracy: 0.9732\n",
      "Epoch 892: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0597 - accuracy: 0.9714 - val_loss: 0.3124 - val_accuracy: 0.9194\n",
      "Epoch 893/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0543 - accuracy: 0.9643\n",
      "Epoch 893: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0596 - accuracy: 0.9592 - val_loss: 0.3495 - val_accuracy: 0.9355\n",
      "Epoch 894/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9755\n",
      "Epoch 894: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0564 - accuracy: 0.9755 - val_loss: 0.4203 - val_accuracy: 0.9355\n",
      "Epoch 895/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9755\n",
      "Epoch 895: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0552 - accuracy: 0.9755 - val_loss: 0.4051 - val_accuracy: 0.9355\n",
      "Epoch 896/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0485 - accuracy: 0.9688\n",
      "Epoch 896: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0469 - accuracy: 0.9714 - val_loss: 0.4154 - val_accuracy: 0.9355\n",
      "Epoch 897/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9755\n",
      "Epoch 897: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0600 - accuracy: 0.9755 - val_loss: 0.3907 - val_accuracy: 0.9194\n",
      "Epoch 898/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9633\n",
      "Epoch 898: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0581 - accuracy: 0.9633 - val_loss: 0.2849 - val_accuracy: 0.8871\n",
      "Epoch 899/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9633\n",
      "Epoch 899: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0527 - accuracy: 0.9633 - val_loss: 0.3236 - val_accuracy: 0.8871\n",
      "Epoch 900/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0675 - accuracy: 0.9598\n",
      "Epoch 900: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0630 - accuracy: 0.9633 - val_loss: 0.3546 - val_accuracy: 0.8548\n",
      "Epoch 901/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9755\n",
      "Epoch 901: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0499 - accuracy: 0.9755 - val_loss: 0.4945 - val_accuracy: 0.8065\n",
      "Epoch 902/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9714\n",
      "Epoch 902: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0572 - accuracy: 0.9714 - val_loss: 0.6449 - val_accuracy: 0.7903\n",
      "Epoch 903/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9673\n",
      "Epoch 903: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0477 - accuracy: 0.9673 - val_loss: 0.7291 - val_accuracy: 0.7742\n",
      "Epoch 904/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9714\n",
      "Epoch 904: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0582 - accuracy: 0.9714 - val_loss: 0.3766 - val_accuracy: 0.9032\n",
      "Epoch 905/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0604 - accuracy: 0.9732\n",
      "Epoch 905: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0593 - accuracy: 0.9755 - val_loss: 0.3210 - val_accuracy: 0.9032\n",
      "Epoch 906/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0525 - accuracy: 0.9732\n",
      "Epoch 906: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0482 - accuracy: 0.9755 - val_loss: 0.6295 - val_accuracy: 0.7742\n",
      "Epoch 907/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9633\n",
      "Epoch 907: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0561 - accuracy: 0.9633 - val_loss: 1.5571 - val_accuracy: 0.6452\n",
      "Epoch 908/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9714\n",
      "Epoch 908: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0520 - accuracy: 0.9714 - val_loss: 1.2351 - val_accuracy: 0.6613\n",
      "Epoch 909/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9755\n",
      "Epoch 909: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0537 - accuracy: 0.9755 - val_loss: 0.9982 - val_accuracy: 0.6935\n",
      "Epoch 910/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9755\n",
      "Epoch 910: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0466 - accuracy: 0.9755 - val_loss: 0.7884 - val_accuracy: 0.7419\n",
      "Epoch 911/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9714\n",
      "Epoch 911: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0522 - accuracy: 0.9714 - val_loss: 0.5402 - val_accuracy: 0.8065\n",
      "Epoch 912/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9755\n",
      "Epoch 912: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0514 - accuracy: 0.9755 - val_loss: 0.5967 - val_accuracy: 0.7903\n",
      "Epoch 913/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9633\n",
      "Epoch 913: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0518 - accuracy: 0.9633 - val_loss: 0.3039 - val_accuracy: 0.8710\n",
      "Epoch 914/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9755\n",
      "Epoch 914: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0488 - accuracy: 0.9755 - val_loss: 0.2415 - val_accuracy: 0.9032\n",
      "Epoch 915/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0468 - accuracy: 0.9732\n",
      "Epoch 915: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0457 - accuracy: 0.9755 - val_loss: 0.2287 - val_accuracy: 0.9032\n",
      "Epoch 916/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9714\n",
      "Epoch 916: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0554 - accuracy: 0.9714 - val_loss: 0.2356 - val_accuracy: 0.8871\n",
      "Epoch 917/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0530 - accuracy: 0.9777\n",
      "Epoch 917: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0499 - accuracy: 0.9796 - val_loss: 0.2263 - val_accuracy: 0.9194\n",
      "Epoch 918/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.9714\n",
      "Epoch 918: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0550 - accuracy: 0.9714 - val_loss: 0.2387 - val_accuracy: 0.9194\n",
      "Epoch 919/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9755\n",
      "Epoch 919: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0457 - accuracy: 0.9755 - val_loss: 0.2682 - val_accuracy: 0.9194\n",
      "Epoch 920/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 0.9755\n",
      "Epoch 920: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0542 - accuracy: 0.9755 - val_loss: 0.3024 - val_accuracy: 0.9194\n",
      "Epoch 921/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0540 - accuracy: 0.9732\n",
      "Epoch 921: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0494 - accuracy: 0.9755 - val_loss: 0.2740 - val_accuracy: 0.9194\n",
      "Epoch 922/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0402 - accuracy: 0.9777\n",
      "Epoch 922: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0475 - accuracy: 0.9755 - val_loss: 0.2999 - val_accuracy: 0.9194\n",
      "Epoch 923/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9714\n",
      "Epoch 923: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.0611 - accuracy: 0.9714 - val_loss: 0.3148 - val_accuracy: 0.9194\n",
      "Epoch 924/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9755\n",
      "Epoch 924: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0549 - accuracy: 0.9755 - val_loss: 0.2189 - val_accuracy: 0.9194\n",
      "Epoch 925/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9673\n",
      "Epoch 925: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0521 - accuracy: 0.9673 - val_loss: 0.1698 - val_accuracy: 0.9194\n",
      "Epoch 926/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0523 - accuracy: 0.9643\n",
      "Epoch 926: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0525 - accuracy: 0.9673 - val_loss: 0.1888 - val_accuracy: 0.9194\n",
      "Epoch 927/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9755\n",
      "Epoch 927: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0531 - accuracy: 0.9755 - val_loss: 0.2578 - val_accuracy: 0.8871\n",
      "Epoch 928/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9755\n",
      "Epoch 928: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0511 - accuracy: 0.9755 - val_loss: 0.2705 - val_accuracy: 0.8871\n",
      "Epoch 929/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9755\n",
      "Epoch 929: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0518 - accuracy: 0.9755 - val_loss: 0.2330 - val_accuracy: 0.9032\n",
      "Epoch 930/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9796\n",
      "Epoch 930: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0486 - accuracy: 0.9796 - val_loss: 0.2208 - val_accuracy: 0.9032\n",
      "Epoch 931/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9755\n",
      "Epoch 931: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0587 - accuracy: 0.9755 - val_loss: 0.2128 - val_accuracy: 0.9032\n",
      "Epoch 932/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0461 - accuracy: 0.9777\n",
      "Epoch 932: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0520 - accuracy: 0.9714 - val_loss: 0.2814 - val_accuracy: 0.9032\n",
      "Epoch 933/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9755\n",
      "Epoch 933: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0512 - accuracy: 0.9755 - val_loss: 0.3679 - val_accuracy: 0.8710\n",
      "Epoch 934/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0427 - accuracy: 0.9777\n",
      "Epoch 934: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0445 - accuracy: 0.9755 - val_loss: 0.3153 - val_accuracy: 0.8871\n",
      "Epoch 935/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9633\n",
      "Epoch 935: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0666 - accuracy: 0.9633 - val_loss: 0.2237 - val_accuracy: 0.9194\n",
      "Epoch 936/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9714\n",
      "Epoch 936: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0538 - accuracy: 0.9714 - val_loss: 0.1864 - val_accuracy: 0.9194\n",
      "Epoch 937/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9755\n",
      "Epoch 937: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0491 - accuracy: 0.9755 - val_loss: 0.2065 - val_accuracy: 0.9194\n",
      "Epoch 938/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0501 - accuracy: 0.9777\n",
      "Epoch 938: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0521 - accuracy: 0.9714 - val_loss: 0.2128 - val_accuracy: 0.9194\n",
      "Epoch 939/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9755\n",
      "Epoch 939: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0495 - accuracy: 0.9755 - val_loss: 0.2036 - val_accuracy: 0.9032\n",
      "Epoch 940/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0502 - accuracy: 0.9732\n",
      "Epoch 940: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0548 - accuracy: 0.9714 - val_loss: 0.2107 - val_accuracy: 0.9032\n",
      "Epoch 941/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0478 - accuracy: 0.9732\n",
      "Epoch 941: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0451 - accuracy: 0.9755 - val_loss: 0.2182 - val_accuracy: 0.9355\n",
      "Epoch 942/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9837\n",
      "Epoch 942: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0495 - accuracy: 0.9837 - val_loss: 0.2168 - val_accuracy: 0.9194\n",
      "Epoch 943/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9755\n",
      "Epoch 943: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0537 - accuracy: 0.9755 - val_loss: 0.2697 - val_accuracy: 0.8387\n",
      "Epoch 944/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0507 - accuracy: 0.9732\n",
      "Epoch 944: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0464 - accuracy: 0.9755 - val_loss: 0.3364 - val_accuracy: 0.8387\n",
      "Epoch 945/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0561 - accuracy: 0.9732\n",
      "Epoch 945: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0556 - accuracy: 0.9714 - val_loss: 0.4252 - val_accuracy: 0.8065\n",
      "Epoch 946/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0568 - accuracy: 0.9688\n",
      "Epoch 946: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.0524 - accuracy: 0.9714 - val_loss: 0.4312 - val_accuracy: 0.8226\n",
      "Epoch 947/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9755\n",
      "Epoch 947: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0509 - accuracy: 0.9755 - val_loss: 0.4177 - val_accuracy: 0.8226\n",
      "Epoch 948/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0531 - accuracy: 0.9732\n",
      "Epoch 948: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0521 - accuracy: 0.9714 - val_loss: 0.3649 - val_accuracy: 0.8065\n",
      "Epoch 949/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9796\n",
      "Epoch 949: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0469 - accuracy: 0.9796 - val_loss: 0.3273 - val_accuracy: 0.8387\n",
      "Epoch 950/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9755\n",
      "Epoch 950: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0513 - accuracy: 0.9755 - val_loss: 0.3979 - val_accuracy: 0.8226\n",
      "Epoch 951/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9714\n",
      "Epoch 951: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0528 - accuracy: 0.9714 - val_loss: 0.2714 - val_accuracy: 0.8387\n",
      "Epoch 952/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9673\n",
      "Epoch 952: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0557 - accuracy: 0.9673 - val_loss: 0.2477 - val_accuracy: 0.9194\n",
      "Epoch 953/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9796\n",
      "Epoch 953: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0515 - accuracy: 0.9796 - val_loss: 0.2676 - val_accuracy: 0.8710\n",
      "Epoch 954/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9755\n",
      "Epoch 954: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.0523 - accuracy: 0.9755 - val_loss: 0.3389 - val_accuracy: 0.8548\n",
      "Epoch 955/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9796\n",
      "Epoch 955: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0453 - accuracy: 0.9796 - val_loss: 0.3480 - val_accuracy: 0.8387\n",
      "Epoch 956/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9755\n",
      "Epoch 956: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0465 - accuracy: 0.9755 - val_loss: 0.2333 - val_accuracy: 0.9194\n",
      "Epoch 957/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9673\n",
      "Epoch 957: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0557 - accuracy: 0.9673 - val_loss: 0.2537 - val_accuracy: 0.9194\n",
      "Epoch 958/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9714\n",
      "Epoch 958: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0480 - accuracy: 0.9714 - val_loss: 0.4623 - val_accuracy: 0.7581\n",
      "Epoch 959/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9714\n",
      "Epoch 959: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0595 - accuracy: 0.9714 - val_loss: 0.4069 - val_accuracy: 0.8065\n",
      "Epoch 960/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9673\n",
      "Epoch 960: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0497 - accuracy: 0.9673 - val_loss: 0.3626 - val_accuracy: 0.8065\n",
      "Epoch 961/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9714\n",
      "Epoch 961: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0439 - accuracy: 0.9714 - val_loss: 0.4525 - val_accuracy: 0.7581\n",
      "Epoch 962/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9755\n",
      "Epoch 962: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0497 - accuracy: 0.9755 - val_loss: 0.2225 - val_accuracy: 0.9355\n",
      "Epoch 963/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9755\n",
      "Epoch 963: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0479 - accuracy: 0.9755 - val_loss: 0.2070 - val_accuracy: 0.9194\n",
      "Epoch 964/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9755\n",
      "Epoch 964: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0534 - accuracy: 0.9755 - val_loss: 0.1632 - val_accuracy: 0.9355\n",
      "Epoch 965/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9755\n",
      "Epoch 965: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0427 - accuracy: 0.9755 - val_loss: 0.1645 - val_accuracy: 0.9194\n",
      "Epoch 966/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9673\n",
      "Epoch 966: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0510 - accuracy: 0.9673 - val_loss: 0.1824 - val_accuracy: 0.9355\n",
      "Epoch 967/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0559 - accuracy: 0.9732\n",
      "Epoch 967: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0540 - accuracy: 0.9755 - val_loss: 0.1883 - val_accuracy: 0.9032\n",
      "Epoch 968/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0391 - accuracy: 0.9821\n",
      "Epoch 968: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0489 - accuracy: 0.9755 - val_loss: 0.2067 - val_accuracy: 0.9194\n",
      "Epoch 969/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9673\n",
      "Epoch 969: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.0507 - accuracy: 0.9673 - val_loss: 0.2274 - val_accuracy: 0.9194\n",
      "Epoch 970/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9755\n",
      "Epoch 970: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0522 - accuracy: 0.9755 - val_loss: 0.2666 - val_accuracy: 0.9032\n",
      "Epoch 971/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9673\n",
      "Epoch 971: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0539 - accuracy: 0.9673 - val_loss: 0.3505 - val_accuracy: 0.8710\n",
      "Epoch 972/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9633\n",
      "Epoch 972: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0599 - accuracy: 0.9633 - val_loss: 0.2688 - val_accuracy: 0.9194\n",
      "Epoch 973/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0480 - accuracy: 0.9777\n",
      "Epoch 973: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0529 - accuracy: 0.9755 - val_loss: 0.2955 - val_accuracy: 0.9032\n",
      "Epoch 974/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0554 - accuracy: 0.9598\n",
      "Epoch 974: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0537 - accuracy: 0.9592 - val_loss: 0.3095 - val_accuracy: 0.9194\n",
      "Epoch 975/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0588 - accuracy: 0.9688\n",
      "Epoch 975: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0539 - accuracy: 0.9714 - val_loss: 0.3072 - val_accuracy: 0.9194\n",
      "Epoch 976/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9755\n",
      "Epoch 976: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0514 - accuracy: 0.9755 - val_loss: 0.3545 - val_accuracy: 0.9032\n",
      "Epoch 977/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0529 - accuracy: 0.9777\n",
      "Epoch 977: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0543 - accuracy: 0.9755 - val_loss: 0.3820 - val_accuracy: 0.8871\n",
      "Epoch 978/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9714\n",
      "Epoch 978: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0505 - accuracy: 0.9714 - val_loss: 0.3952 - val_accuracy: 0.8871\n",
      "Epoch 979/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9673\n",
      "Epoch 979: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0502 - accuracy: 0.9673 - val_loss: 0.3763 - val_accuracy: 0.9032\n",
      "Epoch 980/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0464 - accuracy: 0.9777\n",
      "Epoch 980: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.0467 - accuracy: 0.9755 - val_loss: 0.3469 - val_accuracy: 0.9355\n",
      "Epoch 981/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0290 - accuracy: 0.9866\n",
      "Epoch 981: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0587 - accuracy: 0.9755 - val_loss: 0.3363 - val_accuracy: 0.9032\n",
      "Epoch 982/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9673\n",
      "Epoch 982: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0659 - accuracy: 0.9673 - val_loss: 0.3936 - val_accuracy: 0.9194\n",
      "Epoch 983/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9673\n",
      "Epoch 983: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 56ms/step - loss: 0.0561 - accuracy: 0.9673 - val_loss: 0.3774 - val_accuracy: 0.9355\n",
      "Epoch 984/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9633\n",
      "Epoch 984: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0576 - accuracy: 0.9633 - val_loss: 0.3592 - val_accuracy: 0.8871\n",
      "Epoch 985/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0650 - accuracy: 0.9688\n",
      "Epoch 985: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0598 - accuracy: 0.9714 - val_loss: 0.2816 - val_accuracy: 0.8871\n",
      "Epoch 986/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9755\n",
      "Epoch 986: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0442 - accuracy: 0.9755 - val_loss: 0.2750 - val_accuracy: 0.8871\n",
      "Epoch 987/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0577 - accuracy: 0.9821\n",
      "Epoch 987: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0535 - accuracy: 0.9837 - val_loss: 0.3124 - val_accuracy: 0.8710\n",
      "Epoch 988/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0524 - accuracy: 0.9643\n",
      "Epoch 988: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0482 - accuracy: 0.9673 - val_loss: 0.3894 - val_accuracy: 0.8548\n",
      "Epoch 989/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9714\n",
      "Epoch 989: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0582 - accuracy: 0.9714 - val_loss: 0.4151 - val_accuracy: 0.8387\n",
      "Epoch 990/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9673\n",
      "Epoch 990: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0596 - accuracy: 0.9673 - val_loss: 0.3936 - val_accuracy: 0.8387\n",
      "Epoch 991/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0483 - accuracy: 0.9777\n",
      "Epoch 991: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0535 - accuracy: 0.9755 - val_loss: 0.3839 - val_accuracy: 0.8387\n",
      "Epoch 992/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9755\n",
      "Epoch 992: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0457 - accuracy: 0.9755 - val_loss: 0.4067 - val_accuracy: 0.8548\n",
      "Epoch 993/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0518 - accuracy: 0.9732\n",
      "Epoch 993: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.0500 - accuracy: 0.9755 - val_loss: 0.3519 - val_accuracy: 0.8871\n",
      "Epoch 994/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0506 - accuracy: 0.9732\n",
      "Epoch 994: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0554 - accuracy: 0.9714 - val_loss: 0.3671 - val_accuracy: 0.8871\n",
      "Epoch 995/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9755\n",
      "Epoch 995: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0543 - accuracy: 0.9755 - val_loss: 0.3413 - val_accuracy: 0.8871\n",
      "Epoch 996/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0553 - accuracy: 0.9688\n",
      "Epoch 996: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0515 - accuracy: 0.9714 - val_loss: 0.3459 - val_accuracy: 0.8871\n",
      "Epoch 997/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0538 - accuracy: 0.9732\n",
      "Epoch 997: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0492 - accuracy: 0.9755 - val_loss: 0.2986 - val_accuracy: 0.8871\n",
      "Epoch 998/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9755\n",
      "Epoch 998: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.0531 - accuracy: 0.9755 - val_loss: 0.2898 - val_accuracy: 0.8871\n",
      "Epoch 999/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9714\n",
      "Epoch 999: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.0529 - accuracy: 0.9714 - val_loss: 0.2678 - val_accuracy: 0.9032\n",
      "Epoch 1000/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0509 - accuracy: 0.9688\n",
      "Epoch 1000: val_accuracy did not improve from 0.96774\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.0561 - accuracy: 0.9673 - val_loss: 0.2581 - val_accuracy: 0.9032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x391b18160>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=32, \n",
    "          epochs=1000, \n",
    "          shuffle=True,\n",
    "          callbacks=[cp]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5059 - accuracy: 0.8864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5058622360229492, 0.8863636255264282]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"CNN_1D_88ACCRY.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 614ms/step - loss: 0.6202 - accuracy: 0.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6201775074005127, 0.9090909361839294]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_model = load_model('CNN_1D_CHeckPoint.h5')\n",
    "cp_model.evaluate(X_test, y_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_single = CLASSES[np.argmax(y_pred, axis = -1)]\n",
    "actual_single = CLASSES[np.argmax(y_test, axis = -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(X_test)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    data = X_test[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i+1)\n",
    "    ax.plot(data)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.2, 'pred = ' + str(preds_single[idx]), fontsize=10, ha='center', transform=ax.transAxes) \n",
    "    ax.text(0.5, -0.4, 'act = ' + str(actual_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
